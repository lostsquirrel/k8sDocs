<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kubernetes – Service, 负载均衡, 网络</title>
    <link>https://lostsquirrel.github.io/k8sDocs/docs/concepts/services-networking/</link>
    <description>Recent content in Service, 负载均衡, 网络 on Kubernetes</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 30 Jun 2020 00:00:00 +0000</lastBuildDate>
    
	  <atom:link href="https://lostsquirrel.github.io/k8sDocs/docs/concepts/services-networking/index.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title>Docs: Service</title>
      <link>https://lostsquirrel.github.io/k8sDocs/docs/concepts/services-networking/service/</link>
      <pubDate>Tue, 30 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://lostsquirrel.github.io/k8sDocs/docs/concepts/services-networking/service/</guid>
      <description>
        
        
        &lt;!--
---
reviewers:
- bprashanth
title: Service
feature:
  title: Service discovery and load balancing
  description: &gt;
    No need to modify your application to use an unfamiliar service discovery mechanism. Kubernetes gives Pods their own IP addresses and a single DNS name for a set of Pods, and can load-balance across them.

content_type: concept
weight: 10
---
 --&gt;
&lt;!-- overview --&gt;
&lt;!--
&lt;p&gt;以网络服务的方式让一个由一组
&lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/concepts/workloads/pods/&#39; target=&#39;_blank&#39;&gt;Pod&lt;span class=&#39;tooltip-text&#39;&gt;Pod 表示集群中运行的一组容器的集合&lt;/span&gt;
&lt;/a&gt;
组成的应用能够对外提供服务的一种抽象方式&lt;/p&gt;

With Kubernetes you don&#39;t need to modify your application to use an unfamiliar service discovery mechanism.
Kubernetes gives Pods their own IP addresses and a single DNS name for a set of Pods,
and can load-balance across them.
 --&gt;
&lt;p&gt;以网络服务的方式让一个由一组
&lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/concepts/workloads/pods/&#39; target=&#39;_blank&#39;&gt;Pod&lt;span class=&#39;tooltip-text&#39;&gt;Pod 表示集群中运行的一组容器的集合&lt;/span&gt;
&lt;/a&gt;
组成的应用能够对外提供服务的一种抽象方式&lt;/p&gt;
&lt;p&gt;在使用 k8s 时并不需要修改应用来使用不熟悉的服务发现机制。 k8s 为 Pod 提供了自己的 IP 地址和
也为 Pod 集合提供单个 DNS 名称，并为其提供负载均衡。&lt;/p&gt;
&lt;!-- body --&gt;
&lt;!--
## Motivation

Kubernetes &lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/concepts/workloads/pods/&#39; target=&#39;_blank&#39;&gt;Pods&lt;span class=&#39;tooltip-text&#39;&gt;Pod 表示集群中运行的一组容器的集合&lt;/span&gt;
&lt;/a&gt; are mortal.
They are born and when they die, they are not resurrected.
If you use a &lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/concepts/workloads/controllers/deployment/&#39; target=&#39;_blank&#39;&gt;Deployment&lt;span class=&#39;tooltip-text&#39;&gt;管理集群中的一个多副本应用&lt;/span&gt;
&lt;/a&gt; to run your app,
it can create and destroy Pods dynamically.

Each Pod gets its own IP address, however in a Deployment, the set of Pods
running in one moment in time could be different from
the set of Pods running that application a moment later.

This leads to a problem: if some set of Pods (call them &#34;backends&#34;) provides
functionality to other Pods (call them &#34;frontends&#34;) inside your cluster,
how do the frontends find out and keep track of which IP address to connect
to, so that the frontend can use the backend part of the workload?

Enter _Services_.
 --&gt;
&lt;h2 id=&#34;动机&#34;&gt;动机&lt;/h2&gt;
&lt;p&gt;k8s 的 &lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/concepts/workloads/pods/&#39; target=&#39;_blank&#39;&gt;Pod&lt;span class=&#39;tooltip-text&#39;&gt;Pod 表示集群中运行的一组容器的集合&lt;/span&gt;
&lt;/a&gt; 是会挂掉的。它们出生然后挂掉，
它们挂了以后就不能再重生了。 如果使用
&lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/concepts/workloads/controllers/deployment/&#39; target=&#39;_blank&#39;&gt;Deployment&lt;span class=&#39;tooltip-text&#39;&gt;管理集群中的一个多副本应用&lt;/span&gt;
&lt;/a&gt;&lt;br&gt;
来运行应用，则它会动态地创建和销毁 Pod。&lt;/p&gt;
&lt;p&gt;每个 Pod 都会有一个自己的 IP 地址， 但是在 Deployment 中，它所管理的 Pod 在这一个时间点和
另一个时间点可能是不一样的。&lt;/p&gt;
&lt;p&gt;这就会导致一个问题: 如果在集群中有一组 Pod (称作 &amp;ldquo;后端&amp;rdquo;)为另一组 Pod (称作 &amp;ldquo;前端&amp;rdquo;)提供功能，
那么前端的 Pod 怎么能一直找到后端的连接 IP 地址，然后使用后端作为工作负载呢。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Services&lt;/em&gt; 就闪亮登场了.&lt;/p&gt;
&lt;!--
## Service resources {#service-resource}

In Kubernetes, a Service is an abstraction which defines a logical set of Pods
and a policy by which to access them (sometimes this pattern is called
a micro-service). The set of Pods targeted by a Service is usually determined
by a &lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/concepts/overview/working-with-objects/labels/&#39; target=&#39;_blank&#39;&gt;selector&lt;span class=&#39;tooltip-text&#39;&gt;允许用户基于标签过滤资源列表&lt;/span&gt;
&lt;/a&gt;
(see [below](#services-without-selectors) for why you might want a Service
_without_ a selector).

For example, consider a stateless image-processing backend which is running with
3 replicas.  Those replicas are fungible&amp;mdash;frontends do not care which backend
they use.  While the actual Pods that compose the backend set may change, the
frontend clients should not need to be aware of that, nor should they need to keep
track of the set of backends themselves.

The Service abstraction enables this decoupling.

### Cloud-native service discovery

If you&#39;re able to use Kubernetes APIs for service discovery in your application,
you can query the &lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/docs/reference/generated/kube-apiserver/&#39; target=&#39;_blank&#39;&gt;API server&lt;span class=&#39;tooltip-text&#39;&gt;Control plane component that serves the Kubernetes API.&lt;/span&gt;
&lt;/a&gt;
for Endpoints, that get updated whenever the set of Pods in a Service changes.

For non-native applications, Kubernetes offers ways to place a network port or load
balancer in between your application and the backend Pods.

 --&gt;
&lt;h2 id=&#34;service-resource&#34;&gt;Service 资源&lt;/h2&gt;
&lt;p&gt;在 k8s 中， Service 是一个抽象概念，它定义的是逻辑组上的一组 Pod 与访问它们的策略(有时候这种模式也被称为 微服务)。
Service 所指向的是哪些 Pod 通常是由&lt;br&gt;
&lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/concepts/overview/working-with-objects/labels/&#39; target=&#39;_blank&#39;&gt;选择器&lt;span class=&#39;tooltip-text&#39;&gt;允许用户基于标签过滤资源列表&lt;/span&gt;
&lt;/a&gt;
决定的(&lt;a href=&#34;#services-without-selectors&#34;&gt;下面&lt;/a&gt;还介绍了可能 &lt;em&gt;不需要&lt;/em&gt; 选择器的 Service).&lt;/p&gt;
&lt;p&gt;例如，假如有一个无状的图片处理后端，有3个副本在运行。 这些副本是可替代的 — 前端不关心它们
用的是哪个后台。 当组成后端的 Pod 可能发生变化， 但前端的客户端应该不能感知到，它们也不需要自己
来跟踪后端的具体成员。&lt;/p&gt;
&lt;p&gt;Service 的抽象实现了这样的解耦。&lt;/p&gt;
&lt;h3 id=&#34;云原生服务发现&#34;&gt;云原生服务发现&lt;/h3&gt;
&lt;p&gt;如果能够在应用中使用 k8s API 来实现服务发现， 可以通过
&lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/docs/reference/generated/kube-apiserver/&#39; target=&#39;_blank&#39;&gt;API server&lt;span class=&#39;tooltip-text&#39;&gt;Control plane component that serves the Kubernetes API.&lt;/span&gt;
&lt;/a&gt;
查询 Endpoint, 通过这种方式可以实时更新到 Service 的 Pod 变更。&lt;/p&gt;
&lt;p&gt;对于非原生应用， k8s 为应用与后端 Pod 之间通信提供了网络端口或负载均衡等方式。&lt;/p&gt;
&lt;!--
## Defining a Service

A Service in Kubernetes is a REST object, similar to a Pod.  Like all of the
REST objects, you can `POST` a Service definition to the API server to create
a new instance.
The name of a Service object must be a valid
[DNS label name](/docs/concepts/overview/working-with-objects/names#dns-label-names).

For example, suppose you have a set of Pods that each listen on TCP port 9376
and carry a label `app=MyApp`:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  selector:
    app: MyApp
  ports:
    - protocol: TCP
      port: 80
      targetPort: 9376
```

This specification creates a new Service object named &#34;my-service&#34;, which
targets TCP port 9376 on any Pod with the `app=MyApp` label.

Kubernetes assigns this Service an IP address (sometimes called the &#34;cluster IP&#34;),
which is used by the Service proxies
(see [Virtual IPs and service proxies](#virtual-ips-and-service-proxies) below).

The controller for the Service selector continuously scans for Pods that
match its selector, and then POSTs any updates to an Endpoint object
also named &#34;my-service&#34;.

&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; A Service can map &lt;em&gt;any&lt;/em&gt; incoming &lt;code&gt;port&lt;/code&gt; to a &lt;code&gt;targetPort&lt;/code&gt;. By default and
for convenience, the &lt;code&gt;targetPort&lt;/code&gt; is set to the same value as the &lt;code&gt;port&lt;/code&gt;
field.&lt;/div&gt;
&lt;/blockquote&gt;


Port definitions in Pods have names, and you can reference these names in the
`targetPort` attribute of a Service. This works even if there is a mixture
of Pods in the Service using a single configured name, with the same network
protocol available via different port numbers.
This offers a lot of flexibility for deploying and evolving your Services.
For example, you can change the port numbers that Pods expose in the next
version of your backend software, without breaking clients.

The default protocol for Services is TCP; you can also use any other
[supported protocol](#protocol-support).

As many Services need to expose more than one port, Kubernetes supports multiple
port definitions on a Service object.
Each port definition can have the same `protocol`, or a different one.
 --&gt;
&lt;h2 id=&#34;service-定义&#34;&gt;Service 定义&lt;/h2&gt;
&lt;p&gt;Service 在 k8s 中是一个 &lt;code&gt;REST&lt;/code&gt; 对象， 与 Pod 类似。 与其它所有 &lt;code&gt;REST&lt;/code&gt; 对象一样，
可以通过 &lt;code&gt;POST&lt;/code&gt; 请求将 Service 定义发送到 api-server 来创建一个新的实例。
Service 的名称必须是一个有效的
&lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/docs/concepts/overview/working-with-objects/names#dns-label-names&#34;&gt;DNS 标签名称&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;例如， 假如有一组 Pod， 每个 Pod 监听的端口都是 &lt;code&gt;9376&lt;/code&gt;， 都打着一个标签为 &lt;code&gt;app=MyApp&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Service&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-service&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;selector&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;app&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;MyApp&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;ports&lt;/span&gt;:
    - &lt;span style=&#34;color:#f92672&#34;&gt;protocol&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;TCP&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;targetPort&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;9376&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;上面的配置定义了一个 Service 对象，名字叫 &amp;ldquo;my-service&amp;rdquo;， 指向所有 TCP 端口为 &lt;code&gt;9376&lt;/code&gt;， 带有
&lt;code&gt;app=MyApp&lt;/code&gt; 标签的 Pod。&lt;/p&gt;
&lt;p&gt;k8s 会为 Service 分配一个 IP 地址(有时称为 &amp;ldquo;集群IP (cluster IP)&amp;quot;), 这个 IP 地址会被
Service 代理使用。
(见下面的 &lt;a href=&#34;#virtual-ips-and-service-proxies&#34;&gt;虚拟IP 和 service 代理&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Service 选择器的控制器会持续扫描匹配其选择器的 Pod，然后把这些变更以 POST 请求方式发送到一个
叫 &amp;ldquo;my-service&amp;rdquo; 的 Endpoint 对象。&lt;/p&gt;
&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; Service 可以映射 &lt;em&gt;任意&lt;/em&gt; 输入 &lt;code&gt;port&lt;/code&gt; 到 &lt;code&gt;targetPort&lt;/code&gt;。 默认情况和为了方便， &lt;code&gt;targetPort&lt;/code&gt;
会设置与 &lt;code&gt;port&lt;/code&gt; 字段相同的值。&lt;/div&gt;
&lt;/blockquote&gt;

&lt;p&gt;Pod 中的 Port 定义是有名字的， 这个名字可以在 Service &lt;code&gt;targetPort&lt;/code&gt; 属性上引用。
这种方式甚至可以用在当 Service 中使用同一个配置名称的不同 Pod，使用相同的网络协议，不同的端口
这个特性为 Service 的部署和演进提供了很高的灵活性。
例如， 用户可以修改用于下一版后端软件 Pod 暴露的端口，而不影响客户端。&lt;/p&gt;
&lt;p&gt;Services 默认协议为 TCP; 也可以使用其它&lt;a href=&#34;#protocol-support&#34;&gt;支持的协议&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;当许多的服务需要显露不止一个端口， k8s 支持在一个 Service 对象上定义多个端口。 每个端口定义
可以使用同样的 协议(&lt;code&gt;protocol&lt;/code&gt;), 也可以使用不同的.&lt;/p&gt;
&lt;h3 id=&#34;无标签选择器-service&#34;&gt;无标签选择器 Service&lt;/h3&gt;
&lt;p&gt;Service 最常见的用户就是作为 k8s Pod 的入口， 但它也可以作为其它类型的后端的抽象入口。
例如:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在生产环境使用的集群外的数库，但是在测试环境用的是内部的数据。&lt;/li&gt;
&lt;li&gt;想要将 Service 集群中另一个命名空间中的 Service 或另一个集群的服务。&lt;/li&gt;
&lt;li&gt;在迁移工作负载到 k8s 时，为了评估是否可行，先使用一部分后端服务在 k8s 中。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In any of these scenarios you can define a Service &lt;em&gt;without&lt;/em&gt; a Pod selector.
For example:
在以上的任意一种场景中都需要定义 &lt;em&gt;没有&lt;/em&gt; Pod 选择器的 Service。
例如:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Service&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-service&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;ports&lt;/span&gt;:
    - &lt;span style=&#34;color:#f92672&#34;&gt;protocol&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;TCP&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;targetPort&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;9376&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;因为这些 Service 没有选择器，所以对象的 Endpoint 也 &lt;em&gt;不会&lt;/em&gt; 自动创建。 可以通过手动创建 Endpoint
对象的方式将 Service 映射到实际运行的网络地址和端口。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Endpoints&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-service&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;subsets&lt;/span&gt;:
  - &lt;span style=&#34;color:#f92672&#34;&gt;addresses&lt;/span&gt;:
      - &lt;span style=&#34;color:#f92672&#34;&gt;ip&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;192.0.2.42&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;ports&lt;/span&gt;:
      - &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;9376&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Endpoint 对象的名称必以是一个有效的
&lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/docs/concepts/overview/working-with-objects/names#dns-subdomain-names&#34;&gt;DNS 子域名&lt;/a&gt;.
&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; &lt;p&gt;Endpoint 对象所用的 IP &lt;em&gt;必须不能&lt;/em&gt; 是: 回环地址 (127.0.0.0/8 IPv4, ::1/128 IPv6)，或
链路本地(link-local) (169.254.0.0/16 和 224.0.0.0/24  IPv4, fe80::/64 IPv6).&lt;/p&gt;
&lt;p&gt;Endpoint IP 地址也不能是其它 k8s Service 的集群 IP， 因为
&lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/docs/reference/command-line-tools-reference/kube-proxy/&#39; target=&#39;_blank&#39;&gt;kube-proxy&lt;span class=&#39;tooltip-text&#39;&gt;kube-proxy is a network proxy that runs on each node in the cluster.&lt;/span&gt;
&lt;/a&gt;
不支持将虚拟IP作为目的地址。&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/p&gt;
&lt;p&gt;访问无选择器的 Service 与有选择器的 Service 是一样的。在上面的例子中， 流量会路由到YAML定义中
唯一的 Endpoint &lt;code&gt;192.0.2.42:9376&lt;/code&gt; (TCP)&lt;/p&gt;
&lt;p&gt;一个 ExternalName Service 是 Service 中的一种特殊情景， 它没有选择器而是 DNS 名称。
更多信息见本文下面的 &lt;a href=&#34;#externalname&#34;&gt;ExternalName&lt;/a&gt;。&lt;/p&gt;
&lt;!--
### EndpointSlices





&lt;div style=&#34;margin-top: 10px; margin-bottom: 10px;&#34;&gt;
&lt;b&gt;功能特性状态:&lt;/b&gt; &lt;code&gt;Kubernetes v1.17 [beta]&lt;/code&gt;
&lt;/div&gt;



EndpointSlices are an API resource that can provide a more scalable alternative
to Endpoints. Although conceptually quite similar to Endpoints, EndpointSlices
allow for distributing network endpoints across multiple resources. By default,
an EndpointSlice is considered &#34;full&#34; once it reaches 100 endpoints, at which
point additional EndpointSlices will be created to store any additional
endpoints.

EndpointSlices provide additional attributes and functionality which is
described in detail in [EndpointSlices](/docs/concepts/services-networking/endpoint-slices/).
 --&gt;
&lt;h3 id=&#34;endpointslices&#34;&gt;EndpointSlices&lt;/h3&gt;





&lt;div style=&#34;margin-top: 10px; margin-bottom: 10px;&#34;&gt;
&lt;b&gt;功能特性状态:&lt;/b&gt; &lt;code&gt;Kubernetes v1.17 [beta]&lt;/code&gt;
&lt;/div&gt;


&lt;p&gt;EndpointSlice 是一种可比 Endpoint 提供更新好伸缩性替代方案的 API 资源。尽管在概念与 Endpoint
很相近， EndpointSlice 允许对铆中资源的网络末端进行分发. 默认情况下当一个 EndpointSlice
的网络末端数量达到 100 时就认为是 &amp;ldquo;满了&amp;rdquo;, 这时候就会创建新的 EndpointSlice 来存储更多的网络末端。&lt;/p&gt;
&lt;p&gt;更多 EndpointSlice 提供的属性和功能请见
&lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/docs/concepts/services-networking/endpoint-slices/&#34;&gt;EndpointSlices&lt;/a&gt;.&lt;/p&gt;
&lt;!--
### Application protocol






&lt;div style=&#34;margin-top: 10px; margin-bottom: 10px;&#34;&gt;
&lt;b&gt;功能特性状态:&lt;/b&gt; &lt;code&gt;Kubernetes v1.19 [beta]&lt;/code&gt;
&lt;/div&gt;



The AppProtocol field provides a way to specify an application protocol to be
used for each Service port. The value of this field is mirrored by corresponding
Endpoints and EndpointSlice resources.
--&gt;
&lt;h3 id=&#34;应用协议&#34;&gt;应用协议&lt;/h3&gt;





&lt;div style=&#34;margin-top: 10px; margin-bottom: 10px;&#34;&gt;
&lt;b&gt;功能特性状态:&lt;/b&gt; &lt;code&gt;Kubernetes v1.19 [beta]&lt;/code&gt;
&lt;/div&gt;


&lt;p&gt;&lt;code&gt;AppProtocol&lt;/code&gt; 字段提供了指定每个 Service 端口对应的应用协议的一种方式。
这个字段是对 Endpoint 和 EndpointSlice 对应字段的镜像。&lt;/p&gt;
&lt;!--
## Virtual IPs and service proxies

Every node in a Kubernetes cluster runs a `kube-proxy`. `kube-proxy` is
responsible for implementing a form of virtual IP for `Services` of type other
than [`ExternalName`](#externalname).
--&gt;
&lt;h2 id=&#34;虚拟-ip-和-service-代理&#34;&gt;虚拟 IP 和 Service 代理&lt;/h2&gt;
&lt;p&gt;Every node in a Kubernetes cluster runs a &lt;code&gt;kube-proxy&lt;/code&gt;. &lt;code&gt;kube-proxy&lt;/code&gt; is
responsible for implementing a form of virtual IP for &lt;code&gt;Services&lt;/code&gt; of type other
than &lt;a href=&#34;#externalname&#34;&gt;&lt;code&gt;ExternalName&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;k8s 集群中的每一个节点上都运行了 &lt;code&gt;kube-proxy&lt;/code&gt;， &lt;code&gt;kube-proxy&lt;/code&gt; 负责实现除了
&lt;a href=&#34;#externalname&#34;&gt;&lt;code&gt;ExternalName&lt;/code&gt;&lt;/a&gt;
外其它类型的 &lt;code&gt;Services&lt;/code&gt; 虚拟 IP 的实现方式&lt;/p&gt;
&lt;!--
### Why not use round-robin DNS?

A question that pops up every now and then is why Kubernetes relies on
proxying to forward inbound traffic to backends. What about other
approaches? For example, would it be possible to configure DNS records that
have multiple A values (or AAAA for IPv6), and rely on round-robin name
resolution?

There are a few reasons for using proxying for Services:

 * There is a long history of DNS implementations not respecting record TTLs,
   and caching the results of name lookups after they should have expired.
 * Some apps do DNS lookups only once and cache the results indefinitely.
 * Even if apps and libraries did proper re-resolution, the low or zero TTLs
   on the DNS records could impose a high load on DNS that then becomes
   difficult to manage.
 --&gt;
&lt;h3 id=&#34;为嘛不用-round-robin-dns-&#34;&gt;为嘛不用 round-robin DNS ?&lt;/h3&gt;
&lt;p&gt;一个时不时被提起的问题就是为啥 k8s 信赖于代理来转发入站流量到后端。 为啥不用其它的方式？
例如，有没有可能通过配置包含多个 A 值的 DNS 记录(IPv6 用 AAAA)， 然后通过轮询域名解析结果。
以下为 Service 使用代理的几个原因:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DNS 实现不遵循记录的 TTL有长久的历史， 并且在结果过期后继续使用缓存查询结果&lt;/li&gt;
&lt;li&gt;有些应用一次查询 DNS 后永远使用缓存的查询结果&lt;/li&gt;
&lt;li&gt;即便每个应用规范地来查 DNS， 但是 DNS 记录上的 TTL 的值很低或为0 会导致 DNS 的负载很高，并且变得难于管理&lt;/li&gt;
&lt;/ul&gt;
&lt;!--
### User space proxy mode {#proxy-mode-userspace}

In this mode, kube-proxy watches the Kubernetes master for the addition and
removal of Service and Endpoint objects. For each Service it opens a
port (randomly chosen) on the local node.  Any connections to this &#34;proxy port&#34;
are
proxied to one of the Service&#39;s backend Pods (as reported via
Endpoints). kube-proxy takes the `SessionAffinity` setting of the Service into
account when deciding which backend Pod to use.

Lastly, the user-space proxy installs iptables rules which capture traffic to
the Service&#39;s `clusterIP` (which is virtual) and `port`. The rules
redirect that traffic to the proxy port which proxies the backend Pod.

By default, kube-proxy in userspace mode chooses a backend via a round-robin algorithm.

![Services overview diagram for userspace proxy](/images/docs/services-userspace-overview.svg)
 --&gt;
&lt;h3 id=&#34;proxy-mode-userspace&#34;&gt;user-space 代理模式&lt;/h3&gt;
&lt;p&gt;在这种模式下， kube-proxy 监听 k8s 主控节点上 Service 和 Endpoint 对象的添加和删除。
对每一个 Service 它会在本地节点打开一个端口(随机选择)。任意一个连接到该 &amp;ldquo;代理端口&amp;quot;的流量都会代理
到 Service 后端 Pod(由 Endpoint 报告) 中的一个上。 kube-proxy 使用 Service 的 &lt;code&gt;SessionAffinity&lt;/code&gt;
设置为决定使用哪个后端 Pod。&lt;/p&gt;
&lt;p&gt;最后 user-space 代理会添加相应的 iptables 规则将捕获到 Service &lt;code&gt;clusterIP&lt;/code&gt;(是一个虚拟IP) 和 &lt;code&gt;port&lt;/code&gt; 的流量
然后这些规则将这些流量重定向到刚提供的会代理到后端 Pod 的代理端口上。&lt;/p&gt;
&lt;p&gt;默认情况下， kube-proxy 在使用 user-space 代理模式是使用轮询算法选择后端的 Pod。
&lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/docs/services-userspace-overview.svg&#34; alt=&#34;Services overview diagram for userspace proxy&#34;&gt;&lt;/p&gt;
&lt;!--
### `iptables` proxy mode {#proxy-mode-iptables}

In this mode, kube-proxy watches the Kubernetes control plane for the addition and
removal of Service and Endpoint objects. For each Service, it installs
iptables rules, which capture traffic to the Service&#39;s `clusterIP` and `port`,
and redirect that traffic to one of the Service&#39;s
backend sets.  For each Endpoint object, it installs iptables rules which
select a backend Pod.

By default, kube-proxy in iptables mode chooses a backend at random.

Using iptables to handle traffic has a lower system overhead, because traffic
is handled by Linux netfilter without the need to switch between userspace and the
kernel space. This approach is also likely to be more reliable.

If kube-proxy is running in iptables mode and the first Pod that&#39;s selected
does not respond, the connection fails. This is different from userspace
mode: in that scenario, kube-proxy would detect that the connection to the first
Pod had failed and would automatically retry with a different backend Pod.

You can use Pod [readiness probes](/docs/concepts/workloads/pods/pod-lifecycle/#container-probes)
to verify that backend Pods are working OK, so that kube-proxy in iptables mode
only sees backends that test out as healthy. Doing this means you avoid
having traffic sent via kube-proxy to a Pod that&#39;s known to have failed.

![Services overview diagram for iptables proxy](/k8sDocs/images/docs/services-iptables-overview.svg)
--&gt;
&lt;h3 id=&#34;proxy-mode-iptables&#34;&gt;&lt;code&gt;iptables&lt;/code&gt; 代理模式&lt;/h3&gt;
&lt;p&gt;在这种模式下， kube-proxy 监听 k8s 主控节点上 Service 和 Endpoint 对象的添加和删除。
对于每个 Service， 会添加一个 iptables 规则， 这个规则会捕获所有目标是 Service 的 &lt;code&gt;clusterIP&lt;/code&gt; 和 &lt;code&gt;port&lt;/code&gt;
的流量并将其重定向到 Service 后端 Pod 中的一个上。 对于每个 Endpoint 也会添加一个 iptables
规则，用来选择后端的 Pod。&lt;/p&gt;
&lt;p&gt;默认情况下，kube-proxy 在 &lt;code&gt;iptables&lt;/code&gt; 代理模式下，随机选择后端 Pod。&lt;/p&gt;
&lt;p&gt;使用 iptables 来处理流量系统开销更低， 因为流量由 Linux netfilter处理，而不需要在 userspace 和
kernelspace 之间来回切换。 这种方式也可能更加可靠。&lt;/p&gt;
&lt;p&gt;如果 kube-proxy 使用的 iptables 模式， 如果选择的第一个 Pod 没有响应，这个连接就失败了。
这与 userspace 模式不同： 在这种场景下， kube-proxy 会检测到第一个 Pod 的连接失败了，会自动
地尝试其它的后端 Pod。&lt;/p&gt;
&lt;p&gt;可以使用
&lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/docs/concepts/workloads/pods/pod-lifecycle/#container-probes&#34;&gt;就绪探针&lt;/a&gt;
来验证后端的 Pod 是在正常工作的， 因此 kube-proxy 在 iptables 模式下只会看到检测结果为健康的
后端 Pod。 这么做的意义在于避免了通过 kube-proxy 将流量发送到已经知道挂了的 Pod 上。
&lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/docs/services-iptables-overview.svg&#34; alt=&#34;Services overview diagram for iptables proxy&#34;&gt;&lt;/p&gt;
&lt;!--
### IPVS proxy mode {#proxy-mode-ipvs}






&lt;div style=&#34;margin-top: 10px; margin-bottom: 10px;&#34;&gt;
&lt;b&gt;功能特性状态:&lt;/b&gt; &lt;code&gt;Kubernetes v1.11 [stable]&lt;/code&gt;
&lt;/div&gt;



In `ipvs` mode, kube-proxy watches Kubernetes Services and Endpoints,
calls `netlink` interface to create IPVS rules accordingly and synchronizes
IPVS rules with Kubernetes Services and Endpoints periodically.
This control loop ensures that IPVS status matches the desired
state.
When accessing a Service, IPVS directs traffic to one of the backend Pods.

The IPVS proxy mode is based on netfilter hook function that is similar to
iptables mode, but uses a hash table as the underlying data structure and works
in the kernel space.
That means kube-proxy in IPVS mode redirects traffic with lower latency than
kube-proxy in iptables mode, with much better performance when synchronising
proxy rules. Compared to the other proxy modes, IPVS mode also supports a
higher throughput of network traffic.

IPVS provides more options for balancing traffic to backend Pods;
these are:

- `rr`: round-robin
- `lc`: least connection (smallest number of open connections)
- `dh`: destination hashing
- `sh`: source hashing
- `sed`: shortest expected delay
- `nq`: never queue

&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; &lt;p&gt;To run kube-proxy in IPVS mode, you must make IPVS available on
the node before starting kube-proxy.&lt;/p&gt;
&lt;p&gt;When kube-proxy starts in IPVS proxy mode, it verifies whether IPVS
kernel modules are available. If the IPVS kernel modules are not detected, then kube-proxy
falls back to running in iptables proxy mode.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;


![Services overview diagram for IPVS proxy](/k8sDocs/images/docs/services-ipvs-overview.svg)

In these proxy models, the traffic bound for the Service&#39;s IP:Port is
proxied to an appropriate backend without the clients knowing anything
about Kubernetes or Services or Pods.

If you want to make sure that connections from a particular client
are passed to the same Pod each time, you can select the session affinity based
on the client&#39;s IP addresses by setting `service.spec.sessionAffinity` to &#34;ClientIP&#34;
(the default is &#34;None&#34;).
You can also set the maximum session sticky time by setting
`service.spec.sessionAffinityConfig.clientIP.timeoutSeconds` appropriately.
(the default value is 10800, which works out to be 3 hours).
 --&gt;
&lt;h3 id=&#34;proxy-mode-ipvs&#34;&gt;IPVS 代理&lt;/h3&gt;





&lt;div style=&#34;margin-top: 10px; margin-bottom: 10px;&#34;&gt;
&lt;b&gt;功能特性状态:&lt;/b&gt; &lt;code&gt;Kubernetes v1.11 [stable]&lt;/code&gt;
&lt;/div&gt;


&lt;p&gt;在 &lt;code&gt;ipvs&lt;/code&gt; 模式下， kube-proxy 监听 k8s Services 和 Endpoint,
调用 &lt;code&gt;netlink&lt;/code&gt; 接口来创建 IPVS 规则， 并定时根据 k8s Services 和 Endpoint 更新 IPVS 规则。
这个控制回环确保 IPVS 的状态与期望状态一至。 当访问一个 Service 时， IPVS 重定向流量到
后端 Pod 中的一个上。&lt;/p&gt;
&lt;p&gt;IPVS 代理模式基于 netfilter 钩子功能，与 iptables 类似， 但底层使用的数据结构是一个哈希表
并且是在内核空间中工作的。
也就是 kube-proxy 在 IPVS 模式下， 重定向流量会比 iptables 模式有更低的延迟，在同步代理
规则时也会有更好的恨不能。 与其它的代理模式相比， IPVS 模式也支持更高吞吐量的网络流量。&lt;/p&gt;
&lt;p&gt;IPVS 还提供了更多到后端 Pod 的负载均衡选择；
具体如下:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;rr&lt;/code&gt;: 轮询&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lc&lt;/code&gt;: 最少连接 (打开连接数最小的)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dh&lt;/code&gt;: 目标哈希&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sh&lt;/code&gt;: 源哈希&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sed&lt;/code&gt;: 最短期望延迟 (shortest expected delay)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;nq&lt;/code&gt;: 无须队列等待 (never queue)&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; &lt;p&gt;要让 kube-proxy 以 IPVS 运行，必须要在 kube-proxy 启动之前让 IPVS 在节点上是可用的。&lt;/p&gt;
&lt;p&gt;当 kube-proxy 以 IPVS 代理模式启动时， 会检测 IPVS 内核模块是否可用。 如 IPVS 内核模块没有检测到，
则 kube-proxy 会回退以 iptables 模式运行。&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/docs/services-ipvs-overview.svg&#34; alt=&#34;Services overview diagram for IPVS proxy&#34;&gt;&lt;/p&gt;
&lt;p&gt;In these proxy models, the traffic bound for the Service&amp;rsquo;s IP:Port is
proxied to an appropriate backend without the clients knowing anything
about Kubernetes or Services or Pods.
在使用这种代理模式时， 访问 Service IP:Port 的流量被代理到适当的后端时，客户端不会感知到
k8s 或 Service 或 Pod 这些的存在。&lt;/p&gt;
&lt;p&gt;如果需要保证一个特定客户端的连接每次都要转发到同一个 Pod 上面， 可能设置
&lt;code&gt;service.spec.sessionAffinity&lt;/code&gt; 为 &amp;ldquo;ClientIP&amp;rdquo; (默认为 &amp;ldquo;None&amp;rdquo;) 来选择基于客户端IP的会话亲和性(session affinity).
也可以设置基于时间的会话黏性，为 &lt;code&gt;service.spec.sessionAffinityConfig.clientIP.timeoutSeconds&lt;/code&gt;
设置一个合适的值。 (默认值为 10800， 也就是 3 个小时)&lt;/p&gt;
&lt;!--
## Multi-Port Services

For some Services, you need to expose more than one port.
Kubernetes lets you configure multiple port definitions on a Service object.
When using multiple ports for a Service, you must give all of your ports names
so that these are unambiguous.
For example:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  selector:
    app: MyApp
  ports:
    - name: http
      protocol: TCP
      port: 80
      targetPort: 9376
    - name: https
      protocol: TCP
      port: 443
      targetPort: 9377
```

&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; &lt;p&gt;As with Kubernetes &lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/docs/concepts/overview/working-with-objects/names&#39; target=&#39;_blank&#39;&gt;names&lt;span class=&#39;tooltip-text&#39;&gt;A client-provided string that refers to an object in a resource URL, such as /api/v1/pods/some-name.&lt;/span&gt;
&lt;/a&gt; in general, names for ports
must only contain lowercase alphanumeric characters and &lt;code&gt;-&lt;/code&gt;. Port names must
also start and end with an alphanumeric character.&lt;/p&gt;
&lt;p&gt;For example, the names &lt;code&gt;123-abc&lt;/code&gt; and &lt;code&gt;web&lt;/code&gt; are valid, but &lt;code&gt;123_abc&lt;/code&gt; and &lt;code&gt;-web&lt;/code&gt; are not.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;

 --&gt;
&lt;h2 id=&#34;多端口的-service&#34;&gt;多端口的 Service&lt;/h2&gt;
&lt;p&gt;对于有些 Service 需要显露多于一个端口， k8s 允许用户在 Service 对象上定义多个端口。
当在 Service 上使用多个端口时，必须要给所有的端口配置名字，这样才便于区分。
例如:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Service&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-service&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;selector&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;app&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;MyApp&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;ports&lt;/span&gt;:
    - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;http&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;protocol&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;TCP&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;targetPort&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;9376&lt;/span&gt;
    - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;https&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;protocol&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;TCP&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;443&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;targetPort&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;9377&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; &lt;p&gt;依照 k8s 通用 &lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/docs/concepts/overview/working-with-objects/names&#39; target=&#39;_blank&#39;&gt;Name&lt;span class=&#39;tooltip-text&#39;&gt;A client-provided string that refers to an object in a resource URL, such as /api/v1/pods/some-name.&lt;/span&gt;
&lt;/a&gt;， 端口的名称只能包含小写字母，数字，和 中划线(&lt;code&gt;-&lt;/code&gt;)
且端口名只能以字母数字开始和结尾。&lt;/p&gt;
&lt;p&gt;例如， &lt;code&gt;123-abc&lt;/code&gt; 和 &lt;code&gt;web&lt;/code&gt; 是有效的，&lt;code&gt;123_abc&lt;/code&gt; 和 &lt;code&gt;-web&lt;/code&gt; 是无效的&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;

&lt;!--
## Choosing your own IP address

You can specify your own cluster IP address as part of a `Service` creation
request.  To do this, set the `.spec.clusterIP` field. For example, if you
already have an existing DNS entry that you wish to reuse, or legacy systems
that are configured for a specific IP address and difficult to re-configure.

The IP address that you choose must be a valid IPv4 or IPv6 address from within the
`service-cluster-ip-range` CIDR range that is configured for the API server.
If you try to create a Service with an invalid clusterIP address value, the API
server will return a 422 HTTP status code to indicate that there&#39;s a problem.

--&gt;
&lt;h2 id=&#34;选择自己的-ip-地址&#34;&gt;选择自己的 IP 地址&lt;/h2&gt;
&lt;p&gt;在创建 &lt;code&gt;Service&lt;/code&gt; 的时候可以通过设置 &lt;code&gt;.spec.clusterIP&lt;/code&gt; 字段指定自己的集群IP地址。
例如， 希望复用已经存在的 DNS 记录，或者一个已经设置了IP 然后很难重新配置的旧系统。&lt;/p&gt;
&lt;p&gt;选择设置的IP 必须要是 api-server 上配置的 &lt;code&gt;service-cluster-ip-range&lt;/code&gt; CIDR 范围内有效的
IPv4 或 IPv6 地址。 如果尝试使用一个无效的集群IP地址，api-server 会返回一个 422 的 HTTP
状态码，表示配置有问题&lt;/p&gt;
&lt;!--
## Discovering services

Kubernetes supports 2 primary modes of finding a Service - environment
variables and DNS.
 --&gt;
&lt;h2 id=&#34;service-查找&#34;&gt;Service 查找&lt;/h2&gt;
&lt;p&gt;k8s 主要支持 2 种查找一个 Service的方式: 环境变量 和 DNS&lt;/p&gt;
&lt;!--
### Environment variables

When a Pod is run on a Node, the kubelet adds a set of environment variables
for each active Service.  It supports both [Docker links
compatible](https://docs.docker.com/userguide/dockerlinks/) variables (see
[makeLinkVariables](https://releases.k8s.io/master/pkg/kubelet/envvars/envvars.go#L49))
and simpler `{SVCNAME}_SERVICE_HOST` and `{SVCNAME}_SERVICE_PORT` variables,
where the Service name is upper-cased and dashes are converted to underscores.

For example, the Service `&#34;redis-master&#34;` which exposes TCP port 6379 and has been
allocated cluster IP address 10.0.0.11, produces the following environment
variables:

```shell
REDIS_MASTER_SERVICE_HOST=10.0.0.11
REDIS_MASTER_SERVICE_PORT=6379
REDIS_MASTER_PORT=tcp://10.0.0.11:6379
REDIS_MASTER_PORT_6379_TCP=tcp://10.0.0.11:6379
REDIS_MASTER_PORT_6379_TCP_PROTO=tcp
REDIS_MASTER_PORT_6379_TCP_PORT=6379
REDIS_MASTER_PORT_6379_TCP_ADDR=10.0.0.11
```

&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; &lt;p&gt;When you have a Pod that needs to access a Service, and you are using
the environment variable method to publish the port and cluster IP to the client
Pods, you must create the Service &lt;em&gt;before&lt;/em&gt; the client Pods come into existence.
Otherwise, those client Pods won&amp;rsquo;t have their environment variables populated.&lt;/p&gt;
&lt;p&gt;If you only use DNS to discover the cluster IP for a Service, you don&amp;rsquo;t need to
worry about this ordering issue.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;

--&gt;
&lt;h3 id=&#34;环境变量&#34;&gt;环境变量&lt;/h3&gt;
&lt;p&gt;当一个 Pod 运行到一个节点时， kubelet 会把每个活跃的 Service  作为环境变量添加到 Pod 中。
它支持
&lt;a href=&#34;https://docs.docker.com/userguide/dockerlinks/&#34;&gt;Docker 连接兼容&lt;/a&gt;
的变量
(见 &lt;a href=&#34;https://releases.k8s.io/master/pkg/kubelet/envvars/envvars.go#L49&#34;&gt;makeLinkVariables&lt;/a&gt;)
和简单些的 &lt;code&gt;{SVCNAME}_SERVICE_HOST&lt;/code&gt; 和 &lt;code&gt;{SVCNAME}_SERVICE_PORT&lt;/code&gt; 变量，其中 Service
的名称为大写，中划线会被转化为下划线。&lt;/p&gt;
&lt;p&gt;例如， 一个叫 &lt;code&gt;&amp;quot;redis-master&amp;quot;&lt;/code&gt; 的 Service， 暴露的端口是 TCP &lt;code&gt;6379&lt;/code&gt;， 分配的集群IP地址为
&lt;code&gt;10.0.0.11&lt;/code&gt;， 就会产生如下环境变量:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;REDIS_MASTER_SERVICE_HOST&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;10.0.0.11
REDIS_MASTER_SERVICE_PORT&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;6379&lt;/span&gt;
REDIS_MASTER_PORT&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tcp://10.0.0.11:6379
REDIS_MASTER_PORT_6379_TCP&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tcp://10.0.0.11:6379
REDIS_MASTER_PORT_6379_TCP_PROTO&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tcp
REDIS_MASTER_PORT_6379_TCP_PORT&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;6379&lt;/span&gt;
REDIS_MASTER_PORT_6379_TCP_ADDR&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;10.0.0.11
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; &lt;p&gt;当有一个 Pod 需要要访问一个 Service， 并且是使用环境变量的方式将端口和集群IP传递给客户端 Pod 的，
那么 Service 必须要在客户端 Pod 创建 &lt;em&gt;之前&lt;/em&gt; 就要存在。 否则客户端 Pod 中就不会加入它对应的环境变量。&lt;/p&gt;
&lt;p&gt;如果只使用 DNS 为查找 Service 的集群IP，则不需要担心这个顺序问题&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;

&lt;!--
### DNS

You can (and almost always should) set up a DNS service for your Kubernetes
cluster using an [add-on](/docs/concepts/cluster-administration/addons/).

A cluster-aware DNS server, such as CoreDNS, watches the Kubernetes API for new
Services and creates a set of DNS records for each one.  If DNS has been enabled
throughout your cluster then all Pods should automatically be able to resolve
Services by their DNS name.

For example, if you have a Service called `&#34;my-service&#34;` in a Kubernetes
Namespace `&#34;my-ns&#34;`, the control plane and the DNS Service acting together
create a DNS record for `&#34;my-service.my-ns&#34;`. Pods in the `&#34;my-ns&#34;` Namespace
should be able to find it by simply doing a name lookup for `my-service`
(`&#34;my-service.my-ns&#34;` would also work).

Pods in other Namespaces must qualify the name as `my-service.my-ns`. These names
will resolve to the cluster IP assigned for the Service.

Kubernetes also supports DNS SRV (Service) records for named ports.  If the
`&#34;my-service.my-ns&#34;` Service has a port named `&#34;http&#34;` with the protocol set to
`TCP`, you can do a DNS SRV query for `_http._tcp.my-service.my-ns` to discover
the port number for `&#34;http&#34;`, as well as the IP address.

The Kubernetes DNS server is the only way to access `ExternalName` Services.
You can find more information about `ExternalName` resolution in
[DNS Pods and Services](/docs/concepts/services-networking/dns-pod-service/).
--&gt;
&lt;h3 id=&#34;dns&#34;&gt;DNS&lt;/h3&gt;
&lt;p&gt;用户可以(并且几乎绝大多时候应该)通过使用
&lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/docs/concepts/cluster-administration/addons/&#34;&gt;插件&lt;/a&gt;.
为你的集群设置 DNS 服务。&lt;/p&gt;
&lt;p&gt;一个可感知集群的 DNS 服务， 例如 CoreDNS， 会监听 k8s API 创建的 Service 并创建对应的 DNS 记录。
如果集群启用的 DNS 服务，则所以的 Pod 都应该会自动地通过 DNS 名称解析 Service。&lt;/p&gt;
&lt;p&gt;例如，如果有一个名叫 &lt;code&gt;&amp;quot;my-service&amp;quot;&lt;/code&gt; Service 于 &lt;code&gt;&amp;quot;my-ns&amp;quot;&lt;/code&gt; 命名空间，控制中心和 DNS 服务会
协作创建一条 DNS 记录为 &lt;code&gt;&amp;quot;my-service.my-ns&amp;quot;&lt;/code&gt;。 在 &lt;code&gt;&amp;quot;my-ns&amp;quot;&lt;/code&gt; 命名空间的 Pod 可以只需要简单地
使用 &lt;code&gt;my-service&lt;/code&gt; 就能查到(&lt;code&gt;&amp;quot;my-service.my-ns&amp;quot;&lt;/code&gt; 也是可以的)&lt;/p&gt;
&lt;p&gt;在其它命名空间的 Pod 必须使用 &lt;code&gt;my-service.my-ns&lt;/code&gt; 这样的限定名。 这些名称会解析为 Service
分配的集群IP。&lt;/p&gt;
&lt;p&gt;k8s 还支持命名端口的 DNS SRV (Service) 记录。 如果叫 &lt;code&gt;&amp;quot;my-service.my-ns&amp;quot;&lt;/code&gt; 的 Service
有一个叫 &lt;code&gt;&amp;quot;http&amp;quot;&lt;/code&gt; 的 &lt;code&gt;TCP&lt;/code&gt; 端口， 就可以使用 &lt;code&gt;DNS SRV&lt;/code&gt; 查询 &lt;code&gt;_http._tcp.my-service.my-ns&lt;/code&gt;
得到 &lt;code&gt;&amp;quot;http&amp;quot;&lt;/code&gt; 对应的端口号和 IP 地址。&lt;/p&gt;
&lt;p&gt;k8s DNS 服务是访问 &lt;code&gt;ExternalName&lt;/code&gt; Service 的唯一方式。更多关于 &lt;code&gt;ExternalName&lt;/code&gt; 的信息见
&lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/docs/concepts/services-networking/dns-pod-service/&#34;&gt;DNS Pod 和 Service&lt;/a&gt;.&lt;/p&gt;
&lt;!--
## Headless Services

Sometimes you don&#39;t need load-balancing and a single Service IP.  In
this case, you can create what are termed &#34;headless&#34; Services, by explicitly
specifying `&#34;None&#34;` for the cluster IP (`.spec.clusterIP`).

You can use a headless Service to interface with other service discovery mechanisms,
without being tied to Kubernetes&#39; implementation.

For headless `Services`, a cluster IP is not allocated, kube-proxy does not handle
these Services, and there is no load balancing or proxying done by the platform
for them. How DNS is automatically configured depends on whether the Service has
selectors defined:
 --&gt;
&lt;h2 id=&#34;headless-services&#34;&gt;Headless Services&lt;/h2&gt;
&lt;p&gt;有时候并不需要负载均衡和一个 Service 的 IP。 在这种情况下就可以创建一个被称为 &amp;ldquo;无头&amp;rdquo; 的 Service，
更确切的说就是将集群 IP (&lt;code&gt;.spec.clusterIP&lt;/code&gt;) 设置为 &lt;code&gt;&amp;quot;None&amp;quot;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;用户可以使用 无头 Service 作为其它服务发现机制的接口，而不需要与 k8s 实现耦合在一起。&lt;/p&gt;
&lt;p&gt;对于 无头的 &lt;code&gt;Services&lt;/code&gt; 是不会分配集群IP的， &lt;code&gt;kube-proxy&lt;/code&gt; 不会处理这些 Service，
平台也不会对它们提供负载均衡或代理。 DNS 是如何自动配置的基于 Service 是否定义了选择器:&lt;/p&gt;
&lt;!--
### With selectors

For headless Services that define selectors, the endpoints controller creates
`Endpoints` records in the API, and modifies the DNS configuration to return
records (addresses) that point directly to the `Pods` backing the `Service`.

### Without selectors

For headless Services that do not define selectors, the endpoints controller does
not create `Endpoints` records. However, the DNS system looks for and configures
either:

  * CNAME records for [`ExternalName`](#externalname)-type Services.
  * A records for any `Endpoints` that share a name with the Service, for all
    other types.
    --&gt;
&lt;h3 id=&#34;有选择器的&#34;&gt;有选择器的&lt;/h3&gt;
&lt;p&gt;对于有选择器的无头 Service， Endpoint 选择器会创建 &lt;code&gt;Endpoints&lt;/code&gt; 记录， 并修改 DNS 配置
直接返回记录为 &lt;code&gt;Service&lt;/code&gt; 后端 &lt;code&gt;Pod&lt;/code&gt; 的地址。&lt;/p&gt;
&lt;h3 id=&#34;没有选择器的&#34;&gt;没有选择器的&lt;/h3&gt;
&lt;p&gt;For headless Services that do not define selectors, the endpoints controller does
not create &lt;code&gt;Endpoints&lt;/code&gt; records. However, the DNS system looks for and configures
either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CNAME records for &lt;a href=&#34;#externalname&#34;&gt;&lt;code&gt;ExternalName&lt;/code&gt;&lt;/a&gt;-type Services.&lt;/li&gt;
&lt;li&gt;A records for any &lt;code&gt;Endpoints&lt;/code&gt; that share a name with the Service, for all
other types.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于没有选择器的无头 Service， Endpoint 选择器不会创建 &lt;code&gt;Endpoints&lt;/code&gt; 记录，但是 DNS 系统会根据以
下情况来配置:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#externalname&#34;&gt;&lt;code&gt;ExternalName&lt;/code&gt;&lt;/a&gt; 类型的 Service 创建 CNAME&lt;/li&gt;
&lt;li&gt;所有其它类型，为其它任意与该 Service 同名的 &lt;code&gt;Endpoints&lt;/code&gt; 创建 A 记录&lt;/li&gt;
&lt;/ul&gt;
&lt;!--
## Publishing Services (ServiceTypes) {#publishing-services-service-types}

For some parts of your application (for example, frontends) you may want to expose a
Service onto an external IP address, that&#39;s outside of your cluster.

Kubernetes `ServiceTypes` allow you to specify what kind of Service you want.
The default is `ClusterIP`.

`Type` values and their behaviors are:

   * `ClusterIP`: Exposes the Service on a cluster-internal IP. Choosing this value
     makes the Service only reachable from within the cluster. This is the
     default `ServiceType`.
   * [`NodePort`](#nodeport): Exposes the Service on each Node&#39;s IP at a static port
     (the `NodePort`). A `ClusterIP` Service, to which the `NodePort` Service
     routes, is automatically created.  You&#39;ll be able to contact the `NodePort` Service,
     from outside the cluster,
     by requesting `&lt;NodeIP&gt;:&lt;NodePort&gt;`.
   * [`LoadBalancer`](#loadbalancer): Exposes the Service externally using a cloud
     provider&#39;s load balancer. `NodePort` and `ClusterIP` Services, to which the external
     load balancer routes, are automatically created.
   * [`ExternalName`](#externalname): Maps the Service to the contents of the
     `externalName` field (e.g. `foo.bar.example.com`), by returning a `CNAME` record

     with its value. No proxying of any kind is set up.
     &lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; You need either kube-dns version 1.7 or CoreDNS version 0.0.8 or higher to use the &lt;code&gt;ExternalName&lt;/code&gt; type.&lt;/div&gt;
&lt;/blockquote&gt;


You can also use [Ingress](/docs/concepts/services-networking/ingress/) to expose your Service. Ingress is not a Service type, but it acts as the entry point for your cluster. It lets you consolidate your routing rules into a single resource as it can expose multiple services under the same IP address.
--&gt;
&lt;h2 id=&#34;publishing-services-service-types&#34;&gt;发布 Service (ServiceTypes)&lt;/h2&gt;
&lt;p&gt;对于应用的一些部分(例如，前端)，需要将 Service 暴露到集群外部 IP 地址。&lt;/p&gt;
&lt;p&gt;k8s 可以通过 &lt;code&gt;ServiceTypes&lt;/code&gt; 来指定想要创建的 Service 类型， 默认为 &lt;code&gt;ClusterIP&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Type&lt;/code&gt; 的值各行为如下:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;ClusterIP&lt;/code&gt;: 以集群内部 IP 的形式暴露 Service， 使用这种方式 Service 只能在集群内部访问。
这是默认的 &lt;code&gt;ServiceType&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;#nodeport&#34;&gt;&lt;code&gt;NodePort&lt;/code&gt;&lt;/a&gt;: 将 Service 暴露到每个节点 IP和一个静态端口上(可以通过 &lt;code&gt;NodePort&lt;/code&gt;指定)
(&lt;code&gt;ClusterIP&lt;/code&gt; Service 到 &lt;code&gt;NodePort&lt;/code&gt; Service 的路由会自动创建)。
用户可以通过在集群外请求 &lt;code&gt;&amp;lt;NodeIP&amp;gt;:&amp;lt;NodePort&amp;gt;&lt;/code&gt; 方式访问 &lt;code&gt;NodePort&lt;/code&gt; Service。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;#loadbalancer&#34;&gt;&lt;code&gt;LoadBalancer&lt;/code&gt;&lt;/a&gt;: 使用云提供商的负载均衡器对外暴露 Service。
由 &lt;code&gt;NodePort&lt;/code&gt; 和 &lt;code&gt;ClusterIP&lt;/code&gt; Service 到外部负载均衡的路由会自动创建.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;#externalname&#34;&gt;&lt;code&gt;ExternalName&lt;/code&gt;&lt;/a&gt;:
通过返回 &lt;code&gt;CNAME&lt;/code&gt; 的方式 将 Service 映射到 &lt;code&gt;externalName&lt;/code&gt; 字段 (e.g. &lt;code&gt;foo.bar.example.com&lt;/code&gt;)的服务
没有设置任何类型的代理
&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; 如果使用 &lt;code&gt;ExternalName&lt;/code&gt; 类型，需要 kube-dns &lt;code&gt;v1.7+&lt;/code&gt; 或 CoreDNS &lt;code&gt;v0.0.8+&lt;/code&gt;&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;用户也可以使用 &lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/docs/concepts/services-networking/ingress/&#34;&gt;Ingress&lt;/a&gt; 来暴露 Service。
Ingress 不是 Service 的一个类型， 但它扮演的是集群切入点的角色。 它让路由规则可以统一为一个资源。
并可以在同一个IP地址上暴露多个 Service&lt;/p&gt;
&lt;!--
### Type NodePort {#nodeport}

If you set the `type` field to `NodePort`, the Kubernetes control plane
allocates a port from a range specified by `--service-node-port-range` flag (default: 30000-32767).
Each node proxies that port (the same port number on every Node) into your Service.
Your Service reports the allocated port in its `.spec.ports[*].nodePort` field.


If you want to specify particular IP(s) to proxy the port, you can set the `--nodeport-addresses` flag in kube-proxy to particular IP block(s); this is supported since Kubernetes v1.10.
This flag takes a comma-delimited list of IP blocks (e.g. 10.0.0.0/8, 192.0.2.0/25) to specify IP address ranges that kube-proxy should consider as local to this node.

For example, if you start kube-proxy with the `--nodeport-addresses=127.0.0.0/8` flag, kube-proxy only selects the loopback interface for NodePort Services. The default for `--nodeport-addresses` is an empty list. This means that kube-proxy should consider all available network interfaces for NodePort. (That&#39;s also compatible with earlier Kubernetes releases).

If you want a specific port number, you can specify a value in the `nodePort`
field. The control plane will either allocate you that port or report that
the API transaction failed.
This means that you need to take care of possible port collisions yourself.
You also have to use a valid port number, one that&#39;s inside the range configured
for NodePort use.

Using a NodePort gives you the freedom to set up your own load balancing solution,
to configure environments that are not fully supported by Kubernetes, or even
to just expose one or more nodes&#39; IPs directly.

Note that this Service is visible as `&lt;NodeIP&gt;:spec.ports[*].nodePort`
and `.spec.clusterIP:spec.ports[*].port`. (If the `--nodeport-addresses` flag in kube-proxy is set, &lt;NodeIP&gt; would be filtered NodeIP(s).)

For example:
```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  type: NodePort
  selector:
    app: MyApp
  ports:
      # By default and for convenience, the `targetPort` is set to the same value as the `port` field.
    - port: 80
      targetPort: 80
      # Optional field
      # By default and for convenience, the Kubernetes control plane will allocate a port from a range (default: 30000-32767)
      nodePort: 30007
```
 --&gt;
&lt;h3 id=&#34;nodeport&#34;&gt;NodePort&lt;/h3&gt;
&lt;p&gt;如果将 &lt;code&gt;type&lt;/code&gt; 字段设置为 &lt;code&gt;NodePort&lt;/code&gt;， k8s 控制中心会从
&lt;code&gt;--service-node-port-range&lt;/code&gt; 选择配置的范围(默认 30000-32767)中分配一个端口。
集群中的每个节点都会将那个端口(每个节点使用相同的端口)代理到 Service 上。
Service 会将分配的的端口存放在它的 &lt;code&gt;.spec.ports[*].nodePort&lt;/code&gt; 字段。&lt;/p&gt;
&lt;p&gt;如果想要指定某些IP来代理这个端口，可以通过 kube-proxy 中的 &lt;code&gt;--nodeport-addresses&lt;/code&gt; 选择来
指定 IP 或 IP 段；这个特性自 k8s &lt;code&gt;v1.10&lt;/code&gt; 开始支持。
这个选择支持逗号分隔的 IP 段列表(e.g. 10.0.0.0/8, 192.0.2.0/25) 来指定 kube-proxy 是不是应该认为是应该代理的 IP 地址范围。&lt;/p&gt;
&lt;p&gt;例如，如果将 kube-proxy 设置 &lt;code&gt;--nodeport-addresses=127.0.0.0/8&lt;/code&gt;， 则 kube-proxy 只会
选择本地回环接口用作 Service 的 NodePort。 默认的  &lt;code&gt;--nodeport-addresses&lt;/code&gt; 是一个空列表。
其含义是 kube-proxy 会将所以可用的网络接口应用到 NodePort (这也与早期的 k8s 版本兼容)&lt;/p&gt;
&lt;p&gt;如果用户想要指定端口，可以通过设置 &lt;code&gt;nodePort&lt;/code&gt; 的值实现。 控制中心会分配那个端口或报告业务失败。
也就是说在设置该字段时需要用户自己解决端口冲突的问题。
并且首先设置的端口是一个有效的端口，其次端口是在之前提到所配置的 NodePort 的可用范围内。&lt;/p&gt;
&lt;p&gt;使用 NodePort 时就将负载均衡的解决方案选择交到用户手上, 可以用于配置那些 k8s 不完全支持的环境，
甚至直接暴露一个或多个节点的IP&lt;/p&gt;
&lt;p&gt;要注意 Service 可以通过 &lt;code&gt;&amp;lt;NodeIP&amp;gt;:spec.ports[*].nodePort&lt;/code&gt;:&lt;code&gt;.spec.clusterIP:spec.ports[*].port&lt;/code&gt; 访问。
(如果 kube-proxy 设置了 &lt;code&gt;--nodeport-addresses&lt;/code&gt;， 则 &lt;NodeIP&gt; 只能是配置的范围内的IP)&lt;/p&gt;
&lt;p&gt;例:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Service&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-service&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;type&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;NodePort&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;selector&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;app&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;MyApp&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;ports&lt;/span&gt;:
      &lt;span style=&#34;color:#75715e&#34;&gt;# 默认情况下和为了方便， `targetPort` 会与 `port` 字段使用相同的值&lt;/span&gt;
    - &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;targetPort&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
      &lt;span style=&#34;color:#75715e&#34;&gt;# 可选字段&lt;/span&gt;
      &lt;span style=&#34;color:#75715e&#34;&gt;# 默认情况下和为了方便，k8s 控制中心会在配置的端口范围(默认30000-32767) 内分配一个端口&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;nodePort&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;30007&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;!--
### Type LoadBalancer {#loadbalancer}

On cloud providers which support external load balancers, setting the `type`
field to `LoadBalancer` provisions a load balancer for your Service.
The actual creation of the load balancer happens asynchronously, and
information about the provisioned balancer is published in the Service&#39;s
`.status.loadBalancer` field.
For example:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  selector:
    app: MyApp
  ports:
    - protocol: TCP
      port: 80
      targetPort: 9376
  clusterIP: 10.0.171.239
  type: LoadBalancer
status:
  loadBalancer:
    ingress:
    - ip: 192.0.2.127
```

Traffic from the external load balancer is directed at the backend Pods. The cloud provider decides how it is load balanced.

For LoadBalancer type of Services, when there is more than one port defined, all
ports must have the same protocol and the protocol must be one of `TCP`, `UDP`,
and `SCTP`.

Some cloud providers allow you to specify the `loadBalancerIP`. In those cases, the load-balancer is created
with the user-specified `loadBalancerIP`. If the `loadBalancerIP` field is not specified,
the loadBalancer is set up with an ephemeral IP address. If you specify a `loadBalancerIP`
but your cloud provider does not support the feature, the `loadbalancerIP` field that you
set is ignored.

&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; If you&amp;rsquo;re using SCTP, see the &lt;a href=&#34;#caveat-sctp-loadbalancer-service-type&#34;&gt;caveat&lt;/a&gt; below about the
&lt;code&gt;LoadBalancer&lt;/code&gt; Service type.&lt;/div&gt;
&lt;/blockquote&gt;


&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; &lt;p&gt;On &lt;strong&gt;Azure&lt;/strong&gt;, if you want to use a user-specified public type &lt;code&gt;loadBalancerIP&lt;/code&gt;, you first need
to create a static type public IP address resource. This public IP address resource should
be in the same resource group of the other automatically created resources of the cluster.
For example, &lt;code&gt;MC_myResourceGroup_myAKSCluster_eastus&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Specify the assigned IP address as loadBalancerIP. Ensure that you have updated the securityGroupName in the cloud provider configuration file. For information about troubleshooting &lt;code&gt;CreatingLoadBalancerFailed&lt;/code&gt; permission issues see, &lt;a href=&#34;https://docs.microsoft.com/en-us/azure/aks/static-ip&#34;&gt;Use a static IP address with the Azure Kubernetes Service (AKS) load balancer&lt;/a&gt; or &lt;a href=&#34;https://github.com/Azure/AKS/issues/357&#34;&gt;CreatingLoadBalancerFailed on AKS cluster with advanced networking&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;

 --&gt;
&lt;h3 id=&#34;loadbalancer&#34;&gt;LoadBalancer&lt;/h3&gt;
&lt;p&gt;云提供商还支持外部的负载均衡器， 通过设置 &lt;code&gt;type&lt;/code&gt; 的值为 &lt;code&gt;LoadBalancer&lt;/code&gt; 为 Service 提供一个负载均衡器
实际上对负载均衡器的创建是异步的，关于添加的负载均衡器的信息会添加到 Service 的 &lt;code&gt;.status.loadBalancer&lt;/code&gt; 字段。&lt;/p&gt;
&lt;p&gt;例:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Service&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-service&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;selector&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;app&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;MyApp&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;ports&lt;/span&gt;:
    - &lt;span style=&#34;color:#f92672&#34;&gt;protocol&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;TCP&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;targetPort&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;9376&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;clusterIP&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;10.0.171.239&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;type&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;LoadBalancer&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;status&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;loadBalancer&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;ingress&lt;/span&gt;:
    - &lt;span style=&#34;color:#f92672&#34;&gt;ip&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;192.0.2.127&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;从外部负载均衡器进来的流量会直接转发到后端的 Pod上。 云提供商会决定负载均衡方式。&lt;/p&gt;
&lt;p&gt;对于 LoadBalancer 类型的 Service， 当一个 Service 上有不止一个端口时， 所以的端口必须要使用
相同的协议，并且协议只能是 &lt;code&gt;TCP&lt;/code&gt;, &lt;code&gt;UDP&lt;/code&gt;, &lt;code&gt;SCTP&lt;/code&gt; 中的一种.&lt;/p&gt;
&lt;p&gt;有些云提供商支持指定 &lt;code&gt;loadBalancerIP&lt;/code&gt;， 在这个情况下， 负载均衡是使用指定的 &lt;code&gt;loadBalancerIP&lt;/code&gt; 创建。
如果 &lt;code&gt;loadBalancerIP&lt;/code&gt; 没有指定则会使用一个临时 IP 地址。 如果指定了 &lt;code&gt;loadBalancerIP&lt;/code&gt;
但云提供商不支持该特性，则指定的 &lt;code&gt;loadbalancerIP&lt;/code&gt; 字段会被忽略。
&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; 如果使用的是 SCTP 协议，见下面的 &lt;a href=&#34;#caveat-sctp-loadbalancer-service-type&#34;&gt;caveat&lt;/a&gt; 关于 &lt;code&gt;LoadBalancer&lt;/code&gt;
Service 类型的相关信息&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/p&gt;
&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; &lt;p&gt;在 &lt;strong&gt;Azure&lt;/strong&gt; 上， 如果想要使用用户指定的 &lt;code&gt;loadBalancerIP&lt;/code&gt;， 首先需要创建一个静态类型的
公网 IP 地址资源。 这个公网 IP 地址资源应该与集群其它自动创建的资源在同一个资源组。
例如，&lt;code&gt;MC_myResourceGroup_myAKSCluster_eastus&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;通过 loadBalancerIP 指定分配 IP， 需要确保已经更新云提供商配置文件中的 securityGroupName。
更多 &lt;code&gt;CreatingLoadBalancerFailed&lt;/code&gt; 权限问题的调度信息见
&lt;a href=&#34;https://docs.microsoft.com/en-us/azure/aks/static-ip&#34;&gt;Use a static IP address with the Azure Kubernetes Service (AKS) load balancer&lt;/a&gt;
或
&lt;a href=&#34;https://github.com/Azure/AKS/issues/357&#34;&gt;CreatingLoadBalancerFailed on AKS cluster with advanced networking&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;

&lt;!--
#### Internal load balancer
In a mixed environment it is sometimes necessary to route traffic from Services inside the same
(virtual) network address block.

In a split-horizon DNS environment you would need two Services to be able to route both external and internal traffic to your endpoints.

You can achieve this by adding one the following annotations to a Service.
The annotation to add depends on the cloud Service provider you&#39;re using.

&lt;ul class=&#34;nav nav-tabs&#34; id=&#34;service_tabs&#34; role=&#34;tablist&#34;&gt;&lt;li class=&#34;nav-item&#34;&gt;&lt;a data-toggle=&#34;tab&#34; class=&#34;nav-link active&#34; href=&#34;#service_tabs-0&#34; role=&#34;tab&#34; aria-controls=&#34;service_tabs-0&#34; aria-selected=&#34;true&#34;&gt;Default&lt;/a&gt;&lt;/li&gt;
	  
		&lt;li class=&#34;nav-item&#34;&gt;&lt;a data-toggle=&#34;tab&#34; class=&#34;nav-link&#34; href=&#34;#service_tabs-1&#34; role=&#34;tab&#34; aria-controls=&#34;service_tabs-1&#34;&gt;GCP&lt;/a&gt;&lt;/li&gt;
		&lt;li class=&#34;nav-item&#34;&gt;&lt;a data-toggle=&#34;tab&#34; class=&#34;nav-link&#34; href=&#34;#service_tabs-2&#34; role=&#34;tab&#34; aria-controls=&#34;service_tabs-2&#34;&gt;AWS&lt;/a&gt;&lt;/li&gt;
		&lt;li class=&#34;nav-item&#34;&gt;&lt;a data-toggle=&#34;tab&#34; class=&#34;nav-link&#34; href=&#34;#service_tabs-3&#34; role=&#34;tab&#34; aria-controls=&#34;service_tabs-3&#34;&gt;Azure&lt;/a&gt;&lt;/li&gt;
		&lt;li class=&#34;nav-item&#34;&gt;&lt;a data-toggle=&#34;tab&#34; class=&#34;nav-link&#34; href=&#34;#service_tabs-4&#34; role=&#34;tab&#34; aria-controls=&#34;service_tabs-4&#34;&gt;IBM Cloud&lt;/a&gt;&lt;/li&gt;
		&lt;li class=&#34;nav-item&#34;&gt;&lt;a data-toggle=&#34;tab&#34; class=&#34;nav-link&#34; href=&#34;#service_tabs-5&#34; role=&#34;tab&#34; aria-controls=&#34;service_tabs-5&#34;&gt;OpenStack&lt;/a&gt;&lt;/li&gt;
		&lt;li class=&#34;nav-item&#34;&gt;&lt;a data-toggle=&#34;tab&#34; class=&#34;nav-link&#34; href=&#34;#service_tabs-6&#34; role=&#34;tab&#34; aria-controls=&#34;service_tabs-6&#34;&gt;Baidu Cloud&lt;/a&gt;&lt;/li&gt;
		&lt;li class=&#34;nav-item&#34;&gt;&lt;a data-toggle=&#34;tab&#34; class=&#34;nav-link&#34; href=&#34;#service_tabs-7&#34; role=&#34;tab&#34; aria-controls=&#34;service_tabs-7&#34;&gt;Tencent Cloud&lt;/a&gt;&lt;/li&gt;
		&lt;li class=&#34;nav-item&#34;&gt;&lt;a data-toggle=&#34;tab&#34; class=&#34;nav-link&#34; href=&#34;#service_tabs-8&#34; role=&#34;tab&#34; aria-controls=&#34;service_tabs-8&#34;&gt;Alibaba Cloud&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;div class=&#34;tab-content&#34; id=&#34;service_tabs&#34;&gt;&lt;div id=&#34;service_tabs-0&#34; class=&#34;tab-pane show active&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;service_tabs-0&#34;&gt;

&lt;p&gt;&lt;p&gt;Select one of the tabs.&lt;/p&gt;
&lt;/div&gt;
  &lt;div id=&#34;service_tabs-1&#34; class=&#34;tab-pane&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;service_tabs-1&#34;&gt;

&lt;p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;...]&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-service&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;annotations&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;cloud.google.com/load-balancer-type&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Internal&amp;#34;&lt;/span&gt;
[&lt;span style=&#34;color:#ae81ff&#34;&gt;...]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
  &lt;div id=&#34;service_tabs-2&#34; class=&#34;tab-pane&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;service_tabs-2&#34;&gt;

&lt;p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;...]&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-service&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;annotations&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;service.beta.kubernetes.io/aws-load-balancer-internal&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;true&amp;#34;&lt;/span&gt;
[&lt;span style=&#34;color:#ae81ff&#34;&gt;...]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
  &lt;div id=&#34;service_tabs-3&#34; class=&#34;tab-pane&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;service_tabs-3&#34;&gt;

&lt;p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;...]&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-service&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;annotations&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;service.beta.kubernetes.io/azure-load-balancer-internal&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;true&amp;#34;&lt;/span&gt;
[&lt;span style=&#34;color:#ae81ff&#34;&gt;...]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
  &lt;div id=&#34;service_tabs-4&#34; class=&#34;tab-pane&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;service_tabs-4&#34;&gt;

&lt;p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;...]&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-service&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;annotations&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;service.kubernetes.io/ibm-load-balancer-cloud-provider-ip-type&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;private&amp;#34;&lt;/span&gt;
[&lt;span style=&#34;color:#ae81ff&#34;&gt;...]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
  &lt;div id=&#34;service_tabs-5&#34; class=&#34;tab-pane&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;service_tabs-5&#34;&gt;

&lt;p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;...]&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-service&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;annotations&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;service.beta.kubernetes.io/openstack-internal-load-balancer&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;true&amp;#34;&lt;/span&gt;
[&lt;span style=&#34;color:#ae81ff&#34;&gt;...]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
  &lt;div id=&#34;service_tabs-6&#34; class=&#34;tab-pane&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;service_tabs-6&#34;&gt;

&lt;p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;...]&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-service&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;annotations&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;service.beta.kubernetes.io/cce-load-balancer-internal-vpc&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;true&amp;#34;&lt;/span&gt;
[&lt;span style=&#34;color:#ae81ff&#34;&gt;...]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
  &lt;div id=&#34;service_tabs-7&#34; class=&#34;tab-pane&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;service_tabs-7&#34;&gt;

&lt;p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;...]&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;annotations&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;service.kubernetes.io/qcloud-loadbalancer-internal-subnetid&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;subnet-xxxxx&lt;/span&gt;
[&lt;span style=&#34;color:#ae81ff&#34;&gt;...]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
  &lt;div id=&#34;service_tabs-8&#34; class=&#34;tab-pane&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;service_tabs-8&#34;&gt;

&lt;p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;...]&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;annotations&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;service.beta.kubernetes.io/alibaba-cloud-loadbalancer-address-type&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;intranet&amp;#34;&lt;/span&gt;
[&lt;span style=&#34;color:#ae81ff&#34;&gt;...]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;

 --&gt;
&lt;h4 id=&#34;内部负载均衡器&#34;&gt;内部负载均衡器&lt;/h4&gt;
&lt;p&gt;在一个混搭的环境中，有时候需要在同一个(虚拟)网络地址段从 Service 间路由流量。&lt;/p&gt;
&lt;p&gt;在一个水平分割的 DNS 环境，需要有两个 Service 才能够分别路由外部和内部的流量到 Endpoint.&lt;/p&gt;
&lt;p&gt;可以通过在 Service 上添加以下注解中的一个来达成这个目的。 添加哪个注解基于你用的云提供商。&lt;/p&gt;
&lt;ul class=&#34;nav nav-tabs&#34; id=&#34;service_tabs&#34; role=&#34;tablist&#34;&gt;&lt;li class=&#34;nav-item&#34;&gt;&lt;a data-toggle=&#34;tab&#34; class=&#34;nav-link active&#34; href=&#34;#service_tabs-0&#34; role=&#34;tab&#34; aria-controls=&#34;service_tabs-0&#34; aria-selected=&#34;true&#34;&gt;Default&lt;/a&gt;&lt;/li&gt;
	  
		&lt;li class=&#34;nav-item&#34;&gt;&lt;a data-toggle=&#34;tab&#34; class=&#34;nav-link&#34; href=&#34;#service_tabs-1&#34; role=&#34;tab&#34; aria-controls=&#34;service_tabs-1&#34;&gt;GCP&lt;/a&gt;&lt;/li&gt;
		&lt;li class=&#34;nav-item&#34;&gt;&lt;a data-toggle=&#34;tab&#34; class=&#34;nav-link&#34; href=&#34;#service_tabs-2&#34; role=&#34;tab&#34; aria-controls=&#34;service_tabs-2&#34;&gt;AWS&lt;/a&gt;&lt;/li&gt;
		&lt;li class=&#34;nav-item&#34;&gt;&lt;a data-toggle=&#34;tab&#34; class=&#34;nav-link&#34; href=&#34;#service_tabs-3&#34; role=&#34;tab&#34; aria-controls=&#34;service_tabs-3&#34;&gt;Azure&lt;/a&gt;&lt;/li&gt;
		&lt;li class=&#34;nav-item&#34;&gt;&lt;a data-toggle=&#34;tab&#34; class=&#34;nav-link&#34; href=&#34;#service_tabs-4&#34; role=&#34;tab&#34; aria-controls=&#34;service_tabs-4&#34;&gt;IBM Cloud&lt;/a&gt;&lt;/li&gt;
		&lt;li class=&#34;nav-item&#34;&gt;&lt;a data-toggle=&#34;tab&#34; class=&#34;nav-link&#34; href=&#34;#service_tabs-5&#34; role=&#34;tab&#34; aria-controls=&#34;service_tabs-5&#34;&gt;OpenStack&lt;/a&gt;&lt;/li&gt;
		&lt;li class=&#34;nav-item&#34;&gt;&lt;a data-toggle=&#34;tab&#34; class=&#34;nav-link&#34; href=&#34;#service_tabs-6&#34; role=&#34;tab&#34; aria-controls=&#34;service_tabs-6&#34;&gt;Baidu Cloud&lt;/a&gt;&lt;/li&gt;
		&lt;li class=&#34;nav-item&#34;&gt;&lt;a data-toggle=&#34;tab&#34; class=&#34;nav-link&#34; href=&#34;#service_tabs-7&#34; role=&#34;tab&#34; aria-controls=&#34;service_tabs-7&#34;&gt;Tencent Cloud&lt;/a&gt;&lt;/li&gt;
		&lt;li class=&#34;nav-item&#34;&gt;&lt;a data-toggle=&#34;tab&#34; class=&#34;nav-link&#34; href=&#34;#service_tabs-8&#34; role=&#34;tab&#34; aria-controls=&#34;service_tabs-8&#34;&gt;Alibaba Cloud&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
&lt;div class=&#34;tab-content&#34; id=&#34;service_tabs&#34;&gt;&lt;div id=&#34;service_tabs-0&#34; class=&#34;tab-pane show active&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;service_tabs-0&#34;&gt;

&lt;p&gt;&lt;p&gt;选择其中一个标签&lt;/p&gt;
&lt;/div&gt;
  &lt;div id=&#34;service_tabs-1&#34; class=&#34;tab-pane&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;service_tabs-1&#34;&gt;

&lt;p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;...]&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-service&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;annotations&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;cloud.google.com/load-balancer-type&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Internal&amp;#34;&lt;/span&gt;
[&lt;span style=&#34;color:#ae81ff&#34;&gt;...]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
  &lt;div id=&#34;service_tabs-2&#34; class=&#34;tab-pane&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;service_tabs-2&#34;&gt;

&lt;p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;...]&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-service&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;annotations&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;service.beta.kubernetes.io/aws-load-balancer-internal&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;true&amp;#34;&lt;/span&gt;
[&lt;span style=&#34;color:#ae81ff&#34;&gt;...]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
  &lt;div id=&#34;service_tabs-3&#34; class=&#34;tab-pane&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;service_tabs-3&#34;&gt;

&lt;p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;...]&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-service&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;annotations&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;service.beta.kubernetes.io/azure-load-balancer-internal&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;true&amp;#34;&lt;/span&gt;
[&lt;span style=&#34;color:#ae81ff&#34;&gt;...]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
  &lt;div id=&#34;service_tabs-4&#34; class=&#34;tab-pane&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;service_tabs-4&#34;&gt;

&lt;p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;...]&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-service&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;annotations&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;service.kubernetes.io/ibm-load-balancer-cloud-provider-ip-type&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;private&amp;#34;&lt;/span&gt;
[&lt;span style=&#34;color:#ae81ff&#34;&gt;...]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
  &lt;div id=&#34;service_tabs-5&#34; class=&#34;tab-pane&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;service_tabs-5&#34;&gt;

&lt;p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;...]&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-service&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;annotations&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;service.beta.kubernetes.io/openstack-internal-load-balancer&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;true&amp;#34;&lt;/span&gt;
[&lt;span style=&#34;color:#ae81ff&#34;&gt;...]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
  &lt;div id=&#34;service_tabs-6&#34; class=&#34;tab-pane&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;service_tabs-6&#34;&gt;

&lt;p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;...]&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-service&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;annotations&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;service.beta.kubernetes.io/cce-load-balancer-internal-vpc&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;true&amp;#34;&lt;/span&gt;
[&lt;span style=&#34;color:#ae81ff&#34;&gt;...]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
  &lt;div id=&#34;service_tabs-7&#34; class=&#34;tab-pane&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;service_tabs-7&#34;&gt;

&lt;p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;...]&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;annotations&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;service.kubernetes.io/qcloud-loadbalancer-internal-subnetid&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;subnet-xxxxx&lt;/span&gt;
[&lt;span style=&#34;color:#ae81ff&#34;&gt;...]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
  &lt;div id=&#34;service_tabs-8&#34; class=&#34;tab-pane&#34; role=&#34;tabpanel&#34; aria-labelledby=&#34;service_tabs-8&#34;&gt;

&lt;p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;...]&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;annotations&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;service.beta.kubernetes.io/alibaba-cloud-loadbalancer-address-type&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;intranet&amp;#34;&lt;/span&gt;
[&lt;span style=&#34;color:#ae81ff&#34;&gt;...]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;

&lt;!--
#### TLS support on AWS {#ssl-support-on-aws}

For partial TLS / SSL support on clusters running on AWS, you can add three
annotations to a `LoadBalancer` service:

```yaml
metadata:
  name: my-service
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-ssl-cert: arn:aws:acm:us-east-1:123456789012:certificate/12345678-1234-1234-1234-123456789012
```

The first specifies the ARN of the certificate to use. It can be either a
certificate from a third party issuer that was uploaded to IAM or one created
within AWS Certificate Manager.

```yaml
metadata:
  name: my-service
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-backend-protocol: (https|http|ssl|tcp)
```

The second annotation specifies which protocol a Pod speaks. For HTTPS and
SSL, the ELB expects the Pod to authenticate itself over the encrypted
connection, using a certificate.

HTTP and HTTPS selects layer 7 proxying: the ELB terminates
the connection with the user, parses headers, and injects the `X-Forwarded-For`
header with the user&#39;s IP address (Pods only see the IP address of the
ELB at the other end of its connection) when forwarding requests.

TCP and SSL selects layer 4 proxying: the ELB forwards traffic without
modifying the headers.

In a mixed-use environment where some ports are secured and others are left unencrypted,
you can use the following annotations:

```yaml
    metadata:
      name: my-service
      annotations:
        service.beta.kubernetes.io/aws-load-balancer-backend-protocol: http
        service.beta.kubernetes.io/aws-load-balancer-ssl-ports: &#34;443,8443&#34;
```

In the above example, if the Service contained three ports, `80`, `443`, and
`8443`, then `443` and `8443` would use the SSL certificate, but `80` would just
be proxied HTTP.

From Kubernetes v1.9 onwards you can use [predefined AWS SSL policies](https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-security-policy-table.html) with HTTPS or SSL listeners for your Services.
To see which policies are available for use, you can use the `aws` command line tool:

```bash
aws elb describe-load-balancer-policies --query &#39;PolicyDescriptions[].PolicyName&#39;
```

You can then specify any one of those policies using the
&#34;`service.beta.kubernetes.io/aws-load-balancer-ssl-negotiation-policy`&#34;
annotation; for example:

```yaml
    metadata:
      name: my-service
      annotations:
        service.beta.kubernetes.io/aws-load-balancer-ssl-negotiation-policy: &#34;ELBSecurityPolicy-TLS-1-2-2017-01&#34;
```
 --&gt;
&lt;h4 id=&#34;ssl-support-on-aws&#34;&gt;AWS 对 TLS 的支持&lt;/h4&gt;
&lt;p&gt;运行在 AWS 上的集群部分支持 TLS / SSL，可以添加以下三个注解到一个 &lt;code&gt;LoadBalancer&lt;/code&gt; 的 Service:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-service&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;annotations&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;service.beta.kubernetes.io/aws-load-balancer-ssl-cert&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;arn:aws:acm:us-east-1:123456789012:certificate/12345678-1234-1234-1234-123456789012&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;第一个指定 证书使用的 ARN。 可以是上传到  IAM 的第三方发行者的证书 或者是在 AWS 证书管理器创建的证书。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-service&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;annotations&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;service.beta.kubernetes.io/aws-load-balancer-backend-protocol&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;(https|http|ssl|tcp)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;connection, using a certificate.
第二个注解指定 Pod 使用的是哪个协议。 对于 HTTPS 和 SSL，负载均衡期望的是 Pod 使用证书的安全连接来认证它自己。&lt;/p&gt;
&lt;p&gt;HTTP 和 HTTPS 使用第 7 层代理: 转发请求是由负载均衡器来终止用户的连接，解析头，插入包含用户 IP 地址
的 &lt;code&gt;X-Forwarded-For&lt;/code&gt; 头(Pod 只能看到连接另一头的负载均衡的IP地址)&lt;/p&gt;
&lt;p&gt;TCP 和 SSL 使用 4 层代理: 负载均衡器转发流量是不会修改头信息&lt;/p&gt;
&lt;p&gt;在混搭环境中，有些端口是安全的有是又是未加密的，可以使用如下注解:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-service&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;annotations&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;service.beta.kubernetes.io/aws-load-balancer-backend-protocol&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;http&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;service.beta.kubernetes.io/aws-load-balancer-ssl-ports&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;443,8443&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在上面的例子中， 如果 Service 包含三个端口， &lt;code&gt;80&lt;/code&gt;, &lt;code&gt;443&lt;/code&gt;, &lt;code&gt;8443&lt;/code&gt;, 其中 &lt;code&gt;443&lt;/code&gt; 和 &lt;code&gt;8443&lt;/code&gt;
是使用 SSL 证书的，但 &lt;code&gt;80&lt;/code&gt; 只通过 HTTP 代理&lt;/p&gt;
&lt;p&gt;从 k8s v1.9 开始，可以使用
&lt;a href=&#34;https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-security-policy-table.html&#34;&gt;predefined AWS SSL policies&lt;/a&gt;
来配置 Service 的 HTTPS 或 SSL 监控器。
可以通过以下 aws 命令行工具来查看哪些可用的策略:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;aws elb describe-load-balancer-policies --query &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;PolicyDescriptions[].PolicyName&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;然后可以使
&amp;ldquo;&lt;code&gt;service.beta.kubernetes.io/aws-load-balancer-ssl-negotiation-policy&lt;/code&gt;&amp;rdquo;
注解来使用其中的某个策略，例:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-service&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;annotations&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;service.beta.kubernetes.io/aws-load-balancer-ssl-negotiation-policy&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ELBSecurityPolicy-TLS-1-2-2017-01&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;!--
#### PROXY protocol support on AWS

To enable [PROXY protocol](https://www.haproxy.org/download/1.8/doc/proxy-protocol.txt)
support for clusters running on AWS, you can use the following service
annotation:

```yaml
    metadata:
      name: my-service
      annotations:
        service.beta.kubernetes.io/aws-load-balancer-proxy-protocol: &#34;*&#34;
```

Since version 1.3.0, the use of this annotation applies to all ports proxied by the ELB
and cannot be configured otherwise. --&gt;
&lt;h4 id=&#34;aws-支持的-proxy-协议&#34;&gt;AWS 支持的 PROXY 协议&lt;/h4&gt;
&lt;p&gt;要在 AWS 运行的集群中启用 &lt;a href=&#34;https://www.haproxy.org/download/1.8/doc/proxy-protocol.txt&#34;&gt;PROXY protocol&lt;/a&gt;
可以在 Service 上添加以下注解:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-service&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;annotations&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;service.beta.kubernetes.io/aws-load-balancer-proxy-protocol&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;*&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;从 v1.3.0 开始，就只能通过这个注解来让所以的端口通过 ELB 代理，不能通过其它方式配置了。&lt;/p&gt;
&lt;!--
#### ELB Access Logs on AWS

There are several annotations to manage access logs for ELB Services on AWS.

The annotation `service.beta.kubernetes.io/aws-load-balancer-access-log-enabled`
controls whether access logs are enabled.

The annotation `service.beta.kubernetes.io/aws-load-balancer-access-log-emit-interval`
controls the interval in minutes for publishing the access logs. You can specify
an interval of either 5 or 60 minutes.

The annotation `service.beta.kubernetes.io/aws-load-balancer-access-log-s3-bucket-name`
controls the name of the Amazon S3 bucket where load balancer access logs are
stored.

The annotation `service.beta.kubernetes.io/aws-load-balancer-access-log-s3-bucket-prefix`
specifies the logical hierarchy you created for your Amazon S3 bucket.

```yaml
    metadata:
      name: my-service
      annotations:
        service.beta.kubernetes.io/aws-load-balancer-access-log-enabled: &#34;true&#34;
        # Specifies whether access logs are enabled for the load balancer
        service.beta.kubernetes.io/aws-load-balancer-access-log-emit-interval: &#34;60&#34;
        # The interval for publishing the access logs. You can specify an interval of either 5 or 60 (minutes).
        service.beta.kubernetes.io/aws-load-balancer-access-log-s3-bucket-name: &#34;my-bucket&#34;
        # The name of the Amazon S3 bucket where the access logs are stored
        service.beta.kubernetes.io/aws-load-balancer-access-log-s3-bucket-prefix: &#34;my-bucket-prefix/prod&#34;
        # The logical hierarchy you created for your Amazon S3 bucket, for example `my-bucket-prefix/prod`
```
 --&gt;
&lt;h4 id=&#34;aws-上-elb-的访问日志&#34;&gt;AWS 上 ELB 的访问日志&lt;/h4&gt;
&lt;p&gt;AWS 上 ELB 的访问日志 可以通过几个注解来管理。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;service.beta.kubernetes.io/aws-load-balancer-access-log-enabled&lt;/code&gt; 注解控制是否开启访问日志&lt;/p&gt;
&lt;p&gt;&lt;code&gt;service.beta.kubernetes.io/aws-load-balancer-access-log-emit-interval&lt;/code&gt; 注解控制发布
日志的时间间隔(单位为分钟)。 时间间隔可以是 5 分钟 或 60 分钟&lt;/p&gt;
&lt;p&gt;&lt;code&gt;service.beta.kubernetes.io/aws-load-balancer-access-log-s3-bucket-name&lt;/code&gt; 注解控制访问
日志存储的 Amazon S3 bucket 名称
&lt;code&gt;service.beta.kubernetes.io/aws-load-balancer-access-log-s3-bucket-prefix&lt;/code&gt; 注解
它指定创建的 Amazon S3 bucket 的逻辑层次&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-service&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;annotations&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;service.beta.kubernetes.io/aws-load-balancer-access-log-enabled&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;true&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#75715e&#34;&gt;# 否开启访问日志&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;service.beta.kubernetes.io/aws-load-balancer-access-log-emit-interval&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;60&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#75715e&#34;&gt;# 发布 日志的时间间隔(单位为分钟)。 时间间隔可以是 5 分钟 或 60 分钟&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;service.beta.kubernetes.io/aws-load-balancer-access-log-s3-bucket-name&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;my-bucket&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#75715e&#34;&gt;# 日志存储的 Amazon S3 bucket 名称&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;service.beta.kubernetes.io/aws-load-balancer-access-log-s3-bucket-prefix&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;my-bucket-prefix/prod&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#75715e&#34;&gt;# 创建的 Amazon S3 bucket 的逻辑层次, 例如 `my-bucket-prefix/prod`&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;!--
#### Connection Draining on AWS

Connection draining for Classic ELBs can be managed with the annotation
`service.beta.kubernetes.io/aws-load-balancer-connection-draining-enabled` set
to the value of `&#34;true&#34;`. The annotation
`service.beta.kubernetes.io/aws-load-balancer-connection-draining-timeout` can
also be used to set maximum time, in seconds, to keep the existing connections open before deregistering the instances.


```yaml
    metadata:
      name: my-service
      annotations:
        service.beta.kubernetes.io/aws-load-balancer-connection-draining-enabled: &#34;true&#34;
        service.beta.kubernetes.io/aws-load-balancer-connection-draining-timeout: &#34;60&#34;
``` --&gt;
&lt;h4 id=&#34;aws-连接控制&#34;&gt;AWS 连接控制&lt;/h4&gt;
&lt;p&gt;经典ELB 的连接使用可以通过将注解
&lt;code&gt;service.beta.kubernetes.io/aws-load-balancer-connection-draining-enabled&lt;/code&gt;
的值设置为 &lt;code&gt;&amp;quot;true&amp;quot;&lt;/code&gt; 来管理。
还可以通过注解
&lt;code&gt;service.beta.kubernetes.io/aws-load-balancer-connection-draining-timeout&lt;/code&gt;
也可以用来设置保证已有连接的最大时间(单位秒)，&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-service&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;annotations&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;service.beta.kubernetes.io/aws-load-balancer-connection-draining-enabled&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;true&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;service.beta.kubernetes.io/aws-load-balancer-connection-draining-timeout&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;60&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;!--
#### Other ELB annotations

There are other annotations to manage Classic Elastic Load Balancers that are described below.

```yaml
    metadata:
      name: my-service
      annotations:
        service.beta.kubernetes.io/aws-load-balancer-connection-idle-timeout: &#34;60&#34;
        # The time, in seconds, that the connection is allowed to be idle (no data has been sent over the connection) before it is closed by the load balancer

        service.beta.kubernetes.io/aws-load-balancer-cross-zone-load-balancing-enabled: &#34;true&#34;
        # Specifies whether cross-zone load balancing is enabled for the load balancer

        service.beta.kubernetes.io/aws-load-balancer-additional-resource-tags: &#34;environment=prod,owner=devops&#34;
        # A comma-separated list of key-value pairs which will be recorded as
        # additional tags in the ELB.

        service.beta.kubernetes.io/aws-load-balancer-healthcheck-healthy-threshold: &#34;&#34;
        # The number of successive successful health checks required for a backend to
        # be considered healthy for traffic. Defaults to 2, must be between 2 and 10

        service.beta.kubernetes.io/aws-load-balancer-healthcheck-unhealthy-threshold: &#34;3&#34;
        # The number of unsuccessful health checks required for a backend to be
        # considered unhealthy for traffic. Defaults to 6, must be between 2 and 10

        service.beta.kubernetes.io/aws-load-balancer-healthcheck-interval: &#34;20&#34;
        # The approximate interval, in seconds, between health checks of an
        # individual instance. Defaults to 10, must be between 5 and 300

        service.beta.kubernetes.io/aws-load-balancer-healthcheck-timeout: &#34;5&#34;
        # The amount of time, in seconds, during which no response means a failed
        # health check. This value must be less than the service.beta.kubernetes.io/aws-load-balancer-healthcheck-interval
        # value. Defaults to 5, must be between 2 and 60

        service.beta.kubernetes.io/aws-load-balancer-extra-security-groups: &#34;sg-53fae93f,sg-42efd82e&#34;
        # A list of additional security groups to be added to the ELB

        service.beta.kubernetes.io/aws-load-balancer-target-node-labels: &#34;ingress-gw,gw-name=public-api&#34;
        # A comma separated list of key-value pairs which are used
        # to select the target nodes for the load balancer
```
 --&gt;
&lt;h4 id=&#34;elb-其它注解&#34;&gt;ELB 其它注解&lt;/h4&gt;
&lt;p&gt;以下介绍管理经典弹性负载均衡器的其它注解.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-service&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;annotations&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;service.beta.kubernetes.io/aws-load-balancer-connection-idle-timeout&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;60&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#75715e&#34;&gt;# 连接在被负载均衡关闭前允许空闲(没有从连接发送数据)的时间，单位秒&lt;/span&gt;

        &lt;span style=&#34;color:#f92672&#34;&gt;service.beta.kubernetes.io/aws-load-balancer-cross-zone-load-balancing-enabled&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;true&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#75715e&#34;&gt;# 指定负载均衡器是否开启跨区负载均衡&lt;/span&gt;

        &lt;span style=&#34;color:#f92672&#34;&gt;service.beta.kubernetes.io/aws-load-balancer-additional-resource-tags&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;environment=prod,owner=devops&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#75715e&#34;&gt;# 一个以逗号分隔的键值对列表，用于记在 ELB 中的额外标签&lt;/span&gt;

        &lt;span style=&#34;color:#f92672&#34;&gt;service.beta.kubernetes.io/aws-load-balancer-healthcheck-healthy-threshold&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#75715e&#34;&gt;# 一个后端服务实例被认为是健康可以处理流量所需要的成功健康检查次数，默认为 2， 只能在 2 到 10 之间&lt;/span&gt;

        &lt;span style=&#34;color:#f92672&#34;&gt;service.beta.kubernetes.io/aws-load-balancer-healthcheck-unhealthy-threshold&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;3&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#75715e&#34;&gt;# 一个后端服务实例被认为是不健康不能处理流量需要的失败的健康检查次数， 默认为 6， 必须在 2 到 10 之间&lt;/span&gt;

        &lt;span style=&#34;color:#f92672&#34;&gt;service.beta.kubernetes.io/aws-load-balancer-healthcheck-interval&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;20&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#75715e&#34;&gt;# 针对每个独立实例进行健康检查的时间间隔，单位秒，默认为 10， 必须在 5 到 300 之间&lt;/span&gt;

        &lt;span style=&#34;color:#f92672&#34;&gt;service.beta.kubernetes.io/aws-load-balancer-healthcheck-timeout&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;5&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#75715e&#34;&gt;# 如果在这个时间(单位秒)内健康检查没有响应，则认为检测结果为失败。这个值必须小于&lt;/span&gt;
        &lt;span style=&#34;color:#75715e&#34;&gt;# service.beta.kubernetes.io/aws-load-balancer-healthcheck-interval 的值&lt;/span&gt;
        &lt;span style=&#34;color:#75715e&#34;&gt;# 默认为 5， 必须在 2 到 10 之间。&lt;/span&gt;

        &lt;span style=&#34;color:#f92672&#34;&gt;service.beta.kubernetes.io/aws-load-balancer-extra-security-groups&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;sg-53fae93f,sg-42efd82e&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#75715e&#34;&gt;# 被添加到 ELB 的额外的安全组列表&lt;/span&gt;

        &lt;span style=&#34;color:#f92672&#34;&gt;service.beta.kubernetes.io/aws-load-balancer-target-node-labels&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ingress-gw,gw-name=public-api&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#75715e&#34;&gt;# 一个以逗号分隔的键值对列表，用于选择负载均衡的节点&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;!--
#### Network Load Balancer support on AWS {#aws-nlb-support}






&lt;div style=&#34;margin-top: 10px; margin-bottom: 10px;&#34;&gt;
&lt;b&gt;功能特性状态:&lt;/b&gt; &lt;code&gt;Kubernetes v1.15 [beta]&lt;/code&gt;
&lt;/div&gt;



To use a Network Load Balancer on AWS, use the annotation `service.beta.kubernetes.io/aws-load-balancer-type` with the value set to `nlb`.

```yaml
    metadata:
      name: my-service
      annotations:
        service.beta.kubernetes.io/aws-load-balancer-type: &#34;nlb&#34;
```

&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; NLB only works with certain instance classes; see the &lt;a href=&#34;https://docs.aws.amazon.com/elasticloadbalancing/latest/network/target-group-register-targets.html#register-deregister-targets&#34;&gt;AWS documentation&lt;/a&gt;
on Elastic Load Balancing for a list of supported instance types.&lt;/div&gt;
&lt;/blockquote&gt;


Unlike Classic Elastic Load Balancers, Network Load Balancers (NLBs) forward the
client&#39;s IP address through to the node. If a Service&#39;s `.spec.externalTrafficPolicy`
is set to `Cluster`, the client&#39;s IP address is not propagated to the end
Pods.

By setting `.spec.externalTrafficPolicy` to `Local`, the client IP addresses is
propagated to the end Pods, but this could result in uneven distribution of
traffic. Nodes without any Pods for a particular LoadBalancer Service will fail
the NLB Target Group&#39;s health check on the auto-assigned
`.spec.healthCheckNodePort` and not receive any traffic.

In order to achieve even traffic, either use a DaemonSet or specify a
[pod anti-affinity](/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity)
to not locate on the same node.

You can also use NLB Services with the [internal load balancer](/docs/concepts/services-networking/service/#internal-load-balancer)
annotation.

In order for client traffic to reach instances behind an NLB, the Node security
groups are modified with the following IP rules:

| Rule | Protocol | Port(s) | IpRange(s) | IpRange Description |
|------|----------|---------|------------|---------------------|
| Health Check | TCP | NodePort(s) (`.spec.healthCheckNodePort` for `.spec.externalTrafficPolicy = Local`) | VPC CIDR | kubernetes.io/rule/nlb/health=\&lt;loadBalancerName\&gt; |
| Client Traffic | TCP | NodePort(s) | `.spec.loadBalancerSourceRanges` (defaults to `0.0.0.0/0`) | kubernetes.io/rule/nlb/client=\&lt;loadBalancerName\&gt; |
| MTU Discovery | ICMP | 3,4 | `.spec.loadBalancerSourceRanges` (defaults to `0.0.0.0/0`) | kubernetes.io/rule/nlb/mtu=\&lt;loadBalancerName\&gt; |

In order to limit which client IP&#39;s can access the Network Load Balancer,
specify `loadBalancerSourceRanges`.

```yaml
spec:
  loadBalancerSourceRanges:
    - &#34;143.231.0.0/16&#34;
```

&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; If &lt;code&gt;.spec.loadBalancerSourceRanges&lt;/code&gt; is not set, Kubernetes
allows traffic from &lt;code&gt;0.0.0.0/0&lt;/code&gt; to the Node Security Group(s). If nodes have
public IP addresses, be aware that non-NLB traffic can also reach all instances
in those modified security groups.&lt;/div&gt;
&lt;/blockquote&gt;

 --&gt;
&lt;h4 id=&#34;aws-nlb-support&#34;&gt;AWS 上支持的网络负载均衡(NLB)&lt;/h4&gt;





&lt;div style=&#34;margin-top: 10px; margin-bottom: 10px;&#34;&gt;
&lt;b&gt;功能特性状态:&lt;/b&gt; &lt;code&gt;Kubernetes v1.15 [beta]&lt;/code&gt;
&lt;/div&gt;


&lt;p&gt;要使用 AWS 上的网络负载均衡器，使用注解 &lt;code&gt;service.beta.kubernetes.io/aws-load-balancer-type&lt;/code&gt;
设置值为 &lt;code&gt;nlb&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-service&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;annotations&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;service.beta.kubernetes.io/aws-load-balancer-type&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;nlb&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; NLB 只适用的特定类型的实例，ELB 支持的实例类型见
&lt;a href=&#34;https://docs.aws.amazon.com/elasticloadbalancing/latest/network/target-group-register-targets.html#register-deregister-targets&#34;&gt;AWS 文档&lt;/a&gt;&lt;/div&gt;
&lt;/blockquote&gt;

&lt;p&gt;与经典 ELB 不同， NLB 转发的客户端 IP 地址穿透节点。 如果 Service 的
&lt;code&gt;.spec.externalTrafficPolicy&lt;/code&gt; 设置为 &lt;code&gt;Cluster&lt;/code&gt;， 客户端 IP 地址不会传递到最终的 Pod。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;.spec.healthCheckNodePort&lt;/code&gt; and not receive any traffic.
通过设置 &lt;code&gt;.spec.externalTrafficPolicy&lt;/code&gt; 为 &lt;code&gt;Local&lt;/code&gt;， 客户端 IP 地址会传递到最终的 Pod。
但这会导向流量分发不均衡。 没有包含该负载均衡器对应 Service 的 Pod 的节点，会在 NLB 目标组
健康检查时分配的 &lt;code&gt;.spec.healthCheckNodePort&lt;/code&gt; 检查失败。 并不会收到任何流量&lt;/p&gt;
&lt;p&gt;为了达成平衡的负载，要么使用 DaemonSet，要么设置
&lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity&#34;&gt;pod anti-affinity&lt;/a&gt;
让 Pod 不要调度到同一个节点上&lt;/p&gt;
&lt;p&gt;也可以在使用 NLB Service 时在其中包含
&lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/docs/concepts/services-networking/service/#internal-load-balancer&#34;&gt;内部负载均衡器&lt;/a&gt;
注解&lt;/p&gt;
&lt;p&gt;为了能让客户端流量到达 NLB 后面的实例。 节点安全组需要以以下 IP 规则进行修改:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Rule&lt;/th&gt;
&lt;th&gt;Protocol&lt;/th&gt;
&lt;th&gt;Port(s)&lt;/th&gt;
&lt;th&gt;IpRange(s)&lt;/th&gt;
&lt;th&gt;IpRange Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Health Check&lt;/td&gt;
&lt;td&gt;TCP&lt;/td&gt;
&lt;td&gt;NodePort(s) (&lt;code&gt;.spec.healthCheckNodePort&lt;/code&gt; for &lt;code&gt;.spec.externalTrafficPolicy = Local&lt;/code&gt;)&lt;/td&gt;
&lt;td&gt;VPC CIDR&lt;/td&gt;
&lt;td&gt;kubernetes.io/rule/nlb/health=&amp;lt;loadBalancerName&amp;gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Client Traffic&lt;/td&gt;
&lt;td&gt;TCP&lt;/td&gt;
&lt;td&gt;NodePort(s)&lt;/td&gt;
&lt;td&gt;&lt;code&gt;.spec.loadBalancerSourceRanges&lt;/code&gt; (defaults to &lt;code&gt;0.0.0.0/0&lt;/code&gt;)&lt;/td&gt;
&lt;td&gt;kubernetes.io/rule/nlb/client=&amp;lt;loadBalancerName&amp;gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;MTU Discovery&lt;/td&gt;
&lt;td&gt;ICMP&lt;/td&gt;
&lt;td&gt;3,4&lt;/td&gt;
&lt;td&gt;&lt;code&gt;.spec.loadBalancerSourceRanges&lt;/code&gt; (defaults to &lt;code&gt;0.0.0.0/0&lt;/code&gt;)&lt;/td&gt;
&lt;td&gt;kubernetes.io/rule/nlb/mtu=&amp;lt;loadBalancerName&amp;gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;为限所哪个客户端 IP 可以访问 NLB， 指定 &lt;code&gt;loadBalancerSourceRanges&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;loadBalancerSourceRanges&lt;/span&gt;:
    - &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;143.231.0.0/16&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; 如果 &lt;code&gt;.spec.loadBalancerSourceRanges&lt;/code&gt; 没有设置，k8s 允许来自 &lt;code&gt;0.0.0.0/0&lt;/code&gt; 流量到节点安全组。
如果节点有公网 IP 地址，要注意那些非 NLB 流量也会到达所有这些修改过的安全组。&lt;/div&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;div&gt;&lt;strong&gt;TODO: &lt;/strong&gt;对 AWS 使用不熟悉，需要实践理解后再考虑怎么修改&lt;/div&gt;
&lt;/blockquote&gt;

&lt;!--
#### Other CLB annotations on Tencent Kubernetes Engine (TKE)

There are other annotations for managing Cloud Load Balancers on TKE as shown below.

```yaml
    metadata:
      name: my-service
      annotations:
        # Bind Loadbalancers with specified nodes
        service.kubernetes.io/qcloud-loadbalancer-backends-label: key in (value1, value2)

        # ID of an existing load balancer
        service.kubernetes.io/tke-existed-lbid：lb-6swtxxxx

        # Custom parameters for the load balancer (LB), does not support modification of LB type yet
        service.kubernetes.io/service.extensiveParameters: &#34;&#34;

        # Custom parameters for the LB listener
        service.kubernetes.io/service.listenerParameters: &#34;&#34;

        # Specifies the type of Load balancer;
        # valid values: classic (Classic Cloud Load Balancer) or application (Application Cloud Load Balancer)
        service.kubernetes.io/loadbalance-type: xxxxx

        # Specifies the public network bandwidth billing method;
        # valid values: TRAFFIC_POSTPAID_BY_HOUR(bill-by-traffic) and BANDWIDTH_POSTPAID_BY_HOUR (bill-by-bandwidth).
        service.kubernetes.io/qcloud-loadbalancer-internet-charge-type: xxxxxx

        # Specifies the bandwidth value (value range: [1,2000] Mbps).
        service.kubernetes.io/qcloud-loadbalancer-internet-max-bandwidth-out: &#34;10&#34;

        # When this annotation is set，the loadbalancers will only register nodes
        # with pod running on it, otherwise all nodes will be registered.
        service.kubernetes.io/local-svc-only-bind-node-with-pod: true
```
 --&gt;
&lt;h4 id=&#34;tencent-kubernetes-engine-tke-上其它-clb-注解&#34;&gt;Tencent Kubernetes Engine (TKE) 上其它 CLB 注解&lt;/h4&gt;
&lt;p&gt;以下为管理 TKE 上 CLB 的其它注解说明。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-service&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;annotations&lt;/span&gt;:
        &lt;span style=&#34;color:#75715e&#34;&gt;# 将 负载均衡器与指定节点绑定&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;service.kubernetes.io/qcloud-loadbalancer-backends-label&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;key in (value1, value2)&lt;/span&gt;

        &lt;span style=&#34;color:#75715e&#34;&gt;# 已经存在的负载均衡器的 ID&lt;/span&gt;
        &lt;span style=&#34;color:#ae81ff&#34;&gt;service.kubernetes.io/tke-existed-lbid：lb-6swtxxxx&lt;/span&gt;

        &lt;span style=&#34;color:#75715e&#34;&gt;# Custom parameters for the load balancer (LB), does not support modification of LB type yet&lt;/span&gt;
        &lt;span style=&#34;color:#75715e&#34;&gt;# 负载均衡器的自定义参数， 还不支持对负载均衡类型的修改&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;service.kubernetes.io/service.extensiveParameters&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;

        &lt;span style=&#34;color:#75715e&#34;&gt;# Custom parameters for the LB listener&lt;/span&gt;
        &lt;span style=&#34;color:#75715e&#34;&gt;# 负载均衡监听器的自定义参数&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;service.kubernetes.io/service.listenerParameters&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;

        &lt;span style=&#34;color:#75715e&#34;&gt;# 设置负载均衡器的类型&lt;/span&gt;
        &lt;span style=&#34;color:#75715e&#34;&gt;# 有效值为: classic (Classic Cloud Load Balancer) 或  application (Application Cloud Load Balancer)&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;service.kubernetes.io/loadbalance-type&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;xxxxx&lt;/span&gt;

        &lt;span style=&#34;color:#75715e&#34;&gt;# 设置公网带宽收费方式&lt;/span&gt;
        &lt;span style=&#34;color:#75715e&#34;&gt;# 有效值为: TRAFFIC_POSTPAID_BY_HOUR(bill-by-traffic) 或 BANDWIDTH_POSTPAID_BY_HOUR (bill-by-bandwidth).&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;service.kubernetes.io/qcloud-loadbalancer-internet-charge-type&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;xxxxxx&lt;/span&gt;

        &lt;span style=&#34;color:#75715e&#34;&gt;# 设置带宽的值(范围: [1,2000] Mbps)&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;service.kubernetes.io/qcloud-loadbalancer-internet-max-bandwidth-out&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;10&amp;#34;&lt;/span&gt;

        &lt;span style=&#34;color:#75715e&#34;&gt;# 当这个注解被设置，负载均衡器只会注册有 Pod 在上面运行的节点，否则所有节点都会注册&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;service.kubernetes.io/local-svc-only-bind-node-with-pod&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;true&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;!--
### Type ExternalName {#externalname}

Services of type ExternalName map a Service to a DNS name, not to a typical selector such as
`my-service` or `cassandra`. You specify these Services with the `spec.externalName` parameter.

This Service definition, for example, maps
the `my-service` Service in the `prod` namespace to `my.database.example.com`:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-service
  namespace: prod
spec:
  type: ExternalName
  externalName: my.database.example.com
```
&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; ExternalName accepts an IPv4 address string, but as a DNS names comprised of digits, not as an IP address. ExternalNames that resemble IPv4 addresses are not resolved by CoreDNS or ingress-nginx because ExternalName
is intended to specify a canonical DNS name. To hardcode an IP address, consider using
&lt;a href=&#34;#headless-services&#34;&gt;headless Services&lt;/a&gt;.&lt;/div&gt;
&lt;/blockquote&gt;


When looking up the host `my-service.prod.svc.cluster.local`, the cluster DNS Service
returns a `CNAME` record with the value `my.database.example.com`. Accessing
`my-service` works in the same way as other Services but with the crucial
difference that redirection happens at the DNS level rather than via proxying or
forwarding. Should you later decide to move your database into your cluster, you
can start its Pods, add appropriate selectors or endpoints, and change the
Service&#39;s `type`.

&lt;blockquote class=&#34;warning&#34;&gt;
  &lt;div&gt;&lt;strong&gt;警告：&lt;/strong&gt; &lt;p&gt;You may have trouble using ExternalName for some common protocols, including HTTP and HTTPS. If you use ExternalName then the hostname used by clients inside your cluster is different from the name that the ExternalName references.&lt;/p&gt;
&lt;p&gt;For protocols that use hostnames this difference may lead to errors or unexpected responses. HTTP requests will have a &lt;code&gt;Host:&lt;/code&gt; header that the origin server does not recognize; TLS servers will not be able to provide a certificate matching the hostname that the client connected to.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;


&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; This section is indebted to the &lt;a href=&#34;https://akomljen.com/kubernetes-tips-part-1/&#34;&gt;Kubernetes Tips - Part
1&lt;/a&gt; blog post from &lt;a href=&#34;https://akomljen.com/&#34;&gt;Alen Komljen&lt;/a&gt;.&lt;/div&gt;
&lt;/blockquote&gt;

 --&gt;
&lt;h3 id=&#34;externalname&#34;&gt;ExternalName&lt;/h3&gt;
&lt;p&gt;ExternalName 类型的 Service 将 Service 映射到一个 DNS 名称， 而不是一个常见的选择器，如
&lt;code&gt;my-service&lt;/code&gt; 或 &lt;code&gt;cassandra&lt;/code&gt;. 通过 Service &lt;code&gt;spec.externalName&lt;/code&gt; 字段设置 DNS 名称。&lt;/p&gt;
&lt;p&gt;以面示例配置中将在 &lt;code&gt;prod&lt;/code&gt; 命名空间中一个名叫 &lt;code&gt;my-service&lt;/code&gt; 的 Service 映射到 &lt;code&gt;my.database.example.com&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Service&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-service&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;namespace&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;prod&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;type&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;ExternalName&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;externalName&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my.database.example.com&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; ExternalName 可以使用一个 IPv4 地址的字符串， 但是会被当作一个由数字组成的 DNS 名称，而不是
一个 IP 地址。 ExternalName 值与 IPv4 地址相似的不会被 CoreDNS 或 ingress-nginx 解析，
因为 ExternalName 在设计上就是用作一个标准的 DNS 名称的。 如果要硬编码一个 IP 地址，
考虑使用 &lt;a href=&#34;#headless-services&#34;&gt;无头 Services&lt;/a&gt;&lt;/div&gt;
&lt;/blockquote&gt;

&lt;p&gt;当查询主机名 &lt;code&gt;my-service.prod.svc.cluster.local&lt;/code&gt; 时， 集群 DNS 服务会返回一个 &lt;code&gt;CNAME&lt;/code&gt;
记录，值为 &lt;code&gt;my.database.example.com&lt;/code&gt;. 访问 &lt;code&gt;my-service&lt;/code&gt; 的效果与访问其它的 Service 一样，
关键不同点在于重定义发生在 DNS 层， 而不是通过代理或转发。 如果用户决定以后会将数据库移到集群内，
就可以先启动 Pod， 再添加恰当 的 选择器 或 Endpoint, 再修改 Service 的类型就完成迁移了，而客户端不会有感知。&lt;/p&gt;
&lt;blockquote class=&#34;warning&#34;&gt;
  &lt;div&gt;&lt;strong&gt;警告：&lt;/strong&gt; 那么集群内客户端使用的主机名与 ExternalName 所引用的名称必然是不一样的。
对于使用主机名的协议，这个不同可能会导致错误或意外的响应。 HTTP 请求会有一个 &lt;code&gt;Host:&lt;/code&gt; 头，原始
的服务会认不得。 TLS 服务也不能提供客户端连接主机名匹配的证书。&lt;/div&gt;
&lt;/blockquote&gt;

&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; 这节感谢
&lt;a href=&#34;https://akomljen.com/&#34;&gt;Alen Komljen&lt;/a&gt;
的博客
&lt;a href=&#34;https://akomljen.com/kubernetes-tips-part-1/&#34;&gt;Kubernetes Tips - Part 1&lt;/a&gt;&lt;/div&gt;
&lt;/blockquote&gt;

&lt;!--
### External IPs

If there are external IPs that route to one or more cluster nodes, Kubernetes Services can be exposed on those
`externalIPs`. Traffic that ingresses into the cluster with the external IP (as destination IP), on the Service port,
will be routed to one of the Service endpoints. `externalIPs` are not managed by Kubernetes and are the responsibility
of the cluster administrator.

In the Service spec, `externalIPs` can be specified along with any of the `ServiceTypes`.
In the example below, &#34;`my-service`&#34; can be accessed by clients on &#34;`80.11.12.10:80`&#34; (`externalIP:port`)

```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  selector:
    app: MyApp
  ports:
    - name: http
      protocol: TCP
      port: 80
      targetPort: 9376
  externalIPs:
    - 80.11.12.10
```
 --&gt;
&lt;h3 id=&#34;外部-ip&#34;&gt;外部 IP&lt;/h3&gt;
&lt;p&gt;如果有外部IP 能够路由到集群的一个或多个节点， k8s Service 可以通过这些 &lt;code&gt;externalIPs&lt;/code&gt; 来对外暴露。
通过外部IP(作为目标IP)的流量进入集群，到 Service 的端口，会被路由到一个 Service 的 Endpoint
上。 &lt;code&gt;externalIPs&lt;/code&gt; 不是由 k8s 管理的，这是集群管理员负责的。&lt;/p&gt;
&lt;p&gt;在 Service 中，&lt;code&gt;externalIPs&lt;/code&gt; 可以用在任意  &lt;code&gt;ServiceTypes&lt;/code&gt; 的 Service 上。 在下面的示例中
客户端可以通过 &lt;code&gt;80.11.12.10:80&lt;/code&gt; (&lt;code&gt;externalIP:port&lt;/code&gt;) 访问 &lt;code&gt;my-service&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Service&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-service&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;selector&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;app&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;MyApp&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;ports&lt;/span&gt;:
    - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;http&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;protocol&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;TCP&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;targetPort&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;9376&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;externalIPs&lt;/span&gt;:
    - &lt;span style=&#34;color:#ae81ff&#34;&gt;80.11.12.10&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;!--
## Shortcomings

Using the userspace proxy for VIPs, work at small to medium scale, but will
not scale to very large clusters with thousands of Services.  The
[original design proposal for portals](https://github.com/kubernetes/kubernetes/issues/1107)
has more details on this.

Using the userspace proxy obscures the source IP address of a packet accessing
a Service.
This makes some kinds of network filtering (firewalling) impossible.  The iptables
proxy mode does not
obscure in-cluster source IPs, but it does still impact clients coming through
a load balancer or node-port.

The `Type` field is designed as nested functionality - each level adds to the
previous.  This is not strictly required on all cloud providers (e.g. Google Compute Engine does
not need to allocate a `NodePort` to make `LoadBalancer` work, but AWS does)
but the current API requires it.
 --&gt;
&lt;h2 id=&#34;缺陷&#34;&gt;缺陷&lt;/h2&gt;
&lt;p&gt;使用 userspace 代理的 VIP，只适用于中小规模，但不适用于有上千 Service 的大规模集群。
更多细节见
&lt;a href=&#34;https://github.com/kubernetes/kubernetes/issues/1107&#34;&gt;original design proposal for portals&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;使用 userspace 代理会吃掉进入 Service 的包的源 IP 地址。 这会使得某些类型的网络过虑(防火墙)
变得不可能， iptables 代理模式不会吃掉进入集群的源 IP 地址，但依然与来自负载均衡或 NodePort
的客户端有冲突。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Type&lt;/code&gt; 在设计上是可以嵌套的，每一级添加到前一级上。 但这不是所有的云提供商都严格必须要的(例如
GCE 就不会分配一个 &lt;code&gt;NodePort&lt;/code&gt; 来让 &lt;code&gt;LoadBalancer&lt;/code&gt; 工作，但 AWS 又是需要的)但目前的
API请求必须得有它&lt;/p&gt;
&lt;!--
## Virtual IP implementation {#the-gory-details-of-virtual-ips}

The previous information should be sufficient for many people who just want to
use Services.  However, there is a lot going on behind the scenes that may be
worth understanding.
 --&gt;
&lt;h2 id=&#34;the-gory-details-of-virtual-ips&#34;&gt;虚拟 IP 的实现&lt;/h2&gt;
&lt;p&gt;The previous information should be sufficient for many people who just want to
use Services.  However, there is a lot going on behind the scenes that may be
worth understanding.
之间的信息对于许多只想用 Service 的用户来说已经足够了。但是这些信息之下还有许多值得理解的东西。&lt;/p&gt;
&lt;!--
### Avoiding collisions

One of the primary philosophies of Kubernetes is that you should not be
exposed to situations that could cause your actions to fail through no fault
of your own. For the design of the Service resource, this means not making
you choose your own port number if that choice might collide with
someone else&#39;s choice.  That is an isolation failure.

In order to allow you to choose a port number for your Services, we must
ensure that no two Services can collide. Kubernetes does that by allocating each
Service its own IP address.

To ensure each Service receives a unique IP, an internal allocator atomically
updates a global allocation map in &lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/docs/tasks/administer-cluster/configure-upgrade-etcd/&#39; target=&#39;_blank&#39;&gt;etcd&lt;span class=&#39;tooltip-text&#39;&gt;用来存储 k8s 所有集群数据的一致性和高可用键值存储&lt;/span&gt;
&lt;/a&gt;
prior to creating each Service. The map object must exist in the registry for
Services to get IP address assignments, otherwise creations will
fail with a message indicating an IP address could not be allocated.

In the control plane, a background controller is responsible for creating that
map (needed to support migrating from older versions of Kubernetes that used
in-memory locking). Kubernetes also uses controllers to check for invalid
assignments (eg due to administrator intervention) and for cleaning up allocated
IP addresses that are no longer used by any Services.
 --&gt;
&lt;h3 id=&#34;避免冲突&#34;&gt;避免冲突&lt;/h3&gt;
&lt;p&gt;k8s 一个主要的宗旨就是让用户不是因为自己的错误而引起出错， 就拿 Service 资源的设计来说，就是如果
你选择的端口可能与别人选择的端口可能冲突，则不你来选择这个端口。 这是一种故障隔离。&lt;/p&gt;
&lt;p&gt;为了允许用户为 Service  选择一个端口，我们必须要确保不能有两个 Service 端口冲突。k8s 通过为每
个 Service 分配 IP 地址来避免这个问题。&lt;/p&gt;
&lt;p&gt;为了保证每个 Service 接收的 IP 地址都是唯一的，在创建每个 Service 之间一个内部分配器原子地
在 &lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/docs/tasks/administer-cluster/configure-upgrade-etcd/&#39; target=&#39;_blank&#39;&gt;etcd&lt;span class=&#39;tooltip-text&#39;&gt;用来存储 k8s 所有集群数据的一致性和高可用键值存储&lt;/span&gt;
&lt;/a&gt; 中更新一个全局的分配字典。 必须要能在这个映射中
为 Service 分配指定 IP， 否则就会失败，错误信息为不能分配该 IP 地址。&lt;/p&gt;
&lt;p&gt;在控制中心中，一个后台控制器负载创建这个映射(需要支持使用内存锁的老版本k8s迁移)。k8s 还使用
控制器检查每个分配(例如，因为管理员介入)并清除那些不被任何 Service 使用的 IP 地址。&lt;/p&gt;
&lt;!--
### Service IP addresses {#ips-and-vips}

Unlike Pod IP addresses, which actually route to a fixed destination,
Service IPs are not actually answered by a single host.  Instead, kube-proxy
uses iptables (packet processing logic in Linux) to define _virtual_ IP addresses
which are transparently redirected as needed.  When clients connect to the
VIP, their traffic is automatically transported to an appropriate endpoint.
The environment variables and DNS for Services are actually populated in
terms of the Service&#39;s virtual IP address (and port).

kube-proxy supports three proxy modes&amp;mdash;userspace, iptables and IPVS&amp;mdash;which
each operate slightly differently.
 --&gt;
&lt;h3 id=&#34;ips-and-vips&#34;&gt;Service IP 地址&lt;/h3&gt;
&lt;p&gt;与 Pod 的 IP 地址不同， 当 Pod 实际是路由到一个固定的地址， Service  IP 通常不是由单个主机响应的。
而是 kube-proxy 使用 iptables (Linux 中的包处理逻辑) 来定义一个 &lt;em&gt;虚拟的&lt;/em&gt; IP 地址，根据需要透明地
转发流量。 当客户端连接到 VIP 时， 它们的流量自动传输到恰当和端点上。 Pod 中被注入的环境变量
和 Service DNS 记录指向的也是 Service 的虚拟 IP 地址(和端口)。&lt;/p&gt;
&lt;p&gt;kube-proxy 支持三种代理模式 —userspace, iptables 和 IPVS， 它们之间的运转方式各有不同。&lt;/p&gt;
&lt;!--
#### Userspace

As an example, consider the image processing application described above.
When the backend Service is created, the Kubernetes master assigns a virtual
IP address, for example 10.0.0.1.  Assuming the Service port is 1234, the
Service is observed by all of the kube-proxy instances in the cluster.
When a proxy sees a new Service, it opens a new random port, establishes an
iptables redirect from the virtual IP address to this new port, and starts accepting
connections on it.

When a client connects to the Service&#39;s virtual IP address, the iptables
rule kicks in, and redirects the packets to the proxy&#39;s own port.
The &#34;Service proxy&#34; chooses a backend, and starts proxying traffic from the client to the backend.

This means that Service owners can choose any port they want without risk of
collision.  Clients can simply connect to an IP and port, without being aware
of which Pods they are actually accessing.
 --&gt;
&lt;h4 id=&#34;userspace&#34;&gt;userspace&lt;/h4&gt;
&lt;p&gt;例如， 上面提到过那个处理图片的应用。 当后端的 Service 创建时， k8s 控制中心为它分配一个虚拟
的 IP 地址，假如是 &lt;code&gt;10.0.0.1&lt;/code&gt;。 假定 Service 的端口为 &lt;code&gt;1234&lt;/code&gt;， 该 Service 会被集群中所有
的 kube-proxy 实例监控。 当 一个代理发现一个新的 Service， 它会打开一个随机端口， 创建一个
iptables 规则将虚拟 IP 地址重定向到这个新创建的端口，并开始接收连接。&lt;/p&gt;
&lt;p&gt;当有一个客户端连接到这个 Service 的虚拟 IP 时， iptables 规则工作将包转发到代理自己的端口。
然后 Service 的代理选择后端，然后开始将代理从客户端到后端的流量。&lt;/p&gt;
&lt;p&gt;这么做的意义在于 Service 拥有者可以选择任意端口这就避免的端口冲突的风险。 客户端只是简单地连接
到一个 IP 地址和端口， 并不会感知到它实际上是连接到后端的哪个 Pod。&lt;/p&gt;
&lt;!--
#### iptables

Again, consider the image processing application described above.
When the backend Service is created, the Kubernetes control plane assigns a virtual
IP address, for example 10.0.0.1.  Assuming the Service port is 1234, the
Service is observed by all of the kube-proxy instances in the cluster.
When a proxy sees a new Service, it installs a series of iptables rules which
redirect from the virtual IP address  to per-Service rules.  The per-Service
rules link to per-Endpoint rules which redirect traffic (using destination NAT)
to the backends.

When a client connects to the Service&#39;s virtual IP address the iptables rule kicks in.
A backend is chosen (either based on session affinity or randomly) and packets are
redirected to the backend.  Unlike the userspace proxy, packets are never
copied to userspace, the kube-proxy does not have to be running for the virtual
IP address to work, and Nodes see traffic arriving from the unaltered client IP
address.

This same basic flow executes when traffic comes in through a node-port or
through a load-balancer, though in those cases the client IP does get altered.
 --&gt;
&lt;h4 id=&#34;iptables&#34;&gt;iptables&lt;/h4&gt;
&lt;p&gt;再来，还是上面那个处理图片的应用。 当后端的 Service 创建后， k8s 控制中心分配了一个虚拟IP地址
，假如是 &lt;code&gt;10.0.0.1&lt;/code&gt;.假定 Service 的端口为 &lt;code&gt;1234&lt;/code&gt;， 该 Service 会被集群中所有 的 kube-proxy 实例监控。
当代理发现一个新的 Service, 它会插入一系统 iptables 规则， 这些规则将重定向到虚拟IP地址的流量
到每个 Service 的规则。 每个 Service 的规则又与每个 Endpoint 的规则相连，将流量重定向(通过目标 NAT)
到后端。&lt;/p&gt;
&lt;p&gt;当一个客户端连接到 Service 的虚拟 IP 地址时， iptables 开始插一脚。 选择一个后端(要么基于会话粘性，要么随机)
并将数据包转发到该后端。 与 userspace 代理模式不同， 网络包不会拷贝到用户空间，kube-proxy 也不
需要为为虚拟 IP 运行工作任务， 节点可以看到接收到流量中未修改的客户端 IP 地址&lt;/p&gt;
&lt;p&gt;来自 NodePort 或 负载均衡器的流量也是使用这样的基本执行流程， 在这种情况下客户端 IP 不会被修改。&lt;/p&gt;
&lt;!--
#### IPVS

iptables operations slow down dramatically in large scale cluster e.g 10,000 Services.
IPVS is designed for load balancing and based on in-kernel hash tables. So you can achieve performance consistency in large number of Services from IPVS-based kube-proxy. Meanwhile, IPVS-based kube-proxy has more sophisticated load balancing algorithms (least conns, locality, weighted, persistence).
 --&gt;
&lt;h4 id=&#34;ipvs&#34;&gt;IPVS&lt;/h4&gt;
&lt;p&gt;iptables 在大规模集群中(如，上万个 Service)是急剧下降。IPVS 设计上是基于内核内部的哈希表来
实现负载均衡的。 所以基于 IPVS 的 kube-proxy 可以实现在大量 Service 的情况下性能稳定。
同时基于 IPVS kube-proxy 也包含更丰富的负载均衡算法(最少连接，位置，权重，维持)&lt;/p&gt;
&lt;!--
## API Object

Service is a top-level resource in the Kubernetes REST API. You can find more details
about the API object at: [Service API object](/docs/reference/generated/kubernetes-api/v1.19/#service-v1-core).
 --&gt;
&lt;h2 id=&#34;api-对象&#34;&gt;API 对象&lt;/h2&gt;
&lt;p&gt;Service is a top-level resource in the Kubernetes REST API. You can find more details
about the API object at: &lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/docs/reference/generated/kubernetes-api/v1.19/#service-v1-core&#34;&gt;Service API object&lt;/a&gt;.
Service 是 k8s REST API 中的顶级资源， 更多相关信息见
&lt;a href=&#34;https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.19/#service-v1-core&#34;&gt;Service API 对象&lt;/a&gt;.&lt;/p&gt;
&lt;!--
## Supported protocols {#protocol-support}

### TCP

You can use TCP for any kind of Service, and it&#39;s the default network protocol.

### UDP

You can use UDP for most Services. For type=LoadBalancer Services, UDP support
depends on the cloud provider offering this facility.

### HTTP

If your cloud provider supports it, you can use a Service in LoadBalancer mode
to set up external HTTP / HTTPS reverse proxying, forwarded to the Endpoints
of the Service.

&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; You can also use &lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/concepts/services-networking/ingress/&#39; target=&#39;_blank&#39;&gt;Ingress&lt;span class=&#39;tooltip-text&#39;&gt;一个用于管理外部访问集群内 Service 的 API 对象，通常是 HTTP。&lt;/span&gt;
&lt;/a&gt; in place of Service
to expose HTTP / HTTPS Services.&lt;/div&gt;
&lt;/blockquote&gt;

 --&gt;
&lt;h2 id=&#34;protocol-support&#34;&gt;支持的协议&lt;/h2&gt;
&lt;h3 id=&#34;tcp&#34;&gt;TCP&lt;/h3&gt;
&lt;p&gt;TCP 可用于任意类型的 Service， 也是 Service  的默认网络协议&lt;/p&gt;
&lt;h3 id=&#34;udp&#34;&gt;UDP&lt;/h3&gt;
&lt;p&gt;UDP 可用于大多数 Service, 对于 type=LoadBalancer 的 Service, 是否支持 UDP 基于云提供商
是否提供该功能。&lt;/p&gt;
&lt;h3 id=&#34;http&#34;&gt;HTTP&lt;/h3&gt;
&lt;p&gt;如果云提供商支持，则可以使用 type=LoadBalancer 的 Service 通过外部的 HTTP / HTTPS 反向代理
转发到 Service 的 Endpoint&lt;/p&gt;
&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; 在 Service 暴露的是 HTTP / HTTPS 时也可以使用 &lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/concepts/services-networking/ingress/&#39; target=&#39;_blank&#39;&gt;Ingress&lt;span class=&#39;tooltip-text&#39;&gt;一个用于管理外部访问集群内 Service 的 API 对象，通常是 HTTP。&lt;/span&gt;
&lt;/a&gt;&lt;/div&gt;
&lt;/blockquote&gt;

&lt;!--
### PROXY protocol

If your cloud provider supports it (eg, [AWS](/docs/concepts/cluster-administration/cloud-providers/#aws)),
you can use a Service in LoadBalancer mode to configure a load balancer outside
of Kubernetes itself, that will forward connections prefixed with
[PROXY protocol](https://www.haproxy.org/download/1.8/doc/proxy-protocol.txt).

The load balancer will send an initial series of octets describing the
incoming connection, similar to this example

```
PROXY TCP4 192.0.2.202 10.0.42.7 12345 7\r\n
```
followed by the data from the client.
 --&gt;
&lt;h3 id=&#34;proxy-协议&#34;&gt;PROXY 协议&lt;/h3&gt;
&lt;p&gt;如果云提供商支持， (比如 , &lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/docs/concepts/cluster-administration/cloud-providers/#aws&#34;&gt;AWS&lt;/a&gt;)，
可以在使用 LoadBalancer 类型的 Service 时在 k8s 外部配置负载均衡器， 它会转发带前缀
&lt;a href=&#34;https://www.haproxy.org/download/1.8/doc/proxy-protocol.txt&#34;&gt;PROXY 协议&lt;/a&gt;.
的连接。&lt;/p&gt;
&lt;p&gt;负载均衡器会发送一个初始化八进制序列描述进入的连接，类似如下&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;PROXY TCP4 192.0.2.202 10.0.42.7 12345 7\r\n
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;紧哪关就是客户端发送的数据。&lt;/p&gt;
&lt;!--
### SCTP






&lt;div style=&#34;margin-top: 10px; margin-bottom: 10px;&#34;&gt;
&lt;b&gt;功能特性状态:&lt;/b&gt; &lt;code&gt;Kubernetes v1.19 [beta]&lt;/code&gt;
&lt;/div&gt;



Kubernetes supports SCTP as a `protocol` value in Service, Endpoints, EndpointSlice, NetworkPolicy and Pod definitions. As a beta feature, this is enabled by default. To disable SCTP at a cluster level, you (or your cluster administrator) will need to disable the `SCTPSupport` [feature gate](/docs/reference/command-line-tools-reference/feature-gates/) for the API server with `--feature-gates=SCTPSupport=false,…`.

When the feature gate is enabled, you can set the `protocol` field of a Service, Endpoints, EndpointSlice, NetworkPolicy or Pod to `SCTP`. Kubernetes sets up the network accordingly for the SCTP associations, just like it does for TCP connections.
 --&gt;
&lt;h3 id=&#34;sctp&#34;&gt;SCTP&lt;/h3&gt;





&lt;div style=&#34;margin-top: 10px; margin-bottom: 10px;&#34;&gt;
&lt;b&gt;功能特性状态:&lt;/b&gt; &lt;code&gt;Kubernetes v1.19 [beta]&lt;/code&gt;
&lt;/div&gt;


&lt;p&gt;k8s 支持在 Service, Endpoints, EndpointSlice, NetworkPolicy 和 Pod 定义中 &lt;code&gt;protocol&lt;/code&gt;
的值为 &lt;code&gt;SCTP&lt;/code&gt;。 因为这是一个 beta 版本的特性，所以默认是开启的。要在集群级别禁用 &lt;code&gt;SCTP&lt;/code&gt;，
需要在 api-server 上通过设置 &lt;code&gt;--feature-gates=SCTPSupport=false,…&lt;/code&gt; 禁用 &lt;code&gt;SCTPSupport&lt;/code&gt;
&lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/docs/reference/command-line-tools-reference/feature-gates/&#34;&gt;功能阀&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;当该特性被启用时，可以设置 Service, Endpoints, EndpointSlice, NetworkPolicy, Pod 的
&lt;code&gt;protocol&lt;/code&gt; 为 &lt;code&gt;SCTP&lt;/code&gt;。 k8s 会根据 SCTP 设置网络，就像设置 TCP 连接一样。&lt;/p&gt;
&lt;!--
#### Warnings {#caveat-sctp-overview}

##### Support for multihomed SCTP associations {#caveat-sctp-multihomed}

&lt;blockquote class=&#34;warning&#34;&gt;
  &lt;div&gt;&lt;strong&gt;警告：&lt;/strong&gt; &lt;p&gt;The support of multihomed SCTP associations requires that the CNI plugin can support the assignment of multiple interfaces and IP addresses to a Pod.&lt;/p&gt;
&lt;p&gt;NAT for multihomed SCTP associations requires special logic in the corresponding kernel modules.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;


##### Service with type=LoadBalancer {#caveat-sctp-loadbalancer-service-type}

&lt;blockquote class=&#34;warning&#34;&gt;
  &lt;div&gt;&lt;strong&gt;警告：&lt;/strong&gt; You can only create a Service with &lt;code&gt;type&lt;/code&gt; LoadBalancer plus &lt;code&gt;protocol&lt;/code&gt; SCTP if the cloud provider&amp;rsquo;s load balancer implementation supports SCTP as a protocol. Otherwise, the Service creation request is rejected. The current set of cloud load balancer providers (Azure, AWS, CloudStack, GCE, OpenStack) all lack support for SCTP.&lt;/div&gt;
&lt;/blockquote&gt;


##### Windows {#caveat-sctp-windows-os}

&lt;blockquote class=&#34;warning&#34;&gt;
  &lt;div&gt;&lt;strong&gt;警告：&lt;/strong&gt; SCTP is not supported on Windows based nodes.&lt;/div&gt;
&lt;/blockquote&gt;


##### Userspace kube-proxy {#caveat-sctp-kube-proxy-userspace}

&lt;blockquote class=&#34;warning&#34;&gt;
  &lt;div&gt;&lt;strong&gt;警告：&lt;/strong&gt; The kube-proxy does not support the management of SCTP associations when it is in userspace mode.&lt;/div&gt;
&lt;/blockquote&gt;

 --&gt;
&lt;h4 id=&#34;caveat-sctp-overview&#34;&gt;警告&lt;/h4&gt;
&lt;h5 id=&#34;caveat-sctp-multihomed&#34;&gt;SCTP 多重连接支持&lt;/h5&gt;
&lt;blockquote class=&#34;warning&#34;&gt;
  &lt;div&gt;&lt;strong&gt;警告：&lt;/strong&gt; SCTP 多重连接支持的前提是 CNI 插件支持为一个 Pod 分配多个网上和IP地址
SCTP 多重连接的 NAT 需要在对应的逻辑模块中有特殊逻辑&lt;/div&gt;
&lt;/blockquote&gt;

&lt;h5 id=&#34;caveat-sctp-loadbalancer-service-type&#34;&gt;type=LoadBalancer 的 Service&lt;/h5&gt;
&lt;blockquote class=&#34;warning&#34;&gt;
  &lt;div&gt;&lt;strong&gt;警告：&lt;/strong&gt; 如有在云提供商的负载均衡器实现了对 &lt;code&gt;SCTP&lt;/code&gt; 协议支持时才能够创建一个类型为 LoadBalancer 并且
&lt;code&gt;protocol&lt;/code&gt; 为 SCTP 的 Service. 否则 Service 的创建请求会被拒绝。 目前的云负载均衡提供者
(Azure, AWS, CloudStack, GCE, OpenStack) 都缺乏对 SCTP 的支持。&lt;/div&gt;
&lt;/blockquote&gt;

&lt;h5 id=&#34;caveat-sctp-windows-os&#34;&gt;Windows&lt;/h5&gt;
&lt;blockquote class=&#34;warning&#34;&gt;
  &lt;div&gt;&lt;strong&gt;警告：&lt;/strong&gt; 基于 Windows 的节点不支持 SCTP&lt;/div&gt;
&lt;/blockquote&gt;

&lt;h5 id=&#34;caveat-sctp-kube-proxy-userspace&#34;&gt;userspace kube-proxy&lt;/h5&gt;
&lt;blockquote class=&#34;warning&#34;&gt;
  &lt;div&gt;&lt;strong&gt;警告：&lt;/strong&gt; 使用 userspace 模式的 kube-proxy 不支持对 SCTP 连接的管理&lt;/div&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;div&gt;&lt;strong&gt;TODO: &lt;/strong&gt;对SCTP不了解，需要实践理解后再考虑怎么修改&lt;/div&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;相关资料&#34;&gt;相关资料&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;概念 &lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/docs/concepts/services-networking/connect-applications-service/&#34;&gt;通过 Service 连接应用&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;概念 &lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/docs/concepts/services-networking/ingress/&#34;&gt;Ingress&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;概念 &lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/docs/concepts/services-networking/endpoint-slices/&#34;&gt;EndpointSlices&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Service Topology</title>
      <link>https://lostsquirrel.github.io/k8sDocs/docs/concepts/services-networking/service-topology/</link>
      <pubDate>Wed, 09 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://lostsquirrel.github.io/k8sDocs/docs/concepts/services-networking/service-topology/</guid>
      <description>
        
        
        &lt;!--
---
reviewers:
- johnbelamaric
- imroc
title: Service Topology
feature:
  title: Service Topology
  description: &gt;
    Routing of service traffic based upon cluster topology.

content_type: concept
weight: 10
---
 --&gt;
&lt;!-- overview --&gt;
&lt;!--





&lt;div style=&#34;margin-top: 10px; margin-bottom: 10px;&#34;&gt;
&lt;b&gt;功能特性状态:&lt;/b&gt; &lt;code&gt;Kubernetes v1.17 [alpha]&lt;/code&gt;
&lt;/div&gt;



_Service Topology_ enables a service to route traffic based upon the Node
topology of the cluster. For example, a service can specify that traffic be
preferentially routed to endpoints that are on the same Node as the client, or
in the same availability zone.
 --&gt;





&lt;div style=&#34;margin-top: 10px; margin-bottom: 10px;&#34;&gt;
&lt;b&gt;功能特性状态:&lt;/b&gt; &lt;code&gt;Kubernetes v1.17 [alpha]&lt;/code&gt;
&lt;/div&gt;


&lt;p&gt;&lt;em&gt;Service Topology&lt;/em&gt; 让 Service 可以根据集群中节点的拓扑结构来路由流量。 例如， 一个 Service
可以配置为 流量优先路由到与客户端相同的节点或在同一个可用区的 Endpoint.&lt;/p&gt;
&lt;!-- body --&gt;
&lt;!--
## Introduction

By default, traffic sent to a `ClusterIP` or `NodePort` Service may be routed to
any backend address for the Service. Since Kubernetes 1.7 it has been possible
to route &#34;external&#34; traffic to the Pods running on the Node that received the
traffic, but this is not supported for `ClusterIP` Services, and more complex
topologies &amp;mdash; such as routing zonally &amp;mdash; have not been possible. The
_Service Topology_ feature resolves this by allowing the Service creator to
define a policy for routing traffic based upon the Node labels for the
originating and destination Nodes.

By using Node label matching between the source and destination, the operator
may designate groups of Nodes that are &#34;closer&#34; and &#34;farther&#34; from one another,
using whatever metric makes sense for that operator&#39;s requirements. For many
operators in public clouds, for example, there is a preference to keep service
traffic within the same zone, because interzonal traffic has a cost associated
with it, while intrazonal traffic does not. Other common needs include being able
to route traffic to a local Pod managed by a DaemonSet, or keeping traffic to
Nodes connected to the same top-of-rack switch for the lowest latency.
 --&gt;
&lt;h2 id=&#34;介绍&#34;&gt;介绍&lt;/h2&gt;
&lt;p&gt;默认情况下， 发送到 Service  &lt;code&gt;ClusterIP&lt;/code&gt; 或 &lt;code&gt;NodePort&lt;/code&gt; 的流量会路由到 Service 的任意一个
后端实例地址。 从 k8s 1.7 开始让外部流量路由到接收到流量的节点上运行的 Pod 上成功可能。
但是这不支持 &lt;code&gt;ClusterIP&lt;/code&gt; 类型的 Service。 更复杂的拓扑结构  — 例如根据分区路由 —
也不可能。 &lt;em&gt;Service Topology&lt;/em&gt;  提供了让 Service 创建者基于流量源和目标节点标签定义一个流量路由策略来解决定个问题&lt;/p&gt;
&lt;p&gt;通过比对源和目标节点的标签， 使用一些必要的度量，就可以推断出这一组节点相对于另一组节点是更近还是更远，
许多在公有云的操作器，例如, 优先将 Service 的流量保持在同一个区里面， 因为一般在公有云跨区流量是
收费的，但区内流量是免费的。其它常见的包括能够路由流量到一个由 DaemonSet 管理的本地 Pod， 或
保持流量在同一个架顶式交换机以达到较低的延迟。&lt;/p&gt;
&lt;!--
## Using Service Topology

If your cluster has Service Topology enabled, you can control Service traffic
routing by specifying the `topologyKeys` field on the Service spec. This field
is a preference-order list of Node labels which will be used to sort endpoints
when accessing this Service. Traffic will be directed to a Node whose value for
the first label matches the originating Node&#39;s value for that label. If there is
no backend for the Service on a matching Node, then the second label will be
considered, and so forth, until no labels remain.

If no match is found, the traffic will be rejected, just as if there were no
backends for the Service at all. That is, endpoints are chosen based on the first
topology key with available backends. If this field is specified and all entries
have no backends that match the topology of the client, the service has no
backends for that client and connections should fail. The special value `&#34;*&#34;` may
be used to mean &#34;any topology&#34;. This catch-all value, if used, only makes sense
as the last value in the list.

If `topologyKeys` is not specified or empty, no topology constraints will be applied.

Consider a cluster with Nodes that are labeled with their hostname, zone name,
and region name. Then you can set the `topologyKeys` values of a service to direct
traffic as follows.

* Only to endpoints on the same node, failing if no endpoint exists on the node:
  `[&#34;kubernetes.io/hostname&#34;]`.
* Preferentially to endpoints on the same node, falling back to endpoints in the
  same zone, followed by the same region, and failing otherwise: `[&#34;kubernetes.io/hostname&#34;,
  &#34;topology.kubernetes.io/zone&#34;, &#34;topology.kubernetes.io/region&#34;]`.
  This may be useful, for example, in cases where data locality is critical.
* Preferentially to the same zone, but fallback on any available endpoint if
  none are available within this zone:
  `[&#34;topology.kubernetes.io/zone&#34;, &#34;*&#34;]`.

 --&gt;
&lt;h2 id=&#34;使用-service-topology&#34;&gt;使用 Service Topology&lt;/h2&gt;
&lt;p&gt;如果集群启用了 Service Topology， 可以通过 Service 配置的 &lt;code&gt;topologyKeys&lt;/code&gt; 字段来控制
Service 流量路由方式。 这个字段是一个用于在访问该 Service 时对 Endpoint 排序的一个节点标签的
优先顺序列表。 流量会优先转发到第一个标签与源节点同一个标签有相同值的节点。 如果 Service 后端
的所有节点都没有匹配到，就会尝试使用下一个，直至所有标签都试完。&lt;/p&gt;
&lt;p&gt;如果最终一个匹配都没有找到，则这个流量就会被拒绝，就像 Service 根本就没有后端一样。 也就是说，
Endpoint 是基于第一个有可用后端的拓扑键来选择的。 如果设置了这个字段，但所以有条目都没有
与客户端的条目相匹配的，则 Service 便就有针对该客户端的后端，连接就会失败。 有一个特殊的值可以
用来表示 &amp;ldquo;任意拓扑&amp;rdquo;。 这是一个匹配所有的值，如果要使用，只有作为列表的最后一个值才有意义。&lt;/p&gt;
&lt;p&gt;如果 &lt;code&gt;topologyKeys&lt;/code&gt; 没有设置或值为空，则不会应用任何拓扑约束。&lt;/p&gt;
&lt;p&gt;假定有一个集群中的节点都打上它们的主机名，分区名，地区名。则可以设置 &lt;code&gt;topologyKeys&lt;/code&gt; 如果值来转发流量&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;[&amp;quot;kubernetes.io/hostname&amp;quot;]&lt;/code&gt;: 只匹配同一个节点上的 Endpoint, 如果节点上没有对应的 Endpoint 则失败&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;优先使用同节点上匹配的 Endpoint, 如果没则使用同分区匹配的 Endpoint, 要是还没有则使用同地区
匹配的 Endpoint, 最后都没匹配则失败。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;[&amp;quot;topology.kubernetes.io/zone&amp;quot;, &amp;quot;*&amp;quot;]&lt;/code&gt;: 优先使用同分区匹配的 Endpoint，
如果没则任意该 Service 的可用 Endpoint 都可以。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;!--
## Constraints

* Service topology is not compatible with `externalTrafficPolicy=Local`, and
  therefore a Service cannot use both of these features. It is possible to use
  both features in the same cluster on different Services, just not on the same
  Service.

* Valid topology keys are currently limited to `kubernetes.io/hostname`,
  `topology.kubernetes.io/zone`, and `topology.kubernetes.io/region`, but will
  be generalized to other node labels in the future.

* Topology keys must be valid label keys and at most 16 keys may be specified.

* The catch-all value, `&#34;*&#34;`, must be the last value in the topology keys, if
  it is used.
 --&gt;
&lt;h2 id=&#34;限制&#34;&gt;限制&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Service Topology 与 &lt;code&gt;externalTrafficPolicy=Local&lt;/code&gt; 不兼容，因此同一个 Serice
不能同时使用这两个特性。 但可以在同一个集群中的不同的 Service 中分别使用一个特性。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;目前有效的键只有 &lt;code&gt;kubernetes.io/hostname&lt;/code&gt;, &lt;code&gt;topology.kubernetes.io/zone&lt;/code&gt;,
&lt;code&gt;topology.kubernetes.io/region&lt;/code&gt;，未来可能包含其它的节点标签&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Topology 必须是有效的标签键，最多只能有 16 个键&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;匹配所有的 &lt;code&gt;&amp;quot;*&amp;quot;&lt;/code&gt;，如果要用，只能用作最后一个键&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;!--
## Examples

The following are common examples of using the Service Topology feature.

### Only Node Local Endpoints

A Service that only routes to node local endpoints. If no endpoints exist on the node, traffic is dropped:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  selector:
    app: my-app
  ports:
    - protocol: TCP
      port: 80
      targetPort: 9376
  topologyKeys:
    - &#34;kubernetes.io/hostname&#34;
```
 --&gt;
&lt;h2 id=&#34;示例&#34;&gt;示例&lt;/h2&gt;
&lt;p&gt;The following are common examples of using the Service Topology feature.
以下为 Service Topology 特性常见用法的示例&lt;/p&gt;
&lt;h3 id=&#34;仅限当前节点的-endpoint&#34;&gt;仅限当前节点的 Endpoint&lt;/h3&gt;
&lt;p&gt;这个 Service 只路由到本节点的 Endpoint， 如果本节点没有匹配的 Endpoint，流量被丢弃:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Service&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-service&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;selector&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;app&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-app&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;ports&lt;/span&gt;:
    - &lt;span style=&#34;color:#f92672&#34;&gt;protocol&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;TCP&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;targetPort&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;9376&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;topologyKeys&lt;/span&gt;:
    - &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;kubernetes.io/hostname&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;!--
### Prefer Node Local Endpoints

A Service that prefers node local Endpoints but falls back to cluster wide endpoints if node local endpoints do not exist:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  selector:
    app: my-app
  ports:
    - protocol: TCP
      port: 80
      targetPort: 9376
  topologyKeys:
    - &#34;kubernetes.io/hostname&#34;
    - &#34;*&#34;
```
 --&gt;
&lt;h3 id=&#34;优先使用本节点的-endpoint&#34;&gt;优先使用本节点的 Endpoint&lt;/h3&gt;
&lt;p&gt;这个 Service 优先使用本节点匹配的 Endpoint，如果没则使用集群中可用的 Endpoint:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Service&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-service&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;selector&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;app&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-app&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;ports&lt;/span&gt;:
    - &lt;span style=&#34;color:#f92672&#34;&gt;protocol&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;TCP&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;targetPort&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;9376&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;topologyKeys&lt;/span&gt;:
    - &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;kubernetes.io/hostname&amp;#34;&lt;/span&gt;
    - &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;*&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;!--
### Only Zonal or Regional Endpoints

A Service that prefers zonal then regional endpoints. If no endpoints exist in either, traffic is dropped.


```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  selector:
    app: my-app
  ports:
    - protocol: TCP
      port: 80
      targetPort: 9376
  topologyKeys:
    - &#34;topology.kubernetes.io/zone&#34;
    - &#34;topology.kubernetes.io/region&#34;
```
--&gt;
&lt;h3 id=&#34;仅限本分区或本地区的-endpoint&#34;&gt;仅限本分区或本地区的 Endpoint&lt;/h3&gt;
&lt;p&gt;这个 Service 优先使用本分区匹配的 Endpoint, 要是没有则使用同地区匹配的 Endpoint, 要是还没有就丢弃流量。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Service&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-service&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;selector&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;app&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-app&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;ports&lt;/span&gt;:
    - &lt;span style=&#34;color:#f92672&#34;&gt;protocol&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;TCP&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;targetPort&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;9376&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;topologyKeys&lt;/span&gt;:
    - &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;topology.kubernetes.io/zone&amp;#34;&lt;/span&gt;
    - &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;topology.kubernetes.io/region&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;!--
### Prefer Node Local, Zonal, then Regional Endpoints

A Service that prefers node local, zonal, then regional endpoints but falls back to cluster wide endpoints.

```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  selector:
    app: my-app
  ports:
    - protocol: TCP
      port: 80
      targetPort: 9376
  topologyKeys:
    - &#34;kubernetes.io/hostname&#34;
    - &#34;topology.kubernetes.io/zone&#34;
    - &#34;topology.kubernetes.io/region&#34;
    - &#34;*&#34;
```
 --&gt;
&lt;h3 id=&#34;本节点本分区本地区依次优先&#34;&gt;本节点，本分区，本地区依次优先&lt;/h3&gt;
&lt;p&gt;这个 Service 按照 本节点，本分区，本地区 的顺序依次匹配，如果三个都没有匹配到，则匹配全集群的 Endpoint&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Service&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-service&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;selector&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;app&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-app&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;ports&lt;/span&gt;:
    - &lt;span style=&#34;color:#f92672&#34;&gt;protocol&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;TCP&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;targetPort&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;9376&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;topologyKeys&lt;/span&gt;:
    - &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;kubernetes.io/hostname&amp;#34;&lt;/span&gt;
    - &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;topology.kubernetes.io/zone&amp;#34;&lt;/span&gt;
    - &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;topology.kubernetes.io/region&amp;#34;&lt;/span&gt;
    - &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;*&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;相关资料&#34;&gt;相关资料&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;实践 &lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/docs/tasks/administer-cluster/enabling-service-topology&#34;&gt;启用 Service Topology&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;概念 &lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/docs/concepts/services-networking/connect-applications-service/&#34;&gt;通过 Service 连接应用&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Service 和 Pod 的 DNS</title>
      <link>https://lostsquirrel.github.io/k8sDocs/docs/concepts/services-networking/dns-pod-service/</link>
      <pubDate>Tue, 30 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://lostsquirrel.github.io/k8sDocs/docs/concepts/services-networking/dns-pod-service/</guid>
      <description>
        
        
        &lt;!--
---
reviewers:
- davidopp
- thockin
title: DNS for Services and Pods
content_type: concept
weight: 20
---
 --&gt;
&lt;!-- overview --&gt;
&lt;!--
This page provides an overview of DNS support by Kubernetes.
 --&gt;
&lt;p&gt;本文简述 k8s 对 DNS 的支持&lt;/p&gt;
&lt;!-- body --&gt;
&lt;!--
## Introduction

Kubernetes DNS schedules a DNS Pod and Service on the cluster, and configures
the kubelets to tell individual containers to use the DNS Service&#39;s IP to
resolve DNS names
 --&gt;
&lt;h2 id=&#34;介绍&#34;&gt;介绍&lt;/h2&gt;
&lt;p&gt;k8s DNS 先在集群中部署了一个 DNS 的 Pod 和 Service， 并配置 kubelet 让每一个容器都使用
DNS Service 的 IP 来解析 DNS 名称。&lt;/p&gt;
&lt;!--
### What things get DNS names?

Every Service defined in the cluster (including the DNS server itself) is
assigned a DNS name.  By default, a client Pod&#39;s DNS search list will
include the Pod&#39;s own namespace and the cluster&#39;s default domain.  This is best
illustrated by example:

Assume a Service named `foo` in the Kubernetes namespace `bar`.  A Pod running
in namespace `bar` can look up this service by simply doing a DNS query for
`foo`.  A Pod running in namespace `quux` can look up this service by doing a
DNS query for `foo.bar`.

The following sections detail the supported record types and layout that is
supported.  Any other layout or names or queries that happen to work are
considered implementation details and are subject to change without warning.
For more up-to-date specification, see
[Kubernetes DNS-Based Service Discovery](https://github.com/kubernetes/dns/blob/master/docs/specification.md).
 --&gt;
&lt;h3 id=&#34;啥东西会有-dns-名称&#34;&gt;啥东西会有 DNS 名称?&lt;/h3&gt;
&lt;p&gt;集群中定义的每一个 Service (包括 DNS 服务本身) 都会分配一个 DNS 名称。 默认情况下，一个客户端
Pod 的 DNS 检索列表会包含 Pod 自己所在的命名空间和集群的默认域。 一例胜千言:&lt;/p&gt;
&lt;p&gt;假设在 k8s 的 &lt;code&gt;bar&lt;/code&gt; 命名空间有一个叫 &lt;code&gt;foo&lt;/code&gt; 的 Service. 一个运行在 &lt;code&gt;bar&lt;/code&gt; 命名空间的 Pod
只需要简单地使用 &lt;code&gt;foo&lt;/code&gt; 作为 DNS 查询条目就可以找到这个 Service。 另一个运行在 &lt;code&gt;quux&lt;/code&gt; 命名空间的 Pod
同要为查询这个 Service。 DNS 的查询条目就需要是 &lt;code&gt;foo.bar&lt;/code&gt; (带上命名空间的名称)&lt;/p&gt;
&lt;p&gt;接下来的章节会详细介绍支持的 DNS 记录类型的规划。 (这一句没懂)
最新的规格说明书见
&lt;a href=&#34;https://github.com/kubernetes/dns/blob/master/docs/specification.md&#34;&gt;Kubernetes DNS-Based Service Discovery&lt;/a&gt;.&lt;/p&gt;
&lt;!--
## Services

### A/AAAA records

&#34;Normal&#34; (not headless) Services are assigned a DNS A or AAAA record,
depending on the IP family of the service, for a name of the form
`my-svc.my-namespace.svc.cluster-domain.example`.  This resolves to the cluster IP
of the Service.

&#34;Headless&#34; (without a cluster IP) Services are also assigned a DNS A or AAAA record,
depending on the IP family of the service, for a name of the form
`my-svc.my-namespace.svc.cluster-domain.example`.  Unlike normal
Services, this resolves to the set of IPs of the pods selected by the Service.
Clients are expected to consume the set or else use standard round-robin
selection from the set.

### SRV records

SRV Records are created for named ports that are part of normal or [Headless
Services](/docs/concepts/services-networking/service/#headless-services).
For each named port, the SRV record would have the form
`_my-port-name._my-port-protocol.my-svc.my-namespace.svc.cluster-domain.example`.
For a regular service, this resolves to the port number and the domain name:
`my-svc.my-namespace.svc.cluster-domain.example`.
For a headless service, this resolves to multiple answers, one for each pod
that is backing the service, and contains the port number and the domain name of the pod
of the form `auto-generated-name.my-svc.my-namespace.svc.cluster-domain.example`.
 --&gt;
&lt;h2 id=&#34;service&#34;&gt;Service&lt;/h2&gt;
&lt;h3 id=&#34;aaaaa-记录&#34;&gt;A/AAAA 记录&lt;/h3&gt;
&lt;p&gt;&amp;ldquo;普通的&amp;rdquo;(不是无头(headless)的) Service 会基于使用的是 IPv4 还是 IPv6 分配一个 DNS A 或 AAAA 记录，
记录名为 &lt;code&gt;my-svc.my-namespace.svc.cluster-domain.example&lt;/code&gt;。 记录的值是 Service 的
集群 IP (cluster IP)&lt;/p&gt;
&lt;p&gt;无头(headless)(没有设置 &lt;code&gt;clusterIP&lt;/code&gt;) Service 也会基于使用的是 IPv4 还是 IPv6
分配一个 DNS A 或 AAAA 记录，记录名为 &lt;code&gt;my-svc.my-namespace.svc.cluster-domain.example&lt;/code&gt;，
与普通 Service 不同的是记录值是由 Service 选择的 Pod 的IP 的集合。 客户端在设计要需要能能够
接受 IP 集合或使用标准轮询 IP 集合。&lt;/p&gt;
&lt;h3 id=&#34;srv-记录&#34;&gt;SRV 记录&lt;/h3&gt;
&lt;p&gt;SRV 记录是为命名端口创建的，是普通或
&lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/docs/concepts/services-networking/service/#headless-services&#34;&gt;Headless Services&lt;/a&gt;
的一部分。 对于每个命名端口的 SRV 记录格式如下:
&lt;code&gt;_my-port-name._my-port-protocol.my-svc.my-namespace.svc.cluster-domain.example&lt;/code&gt;.
对于普通 Service , 解析的结果为 端口号和 域名:
&lt;code&gt;my-svc.my-namespace.svc.cluster-domain.example&lt;/code&gt;.
对于 无头(headless) 的 Service, 解析结果有多个应答， 一个是 Service 后端的每个 Pod。
另一个则包含端口号和类似这种格式
&lt;code&gt;auto-generated-name.my-svc.my-namespace.svc.cluster-domain.example&lt;/code&gt;
的 Pod 的域名&lt;/p&gt;
&lt;!--
## Pods

### A/AAAA records

In general a pod has the following DNS resolution:

`pod-ip-address.my-namespace.pod.cluster-domain.example`.

For example, if a pod in the `default` namespace has the IP address 172.17.0.3,
and the domain name for your cluster is `cluster.local`, then the Pod has a DNS name:

`172-17-0-3.default.pod.cluster.local`.

Any pods created by a Deployment or DaemonSet exposed by a Service have the
following DNS resolution available:

`pod-ip-address.deployment-name.my-namespace.svc.cluster-domain.example`.
 --&gt;
&lt;h2 id=&#34;pod&#34;&gt;Pod&lt;/h2&gt;
&lt;h3 id=&#34;aaaaa-记录-1&#34;&gt;A/AAAA 记录&lt;/h3&gt;
&lt;p&gt;通常 Pod 的 DNS 记录名为如下格式:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;pod-ip-address.my-namespace.pod.cluster-domain.example&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;例如， 如果有一个在 &lt;code&gt;default&lt;/code&gt; 命名空间的 Pod， 它的 IP 地址为 &lt;code&gt;172.17.0.3&lt;/code&gt;， 集群配置的
域名叫 &lt;code&gt;cluster.local&lt;/code&gt;， 这样这个 Pod 的 DNS 名称就是:
&lt;code&gt;172-17-0-3.default.pod.cluster.local&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;任意由 Deployment 或 DaemonSet 创建，由 Service 暴露的 Pod 会拥有一个如下的 DNS 名称:
&lt;code&gt;pod-ip-address.deployment-name.my-namespace.svc.cluster-domain.example&lt;/code&gt;.&lt;/p&gt;
&lt;!--
### Pod&#39;s hostname and subdomain fields

Currently when a pod is created, its hostname is the Pod&#39;s `metadata.name` value.

The Pod spec has an optional `hostname` field, which can be used to specify the
Pod&#39;s hostname. When specified, it takes precedence over the Pod&#39;s name to be
the hostname of the pod. For example, given a Pod with `hostname` set to
&#34;`my-host`&#34;, the Pod will have its hostname set to &#34;`my-host`&#34;.

The Pod spec also has an optional `subdomain` field which can be used to specify
its subdomain. For example, a Pod with `hostname` set to &#34;`foo`&#34;, and `subdomain`
set to &#34;`bar`&#34;, in namespace &#34;`my-namespace`&#34;, will have the fully qualified
domain name (FQDN) &#34;`foo.bar.my-namespace.svc.cluster-domain.example`&#34;.

Example:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: default-subdomain
spec:
  selector:
    name: busybox
  clusterIP: None
  ports:
  - name: foo # Actually, no port is needed.
    port: 1234
    targetPort: 1234
---
apiVersion: v1
kind: Pod
metadata:
  name: busybox1
  labels:
    name: busybox
spec:
  hostname: busybox-1
  subdomain: default-subdomain
  containers:
  - image: busybox:1.28
    command:
      - sleep
      - &#34;3600&#34;
    name: busybox
---
apiVersion: v1
kind: Pod
metadata:
  name: busybox2
  labels:
    name: busybox
spec:
  hostname: busybox-2
  subdomain: default-subdomain
  containers:
  - image: busybox:1.28
    command:
      - sleep
      - &#34;3600&#34;
    name: busybox
```

If there exists a headless service in the same namespace as the pod and with
the same name as the subdomain, the cluster&#39;s DNS Server also returns an A or AAAA
record for the Pod&#39;s fully qualified hostname.
For example, given a Pod with the hostname set to &#34;`busybox-1`&#34; and the subdomain set to
&#34;`default-subdomain`&#34;, and a headless Service named &#34;`default-subdomain`&#34; in
the same namespace, the pod will see its own FQDN as
&#34;`busybox-1.default-subdomain.my-namespace.svc.cluster-domain.example`&#34;. DNS serves an
A or AAAA record at that name, pointing to the Pod&#39;s IP. Both pods &#34;`busybox1`&#34; and
&#34;`busybox2`&#34; can have their distinct A or AAAA records.

The Endpoints object can specify the `hostname` for any endpoint addresses,
along with its IP.

&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; Because A or AAAA records are not created for Pod names, &lt;code&gt;hostname&lt;/code&gt; is required for the Pod&amp;rsquo;s A or AAAA
record to be created. A Pod with no &lt;code&gt;hostname&lt;/code&gt; but with &lt;code&gt;subdomain&lt;/code&gt; will only create the
A or AAAA record for the headless service (&lt;code&gt;default-subdomain.my-namespace.svc.cluster-domain.example&lt;/code&gt;),
pointing to the Pod&amp;rsquo;s IP address. Also, Pod needs to become ready in order to have a
record unless &lt;code&gt;publishNotReadyAddresses=True&lt;/code&gt; is set on the Service.&lt;/div&gt;
&lt;/blockquote&gt;

 --&gt;
&lt;h3 id=&#34;pod-的-hostname-和-subdomain-字段&#34;&gt;Pod 的 &lt;code&gt;hostname&lt;/code&gt; 和 &lt;code&gt;subdomain&lt;/code&gt; 字段&lt;/h3&gt;
&lt;p&gt;目前，当一个 Pod 创建后， 它的主机名是 Pod 的 &lt;code&gt;metadata.name&lt;/code&gt; 字段的值。&lt;/p&gt;
&lt;p&gt;Pod 的定义中有一个可选字段 &lt;code&gt;hostname&lt;/code&gt;， 可以用来指定 Pod 的主机名。 当设置了主机名时，它的优先
级是高于 Pod 名称作为 Pod 的主机名的。 例如， 设置一个 Pod 的 &lt;code&gt;hostname&lt;/code&gt; 为 &lt;code&gt;my-host&lt;/code&gt;，
这个 Pod 的主机名就会设置为 &lt;code&gt;my-host&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Pod 定义中还有一个可选择字段 &lt;code&gt;subdomain&lt;/code&gt;， 可以用来指定它的子域名。 例如， 一个 Pod 的
&lt;code&gt;hostname&lt;/code&gt; 设置为 &lt;code&gt;foo&lt;/code&gt;， &lt;code&gt;subdomain&lt;/code&gt; 设置为 &lt;code&gt;bar&lt;/code&gt;， 处理 &lt;code&gt;my-namespace&lt;/code&gt; 命名空间。
它的全限定名(FQDN) 就是 &lt;code&gt;foo.bar.my-namespace.svc.cluster-domain.example&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;示例:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Service&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;default-subdomain&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;selector&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;busybox&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;clusterIP&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;None&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;ports&lt;/span&gt;:
  - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;foo # 实际上是不需要端口的&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;1234&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;targetPort&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;1234&lt;/span&gt;
---
&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Pod&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;busybox1&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;labels&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;busybox&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;hostname&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;busybox-1&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;subdomain&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;default-subdomain&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;containers&lt;/span&gt;:
  - &lt;span style=&#34;color:#f92672&#34;&gt;image&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;busybox:1.28&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;command&lt;/span&gt;:
      - &lt;span style=&#34;color:#ae81ff&#34;&gt;sleep&lt;/span&gt;
      - &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;3600&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;busybox&lt;/span&gt;
---
&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Pod&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;busybox2&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;labels&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;busybox&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;hostname&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;busybox-2&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;subdomain&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;default-subdomain&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;containers&lt;/span&gt;:
  - &lt;span style=&#34;color:#f92672&#34;&gt;image&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;busybox:1.28&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;command&lt;/span&gt;:
      - &lt;span style=&#34;color:#ae81ff&#34;&gt;sleep&lt;/span&gt;
      - &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;3600&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;busybox&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;如果存在这样一个无头(headless) 的 Service, 它与另一个 Pod 在同一个命名空间，且 Pod 的
&lt;code&gt;subdomain&lt;/code&gt; 与这个 Service 的名称是一样的。 集群 DNS 服务一样会返回 Pod 全限制名的 A/AAAA 记录。
例如，假定一个 Pod 的 &lt;code&gt;hostname&lt;/code&gt; 设置为 &lt;code&gt;busybox-1&lt;/code&gt;， &lt;code&gt;subdomain&lt;/code&gt; 设置为 &lt;code&gt;default-subdomain&lt;/code&gt;，
一个无头(headless) 的 Service 名字是 &lt;code&gt;default-subdomain&lt;/code&gt;， 它们在同一个命名空间。
Pod 就可以看到它自己的全限定名(FQDN)为
&lt;code&gt;busybox-1.default-subdomain.my-namespace.svc.cluster-domain.example&lt;/code&gt;。
DNS 服务为这个名称提供一个 A/AAAA 记录， 指向该 Pod 的 IP。 &lt;code&gt;busybox1&lt;/code&gt; 和 &lt;code&gt;busybox2&lt;/code&gt;
都能有它们各自的 A/AAAA 记录。
&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;TODO: &lt;/strong&gt;这里需要配个完整的例子&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/p&gt;
&lt;p&gt;Endpoint 对象可以将任意端点地址和IP 设置为 &lt;code&gt;hostname&lt;/code&gt;
&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;TODO: &lt;/strong&gt;这里不理解，并且需要一个例子&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/p&gt;
&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; 因为 A/AAAA 记录不是为 Pod 名称创建的， &lt;code&gt;hostname&lt;/code&gt; 是 Pod A/AAAA 记录创建所必须的。
一个没有 &lt;code&gt;hostname&lt;/code&gt; 字段，但是有 &lt;code&gt;subdomain&lt;/code&gt; 字段的 Pod 只会为无头(headless)Service
创建 A/AAAA 记录(&lt;code&gt;default-subdomain.my-namespace.svc.cluster-domain.example&lt;/code&gt;)
该记录指向的是该 Pod 的 IP 地址。还有，如果 Service 上没有设置 &lt;code&gt;publishNotReadyAddresses=True&lt;/code&gt;
则 Pod 状态变为就绪后才的 DNS 记录&lt;/div&gt;
&lt;/blockquote&gt;

&lt;!--
### Pod&#39;s setHostnameAsFQDN field {#pod-sethostnameasfqdn-field}






&lt;div style=&#34;margin-top: 10px; margin-bottom: 10px;&#34;&gt;
&lt;b&gt;功能特性状态:&lt;/b&gt; &lt;code&gt;Kubernetes v1.19 [alpha]&lt;/code&gt;
&lt;/div&gt;



**Prerequisites**: The `SetHostnameAsFQDN` [feature gate](/docs/reference/command-line-tools-reference/feature-gates/)
must be enabled for the
&lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/docs/reference/generated/kube-apiserver/&#39; target=&#39;_blank&#39;&gt;API Server&lt;span class=&#39;tooltip-text&#39;&gt;Control plane component that serves the Kubernetes API.&lt;/span&gt;
&lt;/a&gt;

When a Pod is configured to have fully qualified domain name (FQDN), its hostname is the short hostname. For example, if you have a Pod with the fully qualified domain name `busybox-1.default-subdomain.my-namespace.svc.cluster-domain.example`, then by default the `hostname` command inside that Pod returns `busybox-1` and  the `hostname --fqdn` command returns the FQDN.

When you set `setHostnameAsFQDN: true` in the Pod spec, the kubelet writes the Pod&#39;s FQDN into the hostname for that Pod&#39;s namespace. In this case, both `hostname` and `hostname --fqdn` return the Pod&#39;s FQDN.

&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; &lt;p&gt;In Linux, the hostname field of the kernel (the &lt;code&gt;nodename&lt;/code&gt; field of &lt;code&gt;struct utsname&lt;/code&gt;) is limited to 64 characters.&lt;/p&gt;
&lt;p&gt;If a Pod enables this feature and its FQDN is longer than 64 character, it will fail to start. The Pod will remain in &lt;code&gt;Pending&lt;/code&gt; status (&lt;code&gt;ContainerCreating&lt;/code&gt; as seen by &lt;code&gt;kubectl&lt;/code&gt;) generating error events, such as Failed to construct FQDN from pod hostname and cluster domain, FQDN &lt;code&gt;long-FDQN&lt;/code&gt; is too long (64 characters is the max, 70 characters requested). One way of improving user experience for this scenario is to create an &lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/docs/reference/access-authn-authz/extensible-admission-controllers/#admission-webhooks&#34;&gt;admission webhook controller&lt;/a&gt; to control FQDN size when users create top level objects, for example, Deployment.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;

 --&gt;
&lt;h3 id=&#34;pod-sethostnameasfqdn-field&#34;&gt;Pod 的 setHostnameAsFQDN 字段&lt;/h3&gt;





&lt;div style=&#34;margin-top: 10px; margin-bottom: 10px;&#34;&gt;
&lt;b&gt;功能特性状态:&lt;/b&gt; &lt;code&gt;Kubernetes v1.19 [alpha]&lt;/code&gt;
&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;前提条件&lt;/strong&gt;:
需要在 &lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/docs/reference/generated/kube-apiserver/&#39; target=&#39;_blank&#39;&gt;API Server&lt;span class=&#39;tooltip-text&#39;&gt;Control plane component that serves the Kubernetes API.&lt;/span&gt;
&lt;/a&gt; 启用
&lt;code&gt;SetHostnameAsFQDN&lt;/code&gt; &lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/docs/reference/command-line-tools-reference/feature-gates/&#34;&gt;功能阀&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;当一个 Pod 配置了全限定名(FQDN)时，它的主机名是短主机名。 例如， 如果有一个全限定名为
&lt;code&gt;busybox-1.default-subdomain.my-namespace.svc.cluster-domain.example&lt;/code&gt; 的 Pod，
在 Pod 内使用默认的 &lt;code&gt;hostname&lt;/code&gt; 命令时返回的是 &lt;code&gt;busybox-1&lt;/code&gt;， 而 &lt;code&gt;hostname --fqdn&lt;/code&gt; 命令
返回的是全限定名(FQDN)。&lt;/p&gt;
&lt;p&gt;当在 Pod 的定义中设置 &lt;code&gt;setHostnameAsFQDN: true&lt;/code&gt; 时， kubelet 会将 Pod 的 全限定名(FQDN)
写到那个 Pod 命名空间的 hostname. 在这种情况下 &lt;code&gt;hostname&lt;/code&gt; 和 &lt;code&gt;hostname --fqdn&lt;/code&gt; 两个命令
返回的都是全限定名。&lt;/p&gt;
&lt;p&gt;&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; 在 Linux 中， 内核中的 &lt;code&gt;hostname&lt;/code&gt; 字段(&lt;code&gt;struct utsname&lt;/code&gt; 的 &lt;code&gt;nodename&lt;/code&gt; 字段)限制最多只能有 64 个字符。&lt;/div&gt;
&lt;/blockquote&gt;

如果一个 Pod 开启了该特性，并且它的 全限定名(FQDN) 长度大于 64 个字符，就会启动失败。
Pod 会一停在 &lt;code&gt;Pending&lt;/code&gt; 状态(通过 &lt;code&gt;kubectl&lt;/code&gt; 看到的是 &lt;code&gt;ContainerCreating&lt;/code&gt;)，最终会产生一个
错误事件，错误信息类似基于 Pod 主机名和集群域构建全限定名(FQDN)失败， &lt;code&gt;long-FDQN&lt;/code&gt;  FQDN 太长了
(最长只能有 64 个字符，但实际有 70 个字符)。 在这种情况下改善用户体验的一种方式是创建一个
&lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/docs/reference/access-authn-authz/extensible-admission-controllers/#admission-webhooks&#34;&gt;admission webhook controller&lt;/a&gt;
来在创建顶级对象(如，Deployment)时控制全限定名(FQDN)的长度&lt;/p&gt;
&lt;!--
### Pod&#39;s DNS Policy

DNS policies can be set on a per-pod basis. Currently Kubernetes supports the
following pod-specific DNS policies. These policies are specified in the
`dnsPolicy` field of a Pod Spec.

- &#34;`Default`&#34;: The Pod inherits the name resolution configuration from the node
  that the pods run on.
  See [related discussion](/docs/tasks/administer-cluster/dns-custom-nameservers/#inheriting-dns-from-the-node)
  for more details.
- &#34;`ClusterFirst`&#34;: Any DNS query that does not match the configured cluster
  domain suffix, such as &#34;`www.kubernetes.io`&#34;, is forwarded to the upstream
  nameserver inherited from the node. Cluster administrators may have extra
  stub-domain and upstream DNS servers configured.
  See [related discussion](/docs/tasks/administer-cluster/dns-custom-nameservers/#effects-on-pods)
  for details on how DNS queries are handled in those cases.
- &#34;`ClusterFirstWithHostNet`&#34;: For Pods running with hostNetwork, you should
  explicitly set its DNS policy &#34;`ClusterFirstWithHostNet`&#34;.
- &#34;`None`&#34;: It allows a Pod to ignore DNS settings from the Kubernetes
  environment. All DNS settings are supposed to be provided using the
  `dnsConfig` field in the Pod Spec.
  See [Pod&#39;s DNS config](#pod-dns-config) subsection below.

&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; &amp;ldquo;Default&amp;rdquo; is not the default DNS policy. If &lt;code&gt;dnsPolicy&lt;/code&gt; is not
explicitly specified, then &amp;ldquo;ClusterFirst&amp;rdquo; is used.&lt;/div&gt;
&lt;/blockquote&gt;



The example below shows a Pod with its DNS policy set to
&#34;`ClusterFirstWithHostNet`&#34; because it has `hostNetwork` set to `true`.

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: busybox
  namespace: default
spec:
  containers:
  - image: busybox:1.28
    command:
      - sleep
      - &#34;3600&#34;
    imagePullPolicy: IfNotPresent
    name: busybox
  restartPolicy: Always
  hostNetwork: true
  dnsPolicy: ClusterFirstWithHostNet
```
 --&gt;
&lt;h3 id=&#34;pod-的-dns-策略&#34;&gt;Pod 的 DNS 策略&lt;/h3&gt;
&lt;p&gt;DNS policies can be set on a per-pod basis. Currently Kubernetes supports the
following pod-specific DNS policies. These policies are specified in the
&lt;code&gt;dnsPolicy&lt;/code&gt; field of a Pod Spec.
DNS 策略可以在 Pod 级别设置， 目前 k8s 支持以下的 Pod 级别 DNS 策略。 这个策略通过 Pod
定义的 &lt;code&gt;dnsPolicy&lt;/code&gt; 字段指定。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&amp;ldquo;&lt;code&gt;Default&lt;/code&gt;&amp;quot;: Pod 从它自己运行的节点上继承域名解析配置。更多信息见
&lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/docs/tasks/administer-cluster/dns-custom-nameservers/#inheriting-dns-from-the-node&#34;&gt;相关讨论&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&amp;ldquo;&lt;code&gt;ClusterFirst&lt;/code&gt;&amp;quot;: 任何与配置的集群域后缀匹配的 DNS 查询，如   &amp;ldquo;&lt;code&gt;www.kubernetes.io&lt;/code&gt;&amp;quot;，
会被转发到由节点继承的上游域名服务器。 集群管理员可以配置额外的 存根域(stub-domain) 和上游
DNS 服务器。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&amp;ldquo;&lt;code&gt;ClusterFirstWithHostNet&lt;/code&gt;&amp;quot;: 以 &lt;code&gt;hostNetwork&lt;/code&gt; 运行的 Pod，需要显式的设置它的 DNS
策略为 &amp;ldquo;&lt;code&gt;ClusterFirstWithHostNet&lt;/code&gt;&amp;rdquo;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&amp;ldquo;&lt;code&gt;None&lt;/code&gt;&amp;quot;: 这种策略允许 Pod 无视 k8s 环境的 DNS 配置。 所有的 DNS 配置都应该由 Pod 定义中
的 &lt;code&gt;dnsConfig&lt;/code&gt; 字段提供。
&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; &amp;ldquo;Default&amp;rdquo; 并不是默认的 DNS 策略， 如果没有显式的设置 &lt;code&gt;dnsPolicy&lt;/code&gt;，则使用 &amp;ldquo;ClusterFirst&amp;rdquo;&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以面的例子中的 Pod 的 DNS 策略被设置为 &amp;ldquo;&lt;code&gt;ClusterFirstWithHostNet&lt;/code&gt;&amp;rdquo; 因为它的 &lt;code&gt;hostNetwork&lt;/code&gt;
被设置为了 &lt;code&gt;true&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Pod&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;busybox&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;namespace&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;default&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;containers&lt;/span&gt;:
  - &lt;span style=&#34;color:#f92672&#34;&gt;image&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;busybox:1.28&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;command&lt;/span&gt;:
      - &lt;span style=&#34;color:#ae81ff&#34;&gt;sleep&lt;/span&gt;
      - &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;3600&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;imagePullPolicy&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;IfNotPresent&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;busybox&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;restartPolicy&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Always&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;hostNetwork&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;true&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;dnsPolicy&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;ClusterFirstWithHostNet&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;!--
### Pod&#39;s DNS Config {#pod-dns-config}

Pod&#39;s DNS Config allows users more control on the DNS settings for a Pod.

The `dnsConfig` field is optional and it can work with any `dnsPolicy` settings.
However, when a Pod&#39;s `dnsPolicy` is set to &#34;`None`&#34;, the `dnsConfig` field has
to be specified.

Below are the properties a user can specify in the `dnsConfig` field:

- `nameservers`: a list of IP addresses that will be used as DNS servers for the
  Pod. There can be at most 3 IP addresses specified. When the Pod&#39;s `dnsPolicy`
  is set to &#34;`None`&#34;, the list must contain at least one IP address, otherwise
  this property is optional.
  The servers listed will be combined to the base nameservers generated from the
  specified DNS policy with duplicate addresses removed.
- `searches`: a list of DNS search domains for hostname lookup in the Pod.
  This property is optional. When specified, the provided list will be merged
  into the base search domain names generated from the chosen DNS policy.
  Duplicate domain names are removed.
  Kubernetes allows for at most 6 search domains.
- `options`: an optional list of objects where each object may have a `name`
  property (required) and a `value` property (optional). The contents in this
  property will be merged to the options generated from the specified DNS policy.
  Duplicate entries are removed.

The following is an example Pod with custom DNS settings:



 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingcustom-dnsyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/custom-dns.yaml&#34; download=&#34;service/networking/custom-dns.yaml&#34;&gt;
                    &lt;code&gt;service/networking/custom-dns.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingcustom-dnsyaml&#39;)&#34; title=&#34;Copy service/networking/custom-dns.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Pod&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;namespace&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;default&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;dns-example&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;containers&lt;/span&gt;:
    - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;test&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;image&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;nginx&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;dnsPolicy&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;None&amp;#34;&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;dnsConfig&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;nameservers&lt;/span&gt;:
      - &lt;span style=&#34;color:#ae81ff&#34;&gt;1.2.3.4&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;searches&lt;/span&gt;:
      - &lt;span style=&#34;color:#ae81ff&#34;&gt;ns1.svc.cluster-domain.example&lt;/span&gt;
      - &lt;span style=&#34;color:#ae81ff&#34;&gt;my.dns.search.suffix&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;options&lt;/span&gt;:
      - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;ndots&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;value&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;2&amp;#34;&lt;/span&gt;
      - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;edns0&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;



When the Pod above is created, the container `test` gets the following contents
in its `/etc/resolv.conf` file:

```
nameserver 1.2.3.4
search ns1.svc.cluster-domain.example my.dns.search.suffix
options ndots:2 edns0
```

For IPv6 setup, search path and name server should be setup like this:

```shell
kubectl exec -it dns-example -- cat /etc/resolv.conf
```
The output is similar to this:
```shell
nameserver fd00:79:30::a
search default.svc.cluster-domain.example svc.cluster-domain.example cluster-domain.example
options ndots:5
```
 --&gt;
&lt;h3 id=&#34;pod-dns-config&#34;&gt;Pod 的 DNS 配置&lt;/h3&gt;
&lt;p&gt;Pod&amp;rsquo;s DNS Config allows users more control on the DNS settings for a Pod.
Pod 的 DNS 配置让用户可以更多地控制 Pod 上的 DNS 配置。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;dnsConfig&lt;/code&gt; 是一个可选字段， 它可以与 &lt;code&gt;dnsPolicy&lt;/code&gt; 配置配合使用。 但是当一个 Pod 的 &lt;code&gt;dnsPolicy&lt;/code&gt;
设置为 &amp;ldquo;&lt;code&gt;None&lt;/code&gt;&amp;ldquo;时，就必须要设置 &lt;code&gt;dnsConfig&lt;/code&gt; 字段。
以下是 &lt;code&gt;dnsConfig&lt;/code&gt; 字段中用户可以配置的字段:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;nameservers&lt;/code&gt;: Pod 用作 DNS 服务的一个 IP 地址列表。 最多可以指定三个 IP 地址。
当 Pod &lt;code&gt;dnsPolicy&lt;/code&gt; 设置为 &amp;ldquo;&lt;code&gt;None&lt;/code&gt;&amp;quot;， 这个列表中至少包含一个 IP 地址，其它情况下这个字段为可选。
这个 DNS 列表会与 DNS 策略配置产生的基础 DNS 服务器合并，重复的会被删除。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;searches&lt;/code&gt;: 一个 DNS 检索列表，用于 Pod 中的主机名查找。 这个属性为可选。当设置这个字段时，
这个列表会合并到 DNS 策略配置产生的DNS 检索域名中，重复的条目会被删除。 k8s 允许最多 6 个检索域名。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;options&lt;/code&gt;: 一个可选的对象列表， 其中的每个对象有一个必要的 &lt;code&gt;name&lt;/code&gt; 属性和一个可选的 &lt;code&gt;value&lt;/code&gt; 属性。
这些属性会被合并到配置的 DNS 策略生成的选项中&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以下来一个包含自定义 DNS 配置的 Pod 的示例:&lt;/p&gt;


 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingcustom-dnsyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/custom-dns.yaml&#34; download=&#34;service/networking/custom-dns.yaml&#34;&gt;
                    &lt;code&gt;service/networking/custom-dns.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingcustom-dnsyaml&#39;)&#34; title=&#34;Copy service/networking/custom-dns.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Pod&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;namespace&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;default&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;dns-example&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;containers&lt;/span&gt;:
    - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;test&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;image&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;nginx&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;dnsPolicy&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;None&amp;#34;&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;dnsConfig&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;nameservers&lt;/span&gt;:
      - &lt;span style=&#34;color:#ae81ff&#34;&gt;1.2.3.4&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;searches&lt;/span&gt;:
      - &lt;span style=&#34;color:#ae81ff&#34;&gt;ns1.svc.cluster-domain.example&lt;/span&gt;
      - &lt;span style=&#34;color:#ae81ff&#34;&gt;my.dns.search.suffix&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;options&lt;/span&gt;:
      - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;ndots&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;value&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;2&amp;#34;&lt;/span&gt;
      - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;edns0&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;当上面这个 Pod 被创建后，这个叫  &lt;code&gt;test&lt;/code&gt; 容器中的 &lt;code&gt;/etc/resolv.conf&lt;/code&gt; 就会有下面的这些内容:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nameserver 1.2.3.4
search ns1.svc.cluster-domain.example my.dns.search.suffix
options ndots:2 edns0
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;For IPv6 setup, search path and name server should be setup like this:
如果设置了 IPv6， 检索路径和DNS服务应该这么配置:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl exec -it dns-example -- cat /etc/resolv.conf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;输出结果类似:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nameserver fd00:79:30::a
search default.svc.cluster-domain.example svc.cluster-domain.example cluster-domain.example
options ndots:5
&lt;/code&gt;&lt;/pre&gt;&lt;!--
### Feature availability

The availability of Pod DNS Config and DNS Policy &#34;`None`&#34; is shown as below.

| k8s version | Feature support |
| :---------: |:-----------:|
| 1.14 | Stable |
| 1.10 | Beta (on by default)|
| 1.9 | Alpha |
 --&gt;
&lt;h3 id=&#34;feature-可用性&#34;&gt;Feature 可用性&lt;/h3&gt;
&lt;p&gt;Pod DNS 配置 和  DNS 策略的 &amp;ldquo;&lt;code&gt;None&lt;/code&gt;&amp;rdquo; 的可用性如下:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;k8s 版本&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;特性可用性&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1.14&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Stable&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1.10&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Beta (默认启用)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1.9&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Alpha&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;相关资料&#34;&gt;相关资料&lt;/h2&gt;
&lt;!--
For guidance on administering DNS configurations, check
[Configure DNS Service](/docs/tasks/administer-cluster/dns-custom-nameservers/)
 --&gt;
&lt;p&gt;DNS 配置的管理指导见
&lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/tasks/administer-cluster/dns-custom-nameservers/&#34;&gt;Configure DNS Service&lt;/a&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: 通过 Service 连接应用</title>
      <link>https://lostsquirrel.github.io/k8sDocs/docs/concepts/services-networking/connect-applications-service/</link>
      <pubDate>Mon, 14 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://lostsquirrel.github.io/k8sDocs/docs/concepts/services-networking/connect-applications-service/</guid>
      <description>
        
        
        &lt;!--
---
reviewers:
- caesarxuchao
- lavalamp
- thockin
title: Connecting Applications with Services
content_type: concept
weight: 30
---
 --&gt;
&lt;!-- overview --&gt;
&lt;!--
## The Kubernetes model for connecting containers

Now that you have a continuously running, replicated application you can expose it on a network. Before discussing the Kubernetes approach to networking, it is worthwhile to contrast it with the &#34;normal&#34; way networking works with Docker.

By default, Docker uses host-private networking, so containers can talk to other containers only if they are on the same machine. In order for Docker containers to communicate across nodes, there must be allocated ports on the machine&#39;s own IP address, which are then forwarded or proxied to the containers. This obviously means that containers must either coordinate which ports they use very carefully or ports must be allocated dynamically.

Coordinating port allocations across multiple developers or teams that provide containers is very difficult to do at scale, and exposes users to cluster-level issues outside of their control. Kubernetes assumes that pods can communicate with other pods, regardless of which host they land on. Kubernetes gives every pod its own cluster-private IP address, so you do not need to explicitly create links between pods or map container ports to host ports. This means that containers within a Pod can all reach each other&#39;s ports on localhost, and all pods in a cluster can see each other without NAT. The rest of this document elaborates on how you can run reliable services on such a networking model.

This guide uses a simple nginx server to demonstrate proof of concept.
 --&gt;
&lt;h2 id=&#34;连接到容器的-k8s-模型&#34;&gt;连接到容器的 k8s 模型&lt;/h2&gt;
&lt;p&gt;到目前为止我们有一个持续运行的多副本应用，我们可以把它暴露到一个网络中。 在讨论 k8s 的网络实现前，
值得花点时间来看看 Docker 中普通的网络是怎么工作的。&lt;/p&gt;
&lt;p&gt;默认情况下， Docker 使用私有网络，因此只有同一个主机上的容器之间可以相互通信。要使不同主机之间
的容器能够通信，必须要通过主机自己的 IP 地址加上分配端口以转发或代理的方式连接到容器。
通过这种方式很明显的一个问题就是不同容器必须要十分小心地协调怎么分配端口，或者必须动态地分配端口。&lt;/p&gt;
&lt;p&gt;大规模在多个开发者或项目组之间为容器协调端口分配是十分困难的， 并且也直接将用户暴露在无法控制的
集群级问题中。 k8s 确保 Pod 无论他们在哪个主机上，其相互之间都可以通信。k8s 会为每个 Pod 分配
集群内的私有 IP 地址，因此不需要用户显示地创建 Pod 之间的连接，也不需要做容器端口与主机端口的映射关系。
这就是说在一个 Pod 中的容器可以通过本地回环(localhost)以端口实现相互之间的通信，并且集群中
所有的 Pod 都可以在没有 NAT 的情况互相通信。 本文接下来的部分将说结阐怎么通过这个网络模型运行
可靠的服务。&lt;/p&gt;
&lt;p&gt;本文使用一个简单的 nginx 服务来演示证明这个观点。&lt;/p&gt;
&lt;!-- body --&gt;
&lt;!--
## Exposing pods to the cluster

We did this in a previous example, but let&#39;s do it once again and focus on the networking perspective.
Create an nginx Pod, and note that it has a container port specification:



 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingrun-my-nginxyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/run-my-nginx.yaml&#34; download=&#34;service/networking/run-my-nginx.yaml&#34;&gt;
                    &lt;code&gt;service/networking/run-my-nginx.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingrun-my-nginxyaml&#39;)&#34; title=&#34;Copy service/networking/run-my-nginx.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;apps/v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Deployment&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-nginx&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;selector&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;matchLabels&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;run&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-nginx&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;replicas&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;template&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;labels&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;run&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-nginx&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;containers&lt;/span&gt;:
      - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-nginx&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;image&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;nginx&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;ports&lt;/span&gt;:
        - &lt;span style=&#34;color:#f92672&#34;&gt;containerPort&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;



This makes it accessible from any node in your cluster. Check the nodes the Pod is running on:

```shell
kubectl apply -f ./run-my-nginx.yaml
kubectl get pods -l run=my-nginx -o wide
```
```
NAME                        READY     STATUS    RESTARTS   AGE       IP            NODE
my-nginx-3800858182-jr4a2   1/1       Running   0          13s       10.244.3.4    kubernetes-minion-905m
my-nginx-3800858182-kna2y   1/1       Running   0          13s       10.244.2.5    kubernetes-minion-ljyd
```

Check your pods&#39; IPs:

```shell
kubectl get pods -l run=my-nginx -o yaml | grep podIP
    podIP: 10.244.3.4
    podIP: 10.244.2.5
```

You should be able to ssh into any node in your cluster and curl both IPs. Note that the containers are *not* using port 80 on the node, nor are there any special NAT rules to route traffic to the pod. This means you can run multiple nginx pods on the same node all using the same containerPort and access them from any other pod or node in your cluster using IP. Like Docker, ports can still be published to the host node&#39;s interfaces, but the need for this is radically diminished because of the networking model.

You can read more about [how we achieve this](/docs/concepts/cluster-administration/networking/#how-to-achieve-this) if you&#39;re curious.
 --&gt;
&lt;h2 id=&#34;将-pod-暴露到集群中&#34;&gt;将 Pod 暴露到集群中&lt;/h2&gt;
&lt;p&gt;这是我们之间用过的一个盒子，让我们再做一次，但这次专注于网络的角度。 创建一个 nginx 的 Pod，
注意这个定义中有关于端口的定义:&lt;/p&gt;


 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingrun-my-nginxyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/run-my-nginx.yaml&#34; download=&#34;service/networking/run-my-nginx.yaml&#34;&gt;
                    &lt;code&gt;service/networking/run-my-nginx.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingrun-my-nginxyaml&#39;)&#34; title=&#34;Copy service/networking/run-my-nginx.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;apps/v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Deployment&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-nginx&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;selector&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;matchLabels&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;run&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-nginx&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;replicas&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;template&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;labels&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;run&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-nginx&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;containers&lt;/span&gt;:
      - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-nginx&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;image&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;nginx&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;ports&lt;/span&gt;:
        - &lt;span style=&#34;color:#f92672&#34;&gt;containerPort&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;


&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl apply -f ./run-my-nginx.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这使用它可以从集群中的任意节点访问。通过以下命令查看 Pod 运行在哪个节点上&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl get pods -l run&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;my-nginx -o wide
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;NAME                        READY     STATUS    RESTARTS   AGE       IP            NODE
my-nginx-3800858182-jr4a2   1/1       Running   0          13s       10.244.3.4    kubernetes-minion-905m
my-nginx-3800858182-kna2y   1/1       Running   0          13s       10.244.2.5    kubernetes-minion-ljyd
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;查看 Pod 的 IP 地址:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl get pods -l run&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;my-nginx -o yaml | grep podIP
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;podIP: 10.244.3.4
podIP: 10.244.2.5
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;用户可以通过 ssh 连接到集群中的任意节点，并通过 curl 命令访问以上两个 IP。 要注意容器并 &lt;em&gt;没有&lt;/em&gt;
使用节点上的 80 端口，也没有任何特殊的 NAT 规则将流量路由到 Pod。 也就是说用户可以在同一个节点
上使用一样的 &lt;code&gt;containerPort&lt;/code&gt; 运行多个 nginx 的 Pod， 并且可以从集群中任意 Pod 或 节点使用
它的 IP 访问它。 与 Docker 一样， 端口也可以发布到主机的网卡上， 因为网络模型的原因，应该尽量减少这
种方式的使用。&lt;/p&gt;
&lt;p&gt;如果用户比较好奇这个是怎么实现的见 &lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/docs/concepts/cluster-administration/networking/#how-to-achieve-this&#34;&gt;这里&lt;/a&gt;&lt;/p&gt;
&lt;!--
## Creating a Service

So we have pods running nginx in a flat, cluster wide, address space. In theory, you could talk to these pods directly, but what happens when a node dies? The pods die with it, and the Deployment will create new ones, with different IPs. This is the problem a Service solves.

A Kubernetes Service is an abstraction which defines a logical set of Pods running somewhere in your cluster, that all provide the same functionality. When created, each Service is assigned a unique IP address (also called clusterIP). This address is tied to the lifespan of the Service, and will not change while the Service is alive. Pods can be configured to talk to the Service, and know that communication to the Service will be automatically load-balanced out to some pod that is a member of the Service.

You can create a Service for your 2 nginx replicas with `kubectl expose`:

```shell
kubectl expose deployment/my-nginx
```
```
service/my-nginx exposed
```

This is equivalent to `kubectl apply -f` the following yaml:



 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingnginx-svcyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/nginx-svc.yaml&#34; download=&#34;service/networking/nginx-svc.yaml&#34;&gt;
                    &lt;code&gt;service/networking/nginx-svc.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingnginx-svcyaml&#39;)&#34; title=&#34;Copy service/networking/nginx-svc.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Service&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-nginx&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;labels&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;run&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-nginx&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;ports&lt;/span&gt;:
  - &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;protocol&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;TCP&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;selector&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;run&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-nginx&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;



This specification will create a Service which targets TCP port 80 on any Pod
with the `run: my-nginx` label, and expose it on an abstracted Service port
(`targetPort`: is the port the container accepts traffic on, `port`: is the
abstracted Service port, which can be any port other pods use to access the
Service).
View [Service](/docs/reference/generated/kubernetes-api/v1.19/#service-v1-core)
API object to see the list of supported fields in service definition.
Check your Service:

```shell
kubectl get svc my-nginx
```
```
NAME       TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE
my-nginx   ClusterIP   10.0.162.149   &lt;none&gt;        80/TCP    21s
```

As mentioned previously, a Service is backed by a group of Pods. These Pods are
exposed through `endpoints`. The Service&#39;s selector will be evaluated continuously
and the results will be POSTed to an Endpoints object also named `my-nginx`.
When a Pod dies, it is automatically removed from the endpoints, and new Pods
matching the Service&#39;s selector will automatically get added to the endpoints.
Check the endpoints, and note that the IPs are the same as the Pods created in
the first step:

```shell
kubectl describe svc my-nginx
```
```
Name:                my-nginx
Namespace:           default
Labels:              run=my-nginx
Annotations:         &lt;none&gt;
Selector:            run=my-nginx
Type:                ClusterIP
IP:                  10.0.162.149
Port:                &lt;unset&gt; 80/TCP
Endpoints:           10.244.2.5:80,10.244.3.4:80
Session Affinity:    None
Events:              &lt;none&gt;
```
```shell
kubectl get ep my-nginx
```
```
NAME       ENDPOINTS                     AGE
my-nginx   10.244.2.5:80,10.244.3.4:80   1m
```

You should now be able to curl the nginx Service on `&lt;CLUSTER-IP&gt;:&lt;PORT&gt;` from
any node in your cluster. Note that the Service IP is completely virtual, it
never hits the wire. If you&#39;re curious about how this works you can read more
about the [service proxy](/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies).
 --&gt;
&lt;h2 id=&#34;创建一个-service&#34;&gt;创建一个 Service&lt;/h2&gt;
&lt;p&gt;这样我们就一个集群范围以平铺方式地址空间运行 nginx 的 Pod. 理论上，用户可以直接与这些 Pod 通信，
但是要是一个节点挂了会发生什么呢? 节点上面的 Pod 也会跟着一起挂掉， 然后 Deployment 会创建
新的 Pod， 但这些 Pod 的 IP 已经不是之前的了。 这就是 Service 要解决的问题。&lt;/p&gt;
&lt;p&gt;一个 k8s 的 Service 就是对定义了一个集群中运行的提供同样功能的 Pod 的逻辑集合的抽象。每个
Service 被创建了以后都会被分配一个唯一的 IP 地址(也被称为集群IP(clusterIP)). 这个地址与该
Service 一生相伴，在 Service 的整个生命期内都不会改变。 Pod 也可以被配置为与 Service 通信，
访问 Service 的请求会被负载均衡到该 Service 所属的一个 Pod 上。&lt;/p&gt;
&lt;p&gt;可以通过如下 &lt;code&gt;kubectl expose&lt;/code&gt; 为上面的两个 nginx 副本创建一个 Service:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl expose deployment/my-nginx
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;service/my-nginx exposed
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这个命令与 &lt;code&gt;kubectl apply -f&lt;/code&gt; 下面这个 yaml 文件等效:&lt;/p&gt;


 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingnginx-svcyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/nginx-svc.yaml&#34; download=&#34;service/networking/nginx-svc.yaml&#34;&gt;
                    &lt;code&gt;service/networking/nginx-svc.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingnginx-svcyaml&#39;)&#34; title=&#34;Copy service/networking/nginx-svc.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Service&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-nginx&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;labels&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;run&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-nginx&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;ports&lt;/span&gt;:
  - &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;protocol&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;TCP&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;selector&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;run&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-nginx&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;这个配置文件中定义会创建一个 Service, 这个 Service 的目标为任意一个标签为 &lt;code&gt;run: my-nginx&lt;/code&gt;
的 Pod 的 TCP 80 端口，并将这些端口暴露在一个抽象的 Service 端口(&lt;code&gt;targetPort&lt;/code&gt;: 是容器
接收流量的端口，&lt;code&gt;port&lt;/code&gt;: 是抽象 Service 的端口，可以是任意端口，用于其它的 Pod 访问该 Service)
&lt;a href=&#34;https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.19/#service-v1-core&#34;&gt;Service&lt;/a&gt;
的 API 对象中有所有 Service 定义支持的字段列表。&lt;/p&gt;
&lt;p&gt;查看创建的 Service:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl get svc my-nginx
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;NAME       TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE
my-nginx   ClusterIP   10.0.162.149   &amp;lt;none&amp;gt;        80/TCP    21s
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;就如之前提到的，一个 Service 背后都有一组(个) Pod. 这些 Pod 是通过 &lt;code&gt;Endpoint&lt;/code&gt; 来暴露的。
Service 会持续执行然后将结果通过 POST 请求到一个也叫 &lt;code&gt;my-nginx&lt;/code&gt; 的 Endpoint 对象。当有一个
Pod 挂掉时，该 Pod 的端点会自动从 Endpoint 上移除，当有一个新的 Pod 匹配 Service 的选择器
时也会自动添加到 Endpoint 上。 检查 Endpoint， 可以看到上面的 IP 地址与第一步 Pod 创建时的 IP 地址
是一样的&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl describe svc my-nginx
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Name:                my-nginx
Namespace:           default
Labels:              run=my-nginx
Annotations:         &amp;lt;none&amp;gt;
Selector:            run=my-nginx
Type:                ClusterIP
IP:                  10.0.162.149
Port:                &amp;lt;unset&amp;gt; 80/TCP
Endpoints:           10.244.2.5:80,10.244.3.4:80
Session Affinity:    None
Events:              &amp;lt;none&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl get ep my-nginx
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;NAME       ENDPOINTS                     AGE
my-nginx   10.244.2.5:80,10.244.3.4:80   1m
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这个时候就能在集群中的任意一个 Pod 中通过 curl 访问 &lt;code&gt;&amp;lt;CLUSTER-IP&amp;gt;:&amp;lt;PORT&amp;gt;&lt;/code&gt; 来访问这个 nginx
的 Service.  要注意 Service 的 IP 完全是虚拟的。 如果用户对此有兴趣可以看看
&lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies&#34;&gt;service proxy&lt;/a&gt;.&lt;/p&gt;
&lt;!--
## Accessing the Service

Kubernetes supports 2 primary modes of finding a Service - environment variables
and DNS. The former works out of the box while the latter requires the
[CoreDNS cluster addon](https://releases.k8s.io/master/cluster/addons/dns/coredns).
&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; If the service environment variables are not desired (because possible clashing with expected program ones,
too many variables to process, only using DNS, etc) you can disable this mode by setting the &lt;code&gt;enableServiceLinks&lt;/code&gt;
flag to &lt;code&gt;false&lt;/code&gt; on the &lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/docs/reference/generated/kubernetes-api/v1.19/#pod-v1-core&#34;&gt;pod spec&lt;/a&gt;.&lt;/div&gt;
&lt;/blockquote&gt;

 --&gt;
&lt;h2 id=&#34;访问这个-service&#34;&gt;访问这个 Service&lt;/h2&gt;
&lt;p&gt;k8s 主要有两种发现 Service 的模式 - 环境变量和 DNS。 前一个是直接可以用的(要注意顺序问题)
后一种则需要
&lt;a href=&#34;https://releases.k8s.io/master/cluster/addons/dns/coredns&#34;&gt;CoreDNS 集群插件&lt;/a&gt;
&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; 如果不需要 Service 的环境变量(因为可能与程序有冲突，需要处理的变量太多，只使用 DNS 等)， 可以
通过在
&lt;a href=&#34;https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.19/#pod-v1-core&#34;&gt;Pod 定义中&lt;/a&gt;
将 &lt;code&gt;enableServiceLinks&lt;/code&gt; 字段的值设置为 &lt;code&gt;false&lt;/code&gt; 来禁用这种模式&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/p&gt;
&lt;!--
### Environment Variables

When a Pod runs on a Node, the kubelet adds a set of environment variables for
each active Service. This introduces an ordering problem. To see why, inspect
the environment of your running nginx Pods (your Pod name will be different):

```shell
kubectl exec my-nginx-3800858182-jr4a2 -- printenv | grep SERVICE
```
```
KUBERNETES_SERVICE_HOST=10.0.0.1
KUBERNETES_SERVICE_PORT=443
KUBERNETES_SERVICE_PORT_HTTPS=443
```

Note there&#39;s no mention of your Service. This is because you created the replicas
before the Service. Another disadvantage of doing this is that the scheduler might
put both Pods on the same machine, which will take your entire Service down if
it dies. We can do this the right way by killing the 2 Pods and waiting for the
Deployment to recreate them. This time around the Service exists *before* the
replicas. This will give you scheduler-level Service spreading of your Pods
(provided all your nodes have equal capacity), as well as the right environment
variables:

```shell
kubectl scale deployment my-nginx --replicas=0; kubectl scale deployment my-nginx --replicas=2;

kubectl get pods -l run=my-nginx -o wide
```
```
NAME                        READY     STATUS    RESTARTS   AGE     IP            NODE
my-nginx-3800858182-e9ihh   1/1       Running   0          5s      10.244.2.7    kubernetes-minion-ljyd
my-nginx-3800858182-j4rm4   1/1       Running   0          5s      10.244.3.8    kubernetes-minion-905m
```

You may notice that the pods have different names, since they are killed and recreated.

```shell
kubectl exec my-nginx-3800858182-e9ihh -- printenv | grep SERVICE
```
```
KUBERNETES_SERVICE_PORT=443
MY_NGINX_SERVICE_HOST=10.0.162.149
KUBERNETES_SERVICE_HOST=10.0.0.1
MY_NGINX_SERVICE_PORT=80
KUBERNETES_SERVICE_PORT_HTTPS=443
```
 --&gt;
&lt;h3 id=&#34;环境变量&#34;&gt;环境变量&lt;/h3&gt;
&lt;p&gt;当一个 Pod 在一个节点上运行时， kubelet 为会每个活跃的 Service 添加一系列环境变量。这会引入
一个顺序问题。为啥呢，先看看现在运行的 nginx Pod 的环境变量(Pod 名称根据实际会不同)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl exec my-nginx-3800858182-jr4a2 -- printenv | grep SERVICE
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;KUBERNETES_SERVICE_HOST=10.0.0.1
KUBERNETES_SERVICE_PORT=443
KUBERNETES_SERVICE_PORT_HTTPS=443
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;可以看到没有 nginx Service 的信息。 这是因为这些 Pod 副本是在 Service 之前创建的。另一个缺点
是调度器可能将两个 Pod 都丢到一个节点点上，如果这个节点挂了，则整个 Service 也就挂了。这时候
先杀掉这两个 Pod 然后等 Deployment 重建。 这样 Service 就在这些 Pod 创建 &lt;em&gt;之前&lt;/em&gt; 就存在了.
这样就会让 Pod 在 Service 的调度级别(所有节点均匀分布)，同时环境变量也有了:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl scale deployment my-nginx --replicas&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;0; kubectl scale deployment my-nginx --replicas&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;2;

kubectl get pods -l run&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;my-nginx -o wide
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;NAME                        READY     STATUS    RESTARTS   AGE     IP            NODE
my-nginx-3800858182-e9ihh   1/1       Running   0          5s      10.244.2.7    kubernetes-minion-ljyd
my-nginx-3800858182-j4rm4   1/1       Running   0          5s      10.244.3.8    kubernetes-minion-905m
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这时候可以看到 Pod 的名称也变了，因为它们被干掉然后重建了。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl exec my-nginx-3800858182-e9ihh -- printenv | grep SERVICE
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;KUBERNETES_SERVICE_PORT=443
MY_NGINX_SERVICE_HOST=10.0.162.149
KUBERNETES_SERVICE_HOST=10.0.0.1
MY_NGINX_SERVICE_PORT=80
KUBERNETES_SERVICE_PORT_HTTPS=443
&lt;/code&gt;&lt;/pre&gt;&lt;!--
### DNS

Kubernetes offers a DNS cluster addon Service that automatically assigns dns names to other Services. You can check if it&#39;s running on your cluster:

```shell
kubectl get services kube-dns --namespace=kube-system
```
```
NAME       TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)         AGE
kube-dns   ClusterIP   10.0.0.10    &lt;none&gt;        53/UDP,53/TCP   8m
```

The rest of this section will assume you have a Service with a long lived IP
(my-nginx), and a DNS server that has assigned a name to that IP. Here we use the CoreDNS cluster addon (application name `kube-dns`), so you can talk to the Service from any pod in your cluster using standard methods (e.g. `gethostbyname()`). If CoreDNS isn&#39;t running, you can enable it referring to the [CoreDNS README](https://github.com/coredns/deployment/tree/master/kubernetes) or [Installing CoreDNS](/docs/tasks/administer-cluster/coredns/#installing-coredns). Let&#39;s run another curl application to test this:

```shell
kubectl run curl --image=radial/busyboxplus:curl -i --tty
```
```
Waiting for pod default/curl-131556218-9fnch to be running, status is Pending, pod ready: false
Hit enter for command prompt
```

Then, hit enter and run `nslookup my-nginx`:

```shell
[ root@curl-131556218-9fnch:/ ]$ nslookup my-nginx
Server:    10.0.0.10
Address 1: 10.0.0.10

Name:      my-nginx
Address 1: 10.0.162.149
```
 --&gt;
&lt;h3 id=&#34;dns&#34;&gt;DNS&lt;/h3&gt;
&lt;p&gt;k8s 提供了一个 DNS 集群插件的 Service, 它会自动地为其它的 Service 分配 DNS 名称。
可以通过以下命令查看集群中是否运行了该服务:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl get services kube-dns --namespace&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;kube-system
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;NAME       TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)         AGE
kube-dns   ClusterIP   10.0.0.10    &amp;lt;none&amp;gt;        53/UDP,53/TCP   8m
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;本节接下来部分假设有一个拥有长期存在 IP 的 Service (my-nginx), 并且 DNS 服务为这个 IP
分配了一个名称。 这里我们使用的是 CoreDNS 集群插件(应用名称为 &lt;code&gt;kube-dns&lt;/code&gt;)， 因此可以在集群中
的任意一个 Pod 通过标准方式(例如，&lt;code&gt;gethostbyname()&lt;/code&gt; ) 与这个 Service 通信。 如果没有 CoreDNS，
可以参考
&lt;a href=&#34;https://github.com/coredns/deployment/tree/master/kubernetes&#34;&gt;CoreDNS README&lt;/a&gt;
或
&lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/docs/tasks/administer-cluster/coredns/#installing-coredns&#34;&gt;安装 CoreDNS&lt;/a&gt;.
这时候再运行 curl 应用来验证:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl run curl --image&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;radial/busyboxplus:curl -i --tty
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Waiting for pod default/curl-131556218-9fnch to be running, status is Pending, pod ready: false
Hit enter for command prompt
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;看到以上提供，再次敲回车键，然后运行 &lt;code&gt;nslookup my-nginx&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt; root@curl-131556218-9fnch:/ &lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;$ nslookup my-nginx
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Server:    10.0.0.10
Address 1: 10.0.0.10

Name:      my-nginx
Address 1: 10.0.162.149
&lt;/code&gt;&lt;/pre&gt;&lt;!--
## Securing the Service

Till now we have only accessed the nginx server from within the cluster. Before exposing the Service to the internet, you want to make sure the communication channel is secure. For this, you will need:

* Self signed certificates for https (unless you already have an identity certificate)
* An nginx server configured to use the certificates
* A [secret](/docs/concepts/configuration/secret/) that makes the certificates accessible to pods

You can acquire all these from the [nginx https example](https://github.com/kubernetes/examples/tree/master/staging/https-nginx/). This requires having go and make tools installed. If you don&#39;t want to install those, then follow the manual steps later. In short:

```shell
make keys KEY=/tmp/nginx.key CERT=/tmp/nginx.crt
kubectl create secret tls nginxsecret --key /tmp/nginx.key --cert /tmp/nginx.crt
```
```
secret/nginxsecret created
```
```shell
kubectl get secrets
```
```
NAME                  TYPE                                  DATA      AGE
default-token-il9rc   kubernetes.io/service-account-token   1         1d
nginxsecret           kubernetes.io/tls                     2         1m
```
And also the configmap:
```shell
kubectl create configmap nginxconfigmap --from-file=default.conf
```
```
configmap/nginxconfigmap created
```
```shell
kubectl get configmaps
```
```
NAME             DATA   AGE
nginxconfigmap   1      114s
```
Following are the manual steps to follow in case you run into problems running make (on windows for example):

```shell
# Create a public private key pair
openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /d/tmp/nginx.key -out /d/tmp/nginx.crt -subj &#34;/CN=my-nginx/O=my-nginx&#34;
# Convert the keys to base64 encoding
cat /d/tmp/nginx.crt | base64
cat /d/tmp/nginx.key | base64
```
Use the output from the previous commands to create a yaml file as follows. The base64 encoded value should all be on a single line.

```yaml
apiVersion: &#34;v1&#34;
kind: &#34;Secret&#34;
metadata:
  name: &#34;nginxsecret&#34;
  namespace: &#34;default&#34;
type: kubernetes.io/tls
data:
  tls.crt: &#34;LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURIekNDQWdlZ0F3SUJBZ0lKQUp5M3lQK0pzMlpJTUEwR0NTcUdTSWIzRFFFQkJRVUFNQ1l4RVRBUEJnTlYKQkFNVENHNW5hVzU0YzNaak1SRXdEd1lEVlFRS0V3aHVaMmx1ZUhOMll6QWVGdzB4TnpFd01qWXdOekEzTVRKYQpGdzB4T0RFd01qWXdOekEzTVRKYU1DWXhFVEFQQmdOVkJBTVRDRzVuYVc1NGMzWmpNUkV3RHdZRFZRUUtFd2h1CloybHVlSE4yWXpDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBSjFxSU1SOVdWM0IKMlZIQlRMRmtobDRONXljMEJxYUhIQktMSnJMcy8vdzZhU3hRS29GbHlJSU94NGUrMlN5ajBFcndCLzlYTnBwbQppeW1CL3JkRldkOXg5UWhBQUxCZkVaTmNiV3NsTVFVcnhBZW50VWt1dk1vLzgvMHRpbGhjc3paenJEYVJ4NEo5Ci82UVRtVVI3a0ZTWUpOWTVQZkR3cGc3dlVvaDZmZ1Voam92VG42eHNVR0M2QURVODBpNXFlZWhNeVI1N2lmU2YKNHZpaXdIY3hnL3lZR1JBRS9mRTRqakxCdmdONjc2SU90S01rZXV3R0ljNDFhd05tNnNTSzRqYUNGeGpYSnZaZQp2by9kTlEybHhHWCtKT2l3SEhXbXNhdGp4WTRaNVk3R1ZoK0QrWnYvcW1mMFgvbVY0Rmo1NzV3ajFMWVBocWtsCmdhSXZYRyt4U1FVQ0F3RUFBYU5RTUU0d0hRWURWUjBPQkJZRUZPNG9OWkI3YXc1OUlsYkROMzhIYkduYnhFVjcKTUI4R0ExVWRJd1FZTUJhQUZPNG9OWkI3YXc1OUlsYkROMzhIYkduYnhFVjdNQXdHQTFVZEV3UUZNQU1CQWY4dwpEUVlKS29aSWh2Y05BUUVGQlFBRGdnRUJBRVhTMW9FU0lFaXdyMDhWcVA0K2NwTHI3TW5FMTducDBvMm14alFvCjRGb0RvRjdRZnZqeE04Tzd2TjB0clcxb2pGSW0vWDE4ZnZaL3k4ZzVaWG40Vm8zc3hKVmRBcStNZC9jTStzUGEKNmJjTkNUekZqeFpUV0UrKzE5NS9zb2dmOUZ3VDVDK3U2Q3B5N0M3MTZvUXRUakViV05VdEt4cXI0Nk1OZWNCMApwRFhWZmdWQTRadkR4NFo3S2RiZDY5eXM3OVFHYmg5ZW1PZ05NZFlsSUswSGt0ejF5WU4vbVpmK3FqTkJqbWZjCkNnMnlwbGQ0Wi8rUUNQZjl3SkoybFIrY2FnT0R4elBWcGxNSEcybzgvTHFDdnh6elZPUDUxeXdLZEtxaUMwSVEKQ0I5T2wwWW5scE9UNEh1b2hSUzBPOStlMm9KdFZsNUIyczRpbDlhZ3RTVXFxUlU9Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K&#34;
  tls.key: &#34;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&#34;
```
Now create the secrets using the file:

```shell
kubectl apply -f nginxsecrets.yaml
kubectl get secrets
```
```
NAME                  TYPE                                  DATA      AGE
default-token-il9rc   kubernetes.io/service-account-token   1         1d
nginxsecret           kubernetes.io/tls                     2         1m
```

Now modify your nginx replicas to start an https server using the certificate in the secret, and the Service, to expose both ports (80 and 443):



 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingnginx-secure-appyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/nginx-secure-app.yaml&#34; download=&#34;service/networking/nginx-secure-app.yaml&#34;&gt;
                    &lt;code&gt;service/networking/nginx-secure-app.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingnginx-secure-appyaml&#39;)&#34; title=&#34;Copy service/networking/nginx-secure-app.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Service&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-nginx&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;labels&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;run&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-nginx&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;type&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;NodePort&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;ports&lt;/span&gt;:
  - &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;8080&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;targetPort&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;protocol&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;TCP&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;http&lt;/span&gt;
  - &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;443&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;protocol&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;TCP&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;https&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;selector&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;run&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-nginx&lt;/span&gt;
---
&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;apps/v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Deployment&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-nginx&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;selector&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;matchLabels&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;run&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-nginx&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;replicas&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;template&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;labels&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;run&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-nginx&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;volumes&lt;/span&gt;:
      - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;secret-volume&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;secret&lt;/span&gt;:
          &lt;span style=&#34;color:#f92672&#34;&gt;secretName&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;nginxsecret&lt;/span&gt;
      - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;configmap-volume&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;configMap&lt;/span&gt;:
          &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;nginxconfigmap&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;containers&lt;/span&gt;:
      - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;nginxhttps&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;image&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;bprashanth/nginxhttps:1.0&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;ports&lt;/span&gt;:
        - &lt;span style=&#34;color:#f92672&#34;&gt;containerPort&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;443&lt;/span&gt;
        - &lt;span style=&#34;color:#f92672&#34;&gt;containerPort&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;volumeMounts&lt;/span&gt;:
        - &lt;span style=&#34;color:#f92672&#34;&gt;mountPath&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;/etc/nginx/ssl&lt;/span&gt;
          &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;secret-volume&lt;/span&gt;
        - &lt;span style=&#34;color:#f92672&#34;&gt;mountPath&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;/etc/nginx/conf.d&lt;/span&gt;
          &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;configmap-volume&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;



Noteworthy points about the nginx-secure-app manifest:

- It contains both Deployment and Service specification in the same file.
- The [nginx server](https://github.com/kubernetes/examples/tree/master/staging/https-nginx/default.conf)
  serves HTTP traffic on port 80 and HTTPS traffic on 443, and nginx Service
  exposes both ports.
- Each container has access to the keys through a volume mounted at `/etc/nginx/ssl`.
  This is setup *before* the nginx server is started.

```shell
kubectl delete deployments,svc my-nginx; kubectl create -f ./nginx-secure-app.yaml
```

At this point you can reach the nginx server from any node.

```shell
kubectl get pods -o yaml | grep -i podip
    podIP: 10.244.3.5
node $ curl -k https://10.244.3.5
...
&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;
```

Note how we supplied the `-k` parameter to curl in the last step, this is because we don&#39;t know anything about the pods running nginx at certificate generation time,
so we have to tell curl to ignore the CName mismatch. By creating a Service we linked the CName used in the certificate with the actual DNS name used by pods during Service lookup.
Let&#39;s test this from a pod (the same secret is being reused for simplicity, the pod only needs nginx.crt to access the Service):



 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingcurlpodyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/curlpod.yaml&#34; download=&#34;service/networking/curlpod.yaml&#34;&gt;
                    &lt;code&gt;service/networking/curlpod.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingcurlpodyaml&#39;)&#34; title=&#34;Copy service/networking/curlpod.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;apps/v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Deployment&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;curl-deployment&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;selector&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;matchLabels&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;app&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;curlpod&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;replicas&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;template&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;labels&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;app&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;curlpod&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;volumes&lt;/span&gt;:
      - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;secret-volume&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;secret&lt;/span&gt;:
          &lt;span style=&#34;color:#f92672&#34;&gt;secretName&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;nginxsecret&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;containers&lt;/span&gt;:
      - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;curlpod&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;command&lt;/span&gt;:
        - &lt;span style=&#34;color:#ae81ff&#34;&gt;sh&lt;/span&gt;
        - -&lt;span style=&#34;color:#ae81ff&#34;&gt;c&lt;/span&gt;
        - &lt;span style=&#34;color:#ae81ff&#34;&gt;while true; do sleep 1; done&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;image&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;radial/busyboxplus:curl&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;volumeMounts&lt;/span&gt;:
        - &lt;span style=&#34;color:#f92672&#34;&gt;mountPath&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;/etc/nginx/ssl&lt;/span&gt;
          &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;secret-volume&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;



```shell
kubectl apply -f ./curlpod.yaml
kubectl get pods -l app=curlpod
```
```
NAME                               READY     STATUS    RESTARTS   AGE
curl-deployment-1515033274-1410r   1/1       Running   0          1m
```
```shell
kubectl exec curl-deployment-1515033274-1410r -- curl https://my-nginx --cacert /etc/nginx/ssl/tls.crt
...
&lt;title&gt;Welcome to nginx!&lt;/title&gt;
...
```
 --&gt;
&lt;h2 id=&#34;为-service-加安全层&#34;&gt;为 Service 加安全层&lt;/h2&gt;
&lt;p&gt;到目前为止我们都是在集群内访问这个 nginx 服务。 在将这个 Service 暴露到互联网之前，需要确保
连接是安全。 因此，必须要:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Self signed certificates for https (unless you already have an identity certificate)&lt;/li&gt;
&lt;li&gt;An nginx server configured to use the certificates&lt;/li&gt;
&lt;li&gt;A &lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/docs/concepts/configuration/secret/&#34;&gt;secret&lt;/a&gt; that makes the certificates accessible to pods&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;创建一个自签的 https 证书(除非已经有对应的证书)&lt;/li&gt;
&lt;li&gt;配置一个使用该证书的 nginx 服务&lt;/li&gt;
&lt;li&gt;创建一个 &lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/docs/concepts/configuration/secret/&#34;&gt;Secret&lt;/a&gt;， 让证书在 Pod 中可用&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所有的这些都可以参考
&lt;a href=&#34;https://github.com/kubernetes/examples/tree/master/staging/https-nginx&#34;&gt;nginx https 示例&lt;/a&gt;
这个需要有 go 环境和安装打包工具。如果不想安装这些， 则跟着下面步骤手动操作， 简单说:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;make keys KEY&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;/tmp/nginx.key CERT&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;/tmp/nginx.crt
kubectl create secret tls nginxsecret --key /tmp/nginx.key --cert /tmp/nginx.crt
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;secret/nginxsecret created
&lt;/code&gt;&lt;/pre&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl get secrets
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;NAME                  TYPE                                  DATA      AGE
default-token-il9rc   kubernetes.io/service-account-token   1         1d
nginxsecret           kubernetes.io/tls                     2         1m
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;再创建 Configmap:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl create configmap nginxconfigmap --from-file&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;default.conf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;configmap/nginxconfigmap created
&lt;/code&gt;&lt;/pre&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl get configmaps
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;NAME             DATA   AGE
nginxconfigmap   1      114s
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如果运行 make 有问题，则跟随下面的手动步骤操作(比如在 windows 上):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Create a public private key pair&lt;/span&gt;
openssl req -x509 -nodes -days &lt;span style=&#34;color:#ae81ff&#34;&gt;365&lt;/span&gt; -newkey rsa:2048 -keyout /d/tmp/nginx.key -out /d/tmp/nginx.crt -subj &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/CN=my-nginx/O=my-nginx&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# Convert the keys to base64 encoding&lt;/span&gt;
cat /d/tmp/nginx.crt | base64
cat /d/tmp/nginx.key | base64
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Use the output from the previous commands to create a yaml file as follows. The base64 encoded value should all be on a single line.
使用上面的输出创建以下的 yaml 配置文件。 base64 编码的内容应该只有一行。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;v1&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Secret&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;nginxsecret&amp;#34;&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;namespace&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;default&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;type&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;kubernetes.io/tls&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;data&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;tls.crt&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURIekNDQWdlZ0F3SUJBZ0lKQUp5M3lQK0pzMlpJTUEwR0NTcUdTSWIzRFFFQkJRVUFNQ1l4RVRBUEJnTlYKQkFNVENHNW5hVzU0YzNaak1SRXdEd1lEVlFRS0V3aHVaMmx1ZUhOMll6QWVGdzB4TnpFd01qWXdOekEzTVRKYQpGdzB4T0RFd01qWXdOekEzTVRKYU1DWXhFVEFQQmdOVkJBTVRDRzVuYVc1NGMzWmpNUkV3RHdZRFZRUUtFd2h1CloybHVlSE4yWXpDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBSjFxSU1SOVdWM0IKMlZIQlRMRmtobDRONXljMEJxYUhIQktMSnJMcy8vdzZhU3hRS29GbHlJSU94NGUrMlN5ajBFcndCLzlYTnBwbQppeW1CL3JkRldkOXg5UWhBQUxCZkVaTmNiV3NsTVFVcnhBZW50VWt1dk1vLzgvMHRpbGhjc3paenJEYVJ4NEo5Ci82UVRtVVI3a0ZTWUpOWTVQZkR3cGc3dlVvaDZmZ1Voam92VG42eHNVR0M2QURVODBpNXFlZWhNeVI1N2lmU2YKNHZpaXdIY3hnL3lZR1JBRS9mRTRqakxCdmdONjc2SU90S01rZXV3R0ljNDFhd05tNnNTSzRqYUNGeGpYSnZaZQp2by9kTlEybHhHWCtKT2l3SEhXbXNhdGp4WTRaNVk3R1ZoK0QrWnYvcW1mMFgvbVY0Rmo1NzV3ajFMWVBocWtsCmdhSXZYRyt4U1FVQ0F3RUFBYU5RTUU0d0hRWURWUjBPQkJZRUZPNG9OWkI3YXc1OUlsYkROMzhIYkduYnhFVjcKTUI4R0ExVWRJd1FZTUJhQUZPNG9OWkI3YXc1OUlsYkROMzhIYkduYnhFVjdNQXdHQTFVZEV3UUZNQU1CQWY4dwpEUVlKS29aSWh2Y05BUUVGQlFBRGdnRUJBRVhTMW9FU0lFaXdyMDhWcVA0K2NwTHI3TW5FMTducDBvMm14alFvCjRGb0RvRjdRZnZqeE04Tzd2TjB0clcxb2pGSW0vWDE4ZnZaL3k4ZzVaWG40Vm8zc3hKVmRBcStNZC9jTStzUGEKNmJjTkNUekZqeFpUV0UrKzE5NS9zb2dmOUZ3VDVDK3U2Q3B5N0M3MTZvUXRUakViV05VdEt4cXI0Nk1OZWNCMApwRFhWZmdWQTRadkR4NFo3S2RiZDY5eXM3OVFHYmg5ZW1PZ05NZFlsSUswSGt0ejF5WU4vbVpmK3FqTkJqbWZjCkNnMnlwbGQ0Wi8rUUNQZjl3SkoybFIrY2FnT0R4elBWcGxNSEcybzgvTHFDdnh6elZPUDUxeXdLZEtxaUMwSVEKQ0I5T2wwWW5scE9UNEh1b2hSUzBPOStlMm9KdFZsNUIyczRpbDlhZ3RTVXFxUlU9Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K&amp;#34;&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;tls.key&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;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&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;然后使用这引文件创建 Secret：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl apply -f nginxsecrets.yaml
kubectl get secrets
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;NAME                  TYPE                                  DATA      AGE
default-token-il9rc   kubernetes.io/service-account-token   1         1d
nginxsecret           kubernetes.io/tls                     2         1m
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这时候修改 nginx 副本使用 Secret 中的证书启动一个 https 服务。 Service 也需要同时暴露 80 和 443 端口:&lt;/p&gt;


 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingnginx-secure-appyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/nginx-secure-app.yaml&#34; download=&#34;service/networking/nginx-secure-app.yaml&#34;&gt;
                    &lt;code&gt;service/networking/nginx-secure-app.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingnginx-secure-appyaml&#39;)&#34; title=&#34;Copy service/networking/nginx-secure-app.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Service&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-nginx&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;labels&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;run&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-nginx&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;type&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;NodePort&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;ports&lt;/span&gt;:
  - &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;8080&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;targetPort&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;protocol&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;TCP&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;http&lt;/span&gt;
  - &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;443&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;protocol&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;TCP&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;https&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;selector&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;run&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-nginx&lt;/span&gt;
---
&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;apps/v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Deployment&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-nginx&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;selector&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;matchLabels&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;run&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-nginx&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;replicas&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;template&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;labels&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;run&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-nginx&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;volumes&lt;/span&gt;:
      - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;secret-volume&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;secret&lt;/span&gt;:
          &lt;span style=&#34;color:#f92672&#34;&gt;secretName&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;nginxsecret&lt;/span&gt;
      - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;configmap-volume&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;configMap&lt;/span&gt;:
          &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;nginxconfigmap&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;containers&lt;/span&gt;:
      - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;nginxhttps&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;image&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;bprashanth/nginxhttps:1.0&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;ports&lt;/span&gt;:
        - &lt;span style=&#34;color:#f92672&#34;&gt;containerPort&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;443&lt;/span&gt;
        - &lt;span style=&#34;color:#f92672&#34;&gt;containerPort&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;volumeMounts&lt;/span&gt;:
        - &lt;span style=&#34;color:#f92672&#34;&gt;mountPath&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;/etc/nginx/ssl&lt;/span&gt;
          &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;secret-volume&lt;/span&gt;
        - &lt;span style=&#34;color:#f92672&#34;&gt;mountPath&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;/etc/nginx/conf.d&lt;/span&gt;
          &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;configmap-volume&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;需要重点注意 nginx-secure-app 的地方:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在同一个文件中包含了 Deployment 和 Service 的定义配置。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubernetes/examples/tree/master/staging/https-nginx/default.conf&#34;&gt;nginx 服务器&lt;/a&gt;
同时在 80 端口提供 HTTP 流量和 443 端口提供 HTTPS 流量， nginx Service 同时暴露了这两个端口。&lt;/li&gt;
&lt;li&gt;每个容器都通过挂载在  &lt;code&gt;/etc/nginx/ssl&lt;/code&gt; 的数据卷来访问证书
因此需要在 nginx 服务启动 &lt;em&gt;之前&lt;/em&gt; 配置好&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl delete deployments,svc my-nginx; kubectl create -f ./nginx-secure-app.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这时候就可以在任意一个节点上访问这个 nginx 服务&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl get pods -o yaml | grep -i podip
    podIP: 10.244.3.5
node $ curl -k https://10.244.3.5
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;...
&amp;lt;h1&amp;gt;Welcome to nginx!&amp;lt;/h1&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;注意这里最后一步中的 curl 使用用了 &lt;code&gt;-k&lt;/code&gt;， 因为在创建证书的时候不会知道运行 nginx 的 Pod的
任何信息， 因此要让 curl 忽略 CName 不匹配的问题。通过创建一个 Service, 就可以把证书中的
CName 和 Pod 在对 Service 解析使用的 DNS 名称统一起来。
在一个 Pod 中再测试一下(为了简单使用同一个 Secret, 这个 Pod 访问 Service 只需要 nginx.crt)&lt;/p&gt;


 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingcurlpodyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/curlpod.yaml&#34; download=&#34;service/networking/curlpod.yaml&#34;&gt;
                    &lt;code&gt;service/networking/curlpod.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingcurlpodyaml&#39;)&#34; title=&#34;Copy service/networking/curlpod.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;apps/v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Deployment&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;curl-deployment&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;selector&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;matchLabels&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;app&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;curlpod&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;replicas&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;template&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;labels&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;app&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;curlpod&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;volumes&lt;/span&gt;:
      - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;secret-volume&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;secret&lt;/span&gt;:
          &lt;span style=&#34;color:#f92672&#34;&gt;secretName&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;nginxsecret&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;containers&lt;/span&gt;:
      - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;curlpod&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;command&lt;/span&gt;:
        - &lt;span style=&#34;color:#ae81ff&#34;&gt;sh&lt;/span&gt;
        - -&lt;span style=&#34;color:#ae81ff&#34;&gt;c&lt;/span&gt;
        - &lt;span style=&#34;color:#ae81ff&#34;&gt;while true; do sleep 1; done&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;image&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;radial/busyboxplus:curl&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;volumeMounts&lt;/span&gt;:
        - &lt;span style=&#34;color:#f92672&#34;&gt;mountPath&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;/etc/nginx/ssl&lt;/span&gt;
          &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;secret-volume&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;


&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl apply -f ./curlpod.yaml
kubectl get pods -l app&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;curlpod
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;NAME                               READY     STATUS    RESTARTS   AGE
curl-deployment-1515033274-1410r   1/1       Running   0          1m
&lt;/code&gt;&lt;/pre&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl exec curl-deployment-1515033274-1410r -- curl https://my-nginx --cacert /etc/nginx/ssl/tls.crt
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;...
&amp;lt;title&amp;gt;Welcome to nginx!&amp;lt;/title&amp;gt;
...
&lt;/code&gt;&lt;/pre&gt;&lt;!--
## Exposing the Service

For some parts of your applications you may want to expose a Service onto an
external IP address. Kubernetes supports two ways of doing this: NodePorts and
LoadBalancers. The Service created in the last section already used `NodePort`,
so your nginx HTTPS replica is ready to serve traffic on the internet if your
node has a public IP.

```shell
kubectl get svc my-nginx -o yaml | grep nodePort -C 5
  uid: 07191fb3-f61a-11e5-8ae5-42010af00002
spec:
  clusterIP: 10.0.162.149
  ports:
  - name: http
    nodePort: 31704
    port: 8080
    protocol: TCP
    targetPort: 80
  - name: https
    nodePort: 32453
    port: 443
    protocol: TCP
    targetPort: 443
  selector:
    run: my-nginx
```
```shell
kubectl get nodes -o yaml | grep ExternalIP -C 1
    - address: 104.197.41.11
      type: ExternalIP
    allocatable:
--
    - address: 23.251.152.56
      type: ExternalIP
    allocatable:
...

$ curl https://&lt;EXTERNAL-IP&gt;:&lt;NODE-PORT&gt; -k
...
&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;
```

Let&#39;s now recreate the Service to use a cloud load balancer, just change the `Type` of `my-nginx` Service from `NodePort` to `LoadBalancer`:

```shell
kubectl edit svc my-nginx
kubectl get svc my-nginx
```
```
NAME       TYPE           CLUSTER-IP     EXTERNAL-IP        PORT(S)               AGE
my-nginx   LoadBalancer   10.0.162.149     xx.xxx.xxx.xxx     8080:30163/TCP        21s
```
```
curl https://&lt;EXTERNAL-IP&gt; -k
...
&lt;title&gt;Welcome to nginx!&lt;/title&gt;
```

The IP address in the `EXTERNAL-IP` column is the one that is available on the public internet.  The `CLUSTER-IP` is only available inside your
cluster/private cloud network.

Note that on AWS, type `LoadBalancer` creates an ELB, which uses a (long)
hostname, not an IP.  It&#39;s too long to fit in the standard `kubectl get svc`
output, in fact, so you&#39;ll need to do `kubectl describe service my-nginx` to
see it.  You&#39;ll see something like this:

```shell
kubectl describe service my-nginx
...
LoadBalancer Ingress:   a320587ffd19711e5a37606cf4a74574-1142138393.us-east-1.elb.amazonaws.com
...
```
 --&gt;
&lt;h2 id=&#34;暴露这个-service&#34;&gt;暴露这个 Service&lt;/h2&gt;
&lt;p&gt;For some parts of your applications you may want to expose a Service onto an
external IP address. Kubernetes supports two ways of doing this: NodePorts and
LoadBalancers. The Service created in the last section already used &lt;code&gt;NodePort&lt;/code&gt;,
so your nginx HTTPS replica is ready to serve traffic on the internet if your
node has a public IP.&lt;/p&gt;
&lt;p&gt;对于应用中的一部分，用户可能希望通过一个 Service 将其暴露到一个公网 IP 地址上。 k8s 支持两种方式:
NodePort 和 负载均衡器。 最后创建的这个 Service 已经使用了 &lt;code&gt;NodePort&lt;/code&gt;， 所以如果集群中的
节点有公网IP，这个 nginx 的 HTTPS 就可以通过公网访问。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl get svc my-nginx -o yaml | grep nodePort -C &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;uid: 07191fb3-f61a-11e5-8ae5-42010af00002
spec:
clusterIP: 10.0.162.149
ports:
- name: http
  nodePort: 31704
  port: 8080
  protocol: TCP
  targetPort: 80
- name: https
  nodePort: 32453
  port: 443
  protocol: TCP
  targetPort: 443
selector:
  run: my-nginx
&lt;/code&gt;&lt;/pre&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl get nodes -o yaml | grep ExternalIP -C &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;- address: 104.197.41.11
  type: ExternalIP
allocatable:
--
- address: 23.251.152.56
  type: ExternalIP
allocatable:
&lt;/code&gt;&lt;/pre&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;$ curl https://&amp;lt;EXTERNAL-IP&amp;gt;:&amp;lt;NODE-PORT&amp;gt; -k
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;...
&amp;lt;h1&amp;gt;Welcome to nginx!&amp;lt;/h1&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;现在修改 Service 使它使用云负载均衡器，只需要将 &lt;code&gt;my-nginx&lt;/code&gt; Service 的 &lt;code&gt;Type&lt;/code&gt; 由 &lt;code&gt;NodePort&lt;/code&gt; 改为 &lt;code&gt;LoadBalancer&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl edit svc my-nginx
kubectl get svc my-nginx
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;NAME       TYPE           CLUSTER-IP     EXTERNAL-IP        PORT(S)               AGE
my-nginx   LoadBalancer   10.0.162.149     xx.xxx.xxx.xxx     8080:30163/TCP        21s
&lt;/code&gt;&lt;/pre&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;curl https://&amp;lt;EXTERNAL-IP&amp;gt; -k
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;...
&amp;lt;title&amp;gt;Welcome to nginx!&amp;lt;/title&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The IP address in the &lt;code&gt;EXTERNAL-IP&lt;/code&gt; column is the one that is available on the public internet.  The &lt;code&gt;CLUSTER-IP&lt;/code&gt; is only available inside your
cluster/private cloud network.
&lt;code&gt;EXTERNAL-IP&lt;/code&gt; 列中的 IP 地址就是一个公网可用的地址。 &lt;code&gt;CLUSTER-IP&lt;/code&gt; 只能在集群内部使用。
Note that on AWS, type &lt;code&gt;LoadBalancer&lt;/code&gt; creates an ELB, which uses a (long)
hostname, not an IP.  It&amp;rsquo;s too long to fit in the standard &lt;code&gt;kubectl get svc&lt;/code&gt;
output, in fact, so you&amp;rsquo;ll need to do &lt;code&gt;kubectl describe service my-nginx&lt;/code&gt; to
see it.  You&amp;rsquo;ll see something like this:&lt;/p&gt;
&lt;p&gt;要注意在 AWS 上， &lt;code&gt;LoadBalancer&lt;/code&gt; 类型的 Service 会创建一个 ELB, 它会使用一个(很长的)主机名，
而不是一个 IP 地址。 因为这个主机名太长而不适配标准的 &lt;code&gt;kubectl get svc&lt;/code&gt; 输出，实际上需要使用
&lt;code&gt;kubectl describe service my-nginx&lt;/code&gt; 命令才能看当输出的这个主机名，样子就类似下面的:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl describe service my-nginx
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;...
LoadBalancer Ingress:   a320587ffd19711e5a37606cf4a74574-1142138393.us-east-1.elb.amazonaws.com
...
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;相关资料&#34;&gt;相关资料&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;实践 &lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/docs/tasks/access-application-cluster/service-access-application-cluster/&#34;&gt;使用 Service 让集群中的一个应用可以访问&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;实践 &lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/docs/tasks/access-application-cluster/connecting-frontend-backend/&#34;&gt;使用 Service 连接前后端应用&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;实践 &lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/docs/tasks/access-application-cluster/create-external-load-balancer/&#34;&gt;创建一个外部负载均衡器&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: EndpointSlice</title>
      <link>https://lostsquirrel.github.io/k8sDocs/docs/concepts/services-networking/endpoint-slices/</link>
      <pubDate>Thu, 17 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://lostsquirrel.github.io/k8sDocs/docs/concepts/services-networking/endpoint-slices/</guid>
      <description>
        
        
        &lt;!--
---
reviewers:
- freehan
title: EndpointSlices
content_type: concept
weight: 35
---
 --&gt;
&lt;!-- overview --&gt;
&lt;!--





&lt;div style=&#34;margin-top: 10px; margin-bottom: 10px;&#34;&gt;
&lt;b&gt;功能特性状态:&lt;/b&gt; &lt;code&gt;Kubernetes v1.17 [beta]&lt;/code&gt;
&lt;/div&gt;



_EndpointSlices_ provide a simple way to track network endpoints within a
Kubernetes cluster. They offer a more scalable and extensible alternative to
Endpoints.
 --&gt;





&lt;div style=&#34;margin-top: 10px; margin-bottom: 10px;&#34;&gt;
&lt;b&gt;功能特性状态:&lt;/b&gt; &lt;code&gt;Kubernetes v1.17 [beta]&lt;/code&gt;
&lt;/div&gt;


&lt;p&gt;&lt;em&gt;EndpointSlice&lt;/em&gt; 提供了一种简单的方式来在 k8s 集群跟踪网络端点。 它提供了比 Endpoint 拥有更
好的伸缩性和扩展性的替代方案&lt;/p&gt;
&lt;!-- body --&gt;
&lt;!--
## Motivation

The Endpoints API has provided a simple and straightforward way of
tracking network endpoints in Kubernetes. Unfortunately as Kubernetes clusters
and &lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/concepts/services-networking/service/&#39; target=&#39;_blank&#39;&gt;Services&lt;span class=&#39;tooltip-text&#39;&gt;以网络服务的方式让一个由一组 Pod 构成的应用可以对外提供服务的一种方式&lt;/span&gt;
&lt;/a&gt; have grown to handle and
send more traffic to more backend Pods, limitations of that original API became
more visible.
Most notably, those included challenges with scaling to larger numbers of
network endpoints.

Since all network endpoints for a Service were stored in a single Endpoints
resource, those resources could get quite large. That affected the performance
of Kubernetes components (notably the master control plane) and resulted in
significant amounts of network traffic and processing when Endpoints changed.
EndpointSlices help you mitigate those issues as well as provide an extensible
platform for additional features such as topological routing.
 --&gt;
&lt;h2 id=&#34;动机&#34;&gt;动机&lt;/h2&gt;
&lt;p&gt;Endpoint 的 API 提供了一个简单的直接的方式来跟踪 k8s 中的网络端点。不幸的是当 k8s 集群和
&lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/concepts/services-networking/service/&#39; target=&#39;_blank&#39;&gt;Service&lt;span class=&#39;tooltip-text&#39;&gt;以网络服务的方式让一个由一组 Pod 构成的应用可以对外提供服务的一种方式&lt;/span&gt;
&lt;/a&gt; 处理和发送更多的流量到更多的后端 Pod 时，
这个 API 的限制就越来越明显了.  特别是当集群中扩充到很大数量的网络端点时，这些挑战就越发明显。&lt;/p&gt;
&lt;p&gt;当一个 Service 所有的网络端点都被存储在一个 Endpoint 资源时，这个资源就会变得很大。这会影响
到 k8s 组件(特别是控制中心)的性能， 并且的 Endpoint 发生变化时导致大量的网络流量和相关处理业务。
EndpointSlice 缓解这些问题的同时提供了一个可扩展的平台，这个平台上还有包括拓扑路由等特性。&lt;/p&gt;
&lt;!--
## EndpointSlice resources {#endpointslice-resource}

In Kubernetes, an EndpointSlice contains references to a set of network
endpoints. The control plane automatically creates EndpointSlices
for any Kubernetes Service that has a &lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/concepts/overview/working-with-objects/labels/&#39; target=&#39;_blank&#39;&gt;selector&lt;span class=&#39;tooltip-text&#39;&gt;允许用户基于标签过滤资源列表&lt;/span&gt;
&lt;/a&gt; specified. These EndpointSlices include
references to all the Pods that match the Service selector. EndpointSlices group
network endpoints together by unique combinations of protocol, port number, and
Service name.  
The name of a EndpointSlice object must be a valid
[DNS subdomain name](/docs/concepts/overview/working-with-objects/names#dns-subdomain-names).

As an example, here&#39;s a sample EndpointSlice resource for the `example`
Kubernetes Service.

```yaml
apiVersion: discovery.k8s.io/v1beta1
kind: EndpointSlice
metadata:
  name: example-abc
  labels:
    kubernetes.io/service-name: example
addressType: IPv4
ports:
  - name: http
    protocol: TCP
    port: 80
endpoints:
  - addresses:
      - &#34;10.1.2.3&#34;
    conditions:
      ready: true
    hostname: pod-1
    topology:
      kubernetes.io/hostname: node-1
      topology.kubernetes.io/zone: us-west2-a
```

By default, the control plane creates and manages EndpointSlices to have no
more than 100 endpoints each. You can configure this with the
`--max-endpoints-per-slice`
&lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/docs/reference/command-line-tools-reference/kube-controller-manager/&#39; target=&#39;_blank&#39;&gt;kube-controller-manager&lt;span class=&#39;tooltip-text&#39;&gt;Control Plane component that runs controller processes.&lt;/span&gt;
&lt;/a&gt;
flag, up to a maximum of 1000.

EndpointSlices can act as the source of truth for
&lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/docs/reference/command-line-tools-reference/kube-proxy/&#39; target=&#39;_blank&#39;&gt;kube-proxy&lt;span class=&#39;tooltip-text&#39;&gt;kube-proxy is a network proxy that runs on each node in the cluster.&lt;/span&gt;
&lt;/a&gt; when it comes to
how to route internal traffic. When enabled, they should provide a performance
improvement for services with large numbers of endpoints.
 --&gt;
&lt;h2 id=&#34;endpointslice-resource&#34;&gt;EndpointSlice 资源&lt;/h2&gt;
&lt;p&gt;在 k8s 中， 一个 EndpointSlice 包含一组网络端点集合的引用。 控制中心会自动为任意包含
&lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/concepts/overview/working-with-objects/labels/&#39; target=&#39;_blank&#39;&gt;选择器&lt;span class=&#39;tooltip-text&#39;&gt;允许用户基于标签过滤资源列表&lt;/span&gt;
&lt;/a&gt;
的 Service 创建 EndpointSlice。 这些 EndpointSlice 包含所有匹配该 Service 的 Pod 的引用。
EndpointSlice 通过协议，端口号，Service 名称的唯一组合将这些网络端点组织在一起。
EndpointSlice 对象的名称必须是一个
&lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/docs/concepts/overview/working-with-objects/names#dns-subdomain-names&#34;&gt;DNS 子域名&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;下面的例子中，是一个叫 &lt;code&gt;example&lt;/code&gt; 的 Service 的 EndpointSlice 资源的简单示例:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;discovery.k8s.io/v1beta1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;EndpointSlice&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;example-abc&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;labels&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;kubernetes.io/service-name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;example&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;addressType&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;IPv4&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;ports&lt;/span&gt;:
  - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;http&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;protocol&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;TCP&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;endpoints&lt;/span&gt;:
  - &lt;span style=&#34;color:#f92672&#34;&gt;addresses&lt;/span&gt;:
      - &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;10.1.2.3&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;conditions&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;ready&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;true&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;hostname&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;pod-1&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;topology&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;kubernetes.io/hostname&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;node-1&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;topology.kubernetes.io/zone&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;us-west2-a&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;默认情况下， 控制中心创建和管理的 EndpointSlice 每个不超过 100 个网络端点。用户可以通过
&lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/docs/reference/command-line-tools-reference/kube-controller-manager/&#39; target=&#39;_blank&#39;&gt;kube-controller-manager&lt;span class=&#39;tooltip-text&#39;&gt;Control Plane component that runs controller processes.&lt;/span&gt;
&lt;/a&gt;
的 &lt;code&gt;--max-endpoints-per-slice&lt;/code&gt; 参数配置，最高可以到 1000。&lt;/p&gt;
&lt;p&gt;EndpointSlices 可以在路由内部流量时被认作
&lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/docs/reference/command-line-tools-reference/kube-proxy/&#39; target=&#39;_blank&#39;&gt;kube-proxy&lt;span class=&#39;tooltip-text&#39;&gt;kube-proxy is a network proxy that runs on each node in the cluster.&lt;/span&gt;
&lt;/a&gt; 的真实的来源。
当启用后，可以改善拥有大量网络端点的 Service 的性能。&lt;/p&gt;
&lt;!--
### Address types

EndpointSlices support three address types:

* IPv4
* IPv6
* FQDN (Fully Qualified Domain Name)
 --&gt;
&lt;h3 id=&#34;地址类型&#34;&gt;地址类型&lt;/h3&gt;
&lt;p&gt;EndpointSlice 支持以下三种类型:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;IPv4&lt;/li&gt;
&lt;li&gt;IPv6&lt;/li&gt;
&lt;li&gt;FQDN (全限定名)&lt;/li&gt;
&lt;/ul&gt;
&lt;!--
### Topology information {#topology}

Each endpoint within an EndpointSlice can contain relevant topology information.
This is used to indicate where an endpoint is, containing information about the
corresponding Node, zone, and region. When the values are available, the
control plane sets the following Topology labels for EndpointSlices:

* `kubernetes.io/hostname` - The name of the Node this endpoint is on.
* `topology.kubernetes.io/zone` - The zone this endpoint is in.
* `topology.kubernetes.io/region` - The region this endpoint is in.

The values of these labels are derived from resources associated with each
endpoint in a slice. The hostname label represents the value of the NodeName
field on the corresponding Pod. The zone and region labels represent the value
of the labels with the same names on the corresponding Node.
 --&gt;
&lt;h3 id=&#34;topology&#34;&gt;拓扑信息&lt;/h3&gt;
&lt;p&gt;EndpointSlice 中的每一个网络端点都可以有一个有意义的拓扑信息。 用于指示这个网络端点在哪，包含对应的
节点信息，分区信息和地区信息。 当这些值存在时，控制中心会为 EndpointSlice 打上如下标签:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;kubernetes.io/hostname&lt;/code&gt; - 这个网络端点所在的节点名称.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;topology.kubernetes.io/zone&lt;/code&gt; - 这个网络端点所在分区.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;topology.kubernetes.io/region&lt;/code&gt; - 这个网络端点所在地区.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这些标签的值源于 EndpointSlice 中的每个网络端点对应的资源。  hostname 标签表示 对应 Pod
的 NodeName 字段的值。 &lt;code&gt;zone&lt;/code&gt; 和 &lt;code&gt;region&lt;/code&gt; 标签与对应节点同一标签一致。&lt;/p&gt;
&lt;!--
### Management

Most often, the control plane (specifically, the endpoint slice
&lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/2-concepts/01-architecture/02-controller/&#39; target=&#39;_blank&#39;&gt;controller&lt;span class=&#39;tooltip-text&#39;&gt;一个控制回路，负责通过 apiserver 监控集群的共享状态，并尝试通过变更(某些对象)的方式实现集群从当前状态向期望状态迁移&lt;/span&gt;
&lt;/a&gt;) creates and
manages EndpointSlice objects. There are a variety of other use cases for
EndpointSlices, such as service mesh implementations, that could result in other
entities or controllers managing additional sets of EndpointSlices.

To ensure that multiple entities can manage EndpointSlices without interfering
with each other, Kubernetes defines the
&lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/concepts/overview/working-with-objects/labels&#39; target=&#39;_blank&#39;&gt;label&lt;span class=&#39;tooltip-text&#39;&gt;在对象上标上对用户有意义和有关联的属性&lt;/span&gt;
&lt;/a&gt;
`endpointslice.kubernetes.io/managed-by`, which indicates the entity managing
an EndpointSlice.
The endpoint slice controller sets `endpointslice-controller.k8s.io` as the value
for this label on all EndpointSlices it manages. Other entities managing
EndpointSlices should also set a unique value for this label.
 --&gt;
&lt;h3 id=&#34;管理&#34;&gt;管理&lt;/h3&gt;
&lt;p&gt;大多数时候，控制中心(确切的说，EndpointSlice &lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/2-concepts/01-architecture/02-controller/&#39; target=&#39;_blank&#39;&gt;控制器&lt;span class=&#39;tooltip-text&#39;&gt;一个控制回路，负责通过 apiserver 监控集群的共享状态，并尝试通过变更(某些对象)的方式实现集群从当前状态向期望状态迁移&lt;/span&gt;
&lt;/a&gt;)
创建和管理 EndpointSlice 对象。 除此之外 EndpointSlice 还有其它多种应用场景， 例如服务网格的实现，
由此可以会导致其它的实体或控制顺管理额外的 EndpointSlice 集合。&lt;/p&gt;
&lt;p&gt;为了能保证多个实体在管理 EndpointSlice 时不会相互影响， k8s 定义了 &lt;code&gt;endpointslice.kubernetes.io/managed-by&lt;/code&gt;
&lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/concepts/overview/working-with-objects/labels&#39; target=&#39;_blank&#39;&gt;label&lt;span class=&#39;tooltip-text&#39;&gt;在对象上标上对用户有意义和有关联的属性&lt;/span&gt;
&lt;/a&gt;，
这个标签用于指示是哪个实体在管理这个 EndpointSlice。 EndpointSlice 控制器会为所有它管理的
EndpointSlice 设置 &lt;code&gt;endpointslice-controller.k8s.io&lt;/code&gt; 标签。 其它实体管理 EndpointSlice
也应当为该标签设置唯一的值。&lt;/p&gt;
&lt;!--
### Ownership

In most use cases, EndpointSlices are owned by the Service that the endpoint
slice object tracks endpoints for. This ownership is indicated by an owner
reference on each EndpointSlice as well as a `kubernetes.io/service-name`
label that enables simple lookups of all EndpointSlices belonging to a Service.
 --&gt;
&lt;h3 id=&#34;所有权&#34;&gt;所有权&lt;/h3&gt;
&lt;p&gt;在大多数情况下， EndpointSlice 的所有者是它跟踪的网络端点对应的 Service。 这个所有权会通过
EndpointSlice 上的 &lt;code&gt;kubernetes.io/service-name&lt;/code&gt; 标签显示，标签的值为其所属 Service 的名称&lt;/p&gt;
&lt;!--
### EndpointSlice mirroring

In some cases, applications create custom Endpoints resources. To ensure that
these applications do not need to concurrently write to both Endpoints and
EndpointSlice resources, the cluster&#39;s control plane mirrors most Endpoints
resources to corresponding EndpointSlices.

The control plane mirrors Endpoints resources unless:

* the Endpoints resource has a `endpointslice.kubernetes.io/skip-mirror` label
  set to `true`.
* the Endpoints resource has a `control-plane.alpha.kubernetes.io/leader`
  annotation.
* the corresponding Service resource does not exist.
* the corresponding Service resource has a non-nil selector.

Individual Endpoints resources may translate into multiple EndpointSlices. This
will occur if an Endpoints resource has multiple subsets or includes endpoints
with multiple IP families (IPv4 and IPv6). A maximum of 1000 addresses per
subset will be mirrored to EndpointSlices.
 --&gt;
&lt;h3 id=&#34;endpointslice-镜像&#34;&gt;EndpointSlice 镜像&lt;/h3&gt;
&lt;p&gt;在某些情况下，应用会创建自定义的 Endpoint。 为了保证这些应用不会同时写入到 Endpoint 和 EndpointSlice
资源， 集群控制中心会为大多数 Endpoint 创建对应的 EndpointSlice。&lt;/p&gt;
&lt;p&gt;以下情况控制中心不会镜像 Endpoint:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Endpoint 资源有 &lt;code&gt;endpointslice.kubernetes.io/skip-mirror&lt;/code&gt; 标签，且值为 &lt;code&gt;true&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Endpoint 资源有 &lt;code&gt;control-plane.alpha.kubernetes.io/leader&lt;/code&gt; 注解。&lt;/li&gt;
&lt;li&gt;对应的 Service 资源不存在&lt;/li&gt;
&lt;li&gt;对应的 Service 资源有非空选择器&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一个 Endpoint 可能会被转化为多个 EndpointSlice。发生这种情况的原因有可能是 Endpoint 资源
包含多个子网或包含的网络端点同时包含 IPv4 和 IPv6。 每个子网最多可以把 1000 个地址镜像到一个 EndpointSlice&lt;/p&gt;
&lt;!--
### Distribution of EndpointSlices

Each EndpointSlice has a set of ports that applies to all endpoints within the
resource. When named ports are used for a Service, Pods may end up with
different target port numbers for the same named port, requiring different
EndpointSlices. This is similar to the logic behind how subsets are grouped
with Endpoints.

The control plane tries to fill EndpointSlices as full as possible, but does not
actively rebalance them. The logic is fairly straightforward:

1. Iterate through existing EndpointSlices, remove endpoints that are no longer
   desired and update matching endpoints that have changed.
2. Iterate through EndpointSlices that have been modified in the first step and
   fill them up with any new endpoints needed.
3. If there&#39;s still new endpoints left to add, try to fit them into a previously
   unchanged slice and/or create new ones.

Importantly, the third step prioritizes limiting EndpointSlice updates over a
perfectly full distribution of EndpointSlices. As an example, if there are 10
new endpoints to add and 2 EndpointSlices with room for 5 more endpoints each,
this approach will create a new EndpointSlice instead of filling up the 2
existing EndpointSlices. In other words, a single EndpointSlice creation is
preferrable to multiple EndpointSlice updates.

With kube-proxy running on each Node and watching EndpointSlices, every change
to an EndpointSlice becomes relatively expensive since it will be transmitted to
every Node in the cluster. This approach is intended to limit the number of
changes that need to be sent to every Node, even if it may result with multiple
EndpointSlices that are not full.

In practice, this less than ideal distribution should be rare. Most changes
processed by the EndpointSlice controller will be small enough to fit in an
existing EndpointSlice, and if not, a new EndpointSlice is likely going to be
necessary soon anyway. Rolling updates of Deployments also provide a natural
repacking of EndpointSlices with all Pods and their corresponding endpoints
getting replaced.
 --&gt;
&lt;h3 id=&#34;endpointslice-分布&#34;&gt;EndpointSlice 分布&lt;/h3&gt;
&lt;p&gt;每个 EndpointSlice 都有一系列端口，这些端口会被应用到该资源内的所有的网络端点上。当一个
Service 使用命名端口时， Pod 最终可以会有同一个名称的端口的目标端口不一样的情况，这样就需要不
同的 EndpointSlice。 这与子网是怎么对 Endpoint 分组的逻辑是类似的。&lt;/p&gt;
&lt;p&gt;控制中心会尽量将 EndpointSlice 装满，但不会主动地重新平衡它们。 其中逻辑是相同简单的:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;迭代所有存在的 EndpointSlice，称除不需要的网络端点，更新发生变化的网络端点&lt;/li&gt;
&lt;li&gt;迭代每一步中被修改的 EndpointSlice ，添加所有需要的新的网络端点&lt;/li&gt;
&lt;li&gt;如果还有新的网络端点需要添加，尝试添加到之间没变更的 EndpointSlice 或者(同时)创建一个新的。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;重要的是， 在第三步的优先级会限制 EndpointSlice 更新到一个完美分布。 例如，如果有 10 个新增的
网络端点要添加到两个 EndpointSlice，并且这两个 EndpointSlice 都还有 5 个空位，这种方式会
创建一个新的 EndpointSlice， 而不是装满这两个已经存在的 EndpointSlice。 换句话说，创建一个新的
EndpointSlice 优先于更新两个 EndpointSlice。&lt;/p&gt;
&lt;p&gt;当 kube-proxy 运行在每个节点上并监听 EndpointSlice， 每一次对 EndpointSlice 修改都会变得
相对来多代价比较高的，因为每个更新都会传达到信念中的每一个节点上。这种方式旨在限制发送到每个节点
的变更次数，尽管它会导致产生多个没有被装满的 EndpointSlice&lt;/p&gt;
&lt;p&gt;在实践中，这种不太理想分配应该是比较少见的。 大多数由 EndpointSlice 处理的变量应该都足够小到适应
已经存在的 EndpointSlice， 如果没，也就是创建一个很快就也必须要创建的新的 EndpointSlice。
Deployment 的滚动更新也提供了一个自然的  EndpointSlice 重新打包，因为所有的 Pod 和它们对
应的网络端点也是被替换。&lt;/p&gt;
&lt;!--
### Duplicate endpoints

Due to the nature of EndpointSlice changes, endpoints may be represented in more
than one EndpointSlice at the same time. This naturally occurs as changes to
different EndpointSlice objects can arrive at the Kubernetes client watch/cache
at different times. Implementations using EndpointSlice must be able to have the
endpoint appear in more than one slice. A reference implementation of how to
perform endpoint deduplication can be found in the `EndpointSliceCache`
implementation in `kube-proxy`.
 --&gt;
&lt;h3 id=&#34;重复的网络端点&#34;&gt;重复的网络端点&lt;/h3&gt;
&lt;p&gt;由于 EndpointSlice 的自然变更，网络端点可能同时存在于不同的 EndpointSlice 中。 这些自然地
发生在对不同 EndpointSlice 对象的变更，可能在不同的时间到到 k8s 客户端的监听或缓存。使用
EndpointSlice 的实现必须要能处理这种同一个网络端点出现在多个 EndpointSlice 的情况。
怎么处理重复网络端点的实现参考可以在 &lt;code&gt;kube-proxy&lt;/code&gt; 中的 &lt;code&gt;EndpointSliceCache&lt;/code&gt; 实现中找到。&lt;/p&gt;
&lt;h2 id=&#34;相关资料&#34;&gt;相关资料&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;实践 &lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/tasks/administer-cluster/enabling-endpointslices&#34;&gt;开启 EndpointSlices&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;概念 &lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/docs/concepts/services-networking/connect-applications-service/&#34;&gt;通过 Service 连接应用&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Ingress</title>
      <link>https://lostsquirrel.github.io/k8sDocs/docs/concepts/services-networking/ingress/</link>
      <pubDate>Mon, 21 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://lostsquirrel.github.io/k8sDocs/docs/concepts/services-networking/ingress/</guid>
      <description>
        
        
        &lt;!--
---
reviewers:
- bprashanth
title: Ingress
content_type: concept
weight: 40
--- --&gt;
&lt;!-- overview --&gt;
&lt;p&gt;




&lt;div style=&#34;margin-top: 10px; margin-bottom: 10px;&#34;&gt;
&lt;b&gt;功能特性状态:&lt;/b&gt; &lt;code&gt;Kubernetes v1.19 [stable]&lt;/code&gt;
&lt;/div&gt;


&lt;p&gt;一个用于管理外部访问集群内 Service 的 API 对象，通常是 HTTP。&lt;/p&gt;
&lt;p&gt;Ingress 还可以提供负载均衡，SSL 和基于名称的虚拟主机。&lt;/p&gt;&lt;/p&gt;
&lt;!-- body --&gt;
&lt;!--
## Terminology

For clarity, this guide defines the following terms:

* Node: A worker machine in Kubernetes, part of a cluster.
* Cluster: A set of Nodes that run containerized applications managed by Kubernetes. For this example, and in most common Kubernetes deployments, nodes in the cluster are not part of the public internet.
* Edge router: A router that enforces the firewall policy for your cluster. This could be a gateway managed by a cloud provider or a physical piece of hardware.
* Cluster network: A set of links, logical or physical, that facilitate communication within a cluster according to the Kubernetes [networking model](/docs/concepts/cluster-administration/networking/).
* Service: A Kubernetes &lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/concepts/services-networking/service/&#39; target=&#39;_blank&#39;&gt;Service&lt;span class=&#39;tooltip-text&#39;&gt;以网络服务的方式让一个由一组 Pod 构成的应用可以对外提供服务的一种方式&lt;/span&gt;
&lt;/a&gt; that identifies a set of Pods using &lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/concepts/overview/working-with-objects/labels&#39; target=&#39;_blank&#39;&gt;label&lt;span class=&#39;tooltip-text&#39;&gt;在对象上标上对用户有意义和有关联的属性&lt;/span&gt;
&lt;/a&gt; selectors. Unless mentioned otherwise, Services are assumed to have virtual IPs only routable within the cluster network.
 --&gt;
&lt;h2 id=&#34;术语&#34;&gt;术语&lt;/h2&gt;
&lt;p&gt;为了明确，本文定义了如下术语:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;节点(Node): k8s 中的一个工作机，集群的一部分。&lt;/li&gt;
&lt;li&gt;集群(Cluster): 一组由运行由 k8s 管理的容器化应用的节点集合。在本例和大多数常用的 k8s 部署
中，集群中的节点是不在公网上的。&lt;/li&gt;
&lt;li&gt;边缘路由: 一个为集群执行防火墙策略的路由。 可以是由云提供商管理的网关或一个物理硬件。&lt;/li&gt;
&lt;li&gt;集群网络: 一组逻辑的或物理的连接，这些连接根据 k8s
&lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/docs/concepts/cluster-administration/networking/&#34;&gt;网络模型&lt;/a&gt;简化集群内的通信&lt;/li&gt;
&lt;li&gt;Service: 一个 k8s &lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/concepts/services-networking/service/&#39; target=&#39;_blank&#39;&gt;Service&lt;span class=&#39;tooltip-text&#39;&gt;以网络服务的方式让一个由一组 Pod 构成的应用可以对外提供服务的一种方式&lt;/span&gt;
&lt;/a&gt; 就是使用
&lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/concepts/overview/working-with-objects/labels&#39; target=&#39;_blank&#39;&gt;标签&lt;span class=&#39;tooltip-text&#39;&gt;在对象上标上对用户有意义和有关联的属性&lt;/span&gt;
&lt;/a&gt; 选择器区分一组 Pod 的抽象概念。 如果没有特别
说明， Service 假定是有一个只能在集群内路由的虚拟 IP 的。&lt;/li&gt;
&lt;/ul&gt;
&lt;!--
## What is Ingress?

[Ingress](/docs/reference/generated/kubernetes-api/v1.19/#ingress-v1-networking-k8s-io) exposes HTTP and HTTPS routes from outside the cluster to
&lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/docs/concepts/services-networking/service/&#34; target=&#34;_blank&#34;&gt;services&lt;/a&gt; within the cluster.
Traffic routing is controlled by rules defined on the Ingress resource.

```none
    internet
        |
   [ Ingress ]
   --|-----|--
   [ Services ]
```

An Ingress may be configured to give Services externally-reachable URLs, load balance traffic, terminate SSL / TLS, and offer name-based virtual hosting. An [Ingress controller](/docs/concepts/services-networking/ingress-controllers) is responsible for fulfilling the Ingress, usually with a load balancer, though it may also configure your edge router or additional frontends to help handle the traffic.

An Ingress does not expose arbitrary ports or protocols. Exposing services other than HTTP and HTTPS to the internet typically
uses a service of type [Service.Type=NodePort](/docs/concepts/services-networking/service/#nodeport) or
[Service.Type=LoadBalancer](/docs/concepts/services-networking/service/#loadbalancer).
 --&gt;
&lt;h2 id=&#34;ingress-是什么&#34;&gt;Ingress 是什么?&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.19/#ingress-v1-networking-k8s-io&#34;&gt;Ingress&lt;/a&gt;
将集群内部的
&lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/docs/concepts/services-networking/service/&#34; target=&#34;_blank&#34;&gt;Service&lt;/a&gt;
通过 HTTP 和 HTTPS 路由暴露到集群外部。
流量路由由 Ingress 资源内部定义的规则控制。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-none&#34; data-lang=&#34;none&#34;&gt;    internet
        |
   [ Ingress ]
   --|-----|--
   [ Services ]
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;可以配置一个 Ingress 为 Service 提供外部可以访问的 URL, 负载均衡，SSL / TLS, 提供基于名称的
虚拟主机名。
&lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/docs/concepts/services-networking/ingress-controllers&#34;&gt;Ingress 控制器&lt;/a&gt;将负责
实现 Ingress， 通常是通过负载均衡器，也可能是通过配置边缘路由或额外的前端组件来帮助处理流量。&lt;/p&gt;
&lt;p&gt;Ingress 不是暴露任意的端口或协议。 要暴露非 HTTP / HTTPS 的 Service 通常使用
&lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/docs/concepts/services-networking/service/#nodeport&#34;&gt;Service.Type=NodePort&lt;/a&gt;
或
&lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/docs/concepts/services-networking/service/#loadbalancer&#34;&gt;Service.Type=LoadBalancer&lt;/a&gt;.&lt;/p&gt;
&lt;!--
## Prerequisites

You must have an [Ingress controller](/docs/concepts/services-networking/ingress-controllers) to satisfy an Ingress. Only creating an Ingress resource has no effect.

You may need to deploy an Ingress controller such as [ingress-nginx](https://kubernetes.github.io/ingress-nginx/deploy/). You can choose from a number of
[Ingress controllers](/docs/concepts/services-networking/ingress-controllers).

Ideally, all Ingress controllers should fit the reference specification. In reality, the various Ingress
controllers operate slightly differently.

&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; Make sure you review your Ingress controller&amp;rsquo;s documentation to understand the caveats of choosing it.&lt;/div&gt;
&lt;/blockquote&gt;

 --&gt;
&lt;h2 id=&#34;前置条件&#34;&gt;前置条件&lt;/h2&gt;
&lt;p&gt;要使用 Ingress 首先得有一个
&lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/docs/concepts/services-networking/ingress-controllers&#34;&gt;Ingress 控制器&lt;/a&gt;。
不然只创建一个 Ingress 资源是没有效果的。&lt;/p&gt;
&lt;p&gt;需要部署一个 Ingress 控制器，例如
&lt;a href=&#34;https://kubernetes.github.io/ingress-nginx/deploy/&#34;&gt;ingress-nginx&lt;/a&gt;.
也可以从
&lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/docs/concepts/services-networking/ingress-controllers&#34;&gt;Ingress 控制器&lt;/a&gt;
中选几个.&lt;/p&gt;
&lt;p&gt;理想情况下，所有的 Ingress 控制器都应该是符合参考规格说明的。 实际上，不同的 Ingress 运转方式
各自都有点不同。
&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; 在选择 Ingress 控制器前请仔细阅读相关文档，确定理解了相关注意事项。&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/p&gt;
&lt;!--
## The Ingress resource

A minimal Ingress resource example:



 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingminimal-ingressyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/minimal-ingress.yaml&#34; download=&#34;service/networking/minimal-ingress.yaml&#34;&gt;
                    &lt;code&gt;service/networking/minimal-ingress.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingminimal-ingressyaml&#39;)&#34; title=&#34;Copy service/networking/minimal-ingress.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;networking.k8s.io/v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Ingress&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;minimal-ingress&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;annotations&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;nginx.ingress.kubernetes.io/rewrite-target&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;/&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;rules&lt;/span&gt;:
  - &lt;span style=&#34;color:#f92672&#34;&gt;http&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;paths&lt;/span&gt;:
      - &lt;span style=&#34;color:#f92672&#34;&gt;path&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;/testpath&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;pathType&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Prefix&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;backend&lt;/span&gt;:
          &lt;span style=&#34;color:#f92672&#34;&gt;service&lt;/span&gt;:
            &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;test&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;:
              &lt;span style=&#34;color:#f92672&#34;&gt;number&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;



As with all other Kubernetes resources, an Ingress needs `apiVersion`, `kind`, and `metadata` fields.
The name of an Ingress object must be a valid
[DNS subdomain name](/docs/concepts/overview/working-with-objects/names#dns-subdomain-names).
For general information about working with config files, see [deploying applications](/docs/tasks/run-application/run-stateless-application-deployment/), [configuring containers](/docs/tasks/configure-pod-container/configure-pod-configmap/), [managing resources](/docs/concepts/cluster-administration/manage-deployment/).
 Ingress frequently uses annotations to configure some options depending on the Ingress controller, an example of which
 is the [rewrite-target annotation](https://github.com/kubernetes/ingress-nginx/blob/master/docs/examples/rewrite/README.md).
Different [Ingress controller](/docs/concepts/services-networking/ingress-controllers) support different annotations. Review the documentation for
 your choice of Ingress controller to learn which annotations are supported.

The Ingress [spec](https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status)
has all the information needed to configure a load balancer or proxy server. Most importantly, it
contains a list of rules matched against all incoming requests. Ingress resource only supports rules
for directing HTTP(S) traffic.
 --&gt;
&lt;h2 id=&#34;ingress-资源&#34;&gt;Ingress 资源&lt;/h2&gt;
&lt;p&gt;一个最小化 Ingress 资源的示例:


 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingminimal-ingressyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/minimal-ingress.yaml&#34; download=&#34;service/networking/minimal-ingress.yaml&#34;&gt;
                    &lt;code&gt;service/networking/minimal-ingress.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingminimal-ingressyaml&#39;)&#34; title=&#34;Copy service/networking/minimal-ingress.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;networking.k8s.io/v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Ingress&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;minimal-ingress&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;annotations&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;nginx.ingress.kubernetes.io/rewrite-target&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;/&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;rules&lt;/span&gt;:
  - &lt;span style=&#34;color:#f92672&#34;&gt;http&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;paths&lt;/span&gt;:
      - &lt;span style=&#34;color:#f92672&#34;&gt;path&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;/testpath&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;pathType&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Prefix&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;backend&lt;/span&gt;:
          &lt;span style=&#34;color:#f92672&#34;&gt;service&lt;/span&gt;:
            &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;test&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;:
              &lt;span style=&#34;color:#f92672&#34;&gt;number&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;

&lt;/p&gt;
&lt;p&gt;与所有其它的 k8s 资源一样， 一个 Ingress 的必要字段有 &lt;code&gt;apiVersion&lt;/code&gt;, &lt;code&gt;kind&lt;/code&gt;, &lt;code&gt;metadata&lt;/code&gt;。
Ingress 对象的名称必须是一个有效的
&lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/docs/concepts/overview/working-with-objects/names#dns-subdomain-names&#34;&gt;DNS 子域名&lt;/a&gt;.
关于配置文件的通用信息见
&lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/tasks/run-application/run-stateless-application-deployment/&#34;&gt;部署应用&lt;/a&gt;,
&lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/tasks/configure-pod-container/configure-pod-configmap/&#34;&gt;配置容器&lt;/a&gt;,
&lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/docs/concepts/cluster-administration/manage-deployment/&#34;&gt;管理资源&lt;/a&gt;.
Ingress 经常使用注解(annotation) 来配置一些基于 Ingress 控制器的可选配置，这里有一个例子
&lt;a href=&#34;https://github.com/kubernetes/ingress-nginx/blob/master/docs/examples/rewrite/README.md&#34;&gt;rewrite-target 注解&lt;/a&gt;.
不同的
&lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/docs/concepts/services-networking/ingress-controllers&#34;&gt;Ingress 控制器&lt;/a&gt;
会支持不同的注解。 查看对应的控制文档了解其支持的注解(annotation)。&lt;/p&gt;
&lt;p&gt;Ingress &lt;a href=&#34;https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status&#34;&gt;spec&lt;/a&gt;
中包含了配置负载均衡器或代理服务器的所有信息。 最重要的是它包含了一个匹配进入请求的规则列表。
Ingress 资源只支持对 HTTP(S) 流量的转发。&lt;/p&gt;
&lt;!--
### Ingress rules

Each HTTP rule contains the following information:

* An optional host. In this example, no host is specified, so the rule applies to all inbound
  HTTP traffic through the IP address specified. If a host is provided (for example,
  foo.bar.com), the rules apply to that host.
* A list of paths (for example, `/testpath`), each of which has an associated
  backend defined with a `service.name` and a `service.port.name` or
  `service.port.number`. Both the host and path must match the content of an
  incoming request before the load balancer directs traffic to the referenced
  Service.
* A backend is a combination of Service and port names as described in the
  [Service doc](/docs/concepts/services-networking/service/) or a [custom resource backend](#resource-backend) by way of a &lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/&#39; target=&#39;_blank&#39;&gt;CRD&lt;span class=&#39;tooltip-text&#39;&gt;Custom code that defines a resource to add to your Kubernetes API server without building a complete custom server.&lt;/span&gt;
&lt;/a&gt;. HTTP (and HTTPS) requests to the
  Ingress that matches the host and path of the rule are sent to the listed backend.

A `defaultBackend` is often configured in an Ingress controller to service any requests that do not
match a path in the spec.
 --&gt;
&lt;h3 id=&#34;ingress-rules&#34;&gt;Ingress 规则&lt;/h3&gt;
&lt;p&gt;每个 HTTP 规则包含以下信息:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一个可选的主机名。 在这个例子中就没有配，所以这个规则应用于所有通过指定 IP 的流量。如果主机名
有设置(例如，foo.bar.com), 这个规则就应用于这个主机名。&lt;/li&gt;
&lt;li&gt;一个路径列表(如例子中的 &lt;code&gt;/testpath&lt;/code&gt;)， 每个路径都与一个后台通过一个 &lt;code&gt;service.name&lt;/code&gt; 和
一个 &lt;code&gt;service.port.name&lt;/code&gt; 或 &lt;code&gt;service.port.number&lt;/code&gt; 相关联。 必须要主机名和路径都匹配的
进入请求才会重定向到相应的 Service&lt;/li&gt;
&lt;li&gt;一个后端就是一个 Service 和 端口名称的组合，就如
&lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/docs/concepts/services-networking/service/&#34;&gt;Service&lt;/a&gt;
或
&lt;a href=&#34;#resource-backend&#34;&gt;自定义资源后端&lt;/a&gt;通过
&lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/&#39; target=&#39;_blank&#39;&gt;CRD&lt;span class=&#39;tooltip-text&#39;&gt;Custom code that defines a resource to add to your Kubernetes API server without building a complete custom server.&lt;/span&gt;
&lt;/a&gt;
方式中所描述的一样。
到达 Ingress 的 HTTP (和 HTTPS) 请求匹配到对应规则的主机名和路径就会发送到列举的后端。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一个 &lt;code&gt;defaultBackend&lt;/code&gt; 通常是配置在一个 Ingress 控制器中，用于接收所有没有匹配到任何配置中的
路径的请求。&lt;/p&gt;
&lt;!--
### DefaultBackend {#default-backend}

An Ingress with no rules sends all traffic to a single default backend. The `defaultBackend` is conventionally a configuration option
of the [Ingress controller](/docs/concepts/services-networking/ingress-controllers) and is not specified in your Ingress resources.

If none of the hosts or paths match the HTTP request in the Ingress objects, the traffic is
routed to your default backend.
 --&gt;
&lt;h3 id=&#34;default-backend&#34;&gt;默认后端(DefaultBackend)&lt;/h3&gt;
&lt;p&gt;一个没有任何规则的 Ingress 会将所有的流量发送到一个默认的后端。 &lt;code&gt;defaultBackend&lt;/code&gt; 是一个很方便
的配置在  &lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/docs/concepts/services-networking/ingress-controllers&#34;&gt;Ingress 控制器&lt;/a&gt;
并不需要在 Ingress 中配置。&lt;/p&gt;
&lt;p&gt;如果没有一个 Ingress 中的主机名或路径匹配到的 HTTP 请求，这些请求就会路由到默认后端&lt;/p&gt;
&lt;!--
### Resource backends {#resource-backend}

A `Resource` backend is an ObjectRef to another Kubernetes resource within the
same namespace as the Ingress object. A `Resource` is a mutually exclusive
setting with Service, and will fail validation if both are specified. A common
usage for a `Resource` backend is to ingress data to an object storage backend
with static assets.



 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingingress-resource-backendyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/ingress-resource-backend.yaml&#34; download=&#34;service/networking/ingress-resource-backend.yaml&#34;&gt;
                    &lt;code&gt;service/networking/ingress-resource-backend.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingingress-resource-backendyaml&#39;)&#34; title=&#34;Copy service/networking/ingress-resource-backend.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;networking.k8s.io/v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Ingress&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;ingress-resource-backend&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;defaultBackend&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;resource&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;apiGroup&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;k8s.example.com&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;StorageBucket&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;static-assets&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;rules&lt;/span&gt;:
    - &lt;span style=&#34;color:#f92672&#34;&gt;http&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;paths&lt;/span&gt;:
          - &lt;span style=&#34;color:#f92672&#34;&gt;path&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;/icons&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;pathType&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;ImplementationSpecific&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;backend&lt;/span&gt;:
              &lt;span style=&#34;color:#f92672&#34;&gt;resource&lt;/span&gt;:
                &lt;span style=&#34;color:#f92672&#34;&gt;apiGroup&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;k8s.example.com&lt;/span&gt;
                &lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;StorageBucket&lt;/span&gt;
                &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;icon-assets&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;



After creating the Ingress above, you can view it with the following command:

```bash
kubectl describe ingress ingress-resource-backend
```

```
Name:             ingress-resource-backend
Namespace:        default
Address:
Default backend:  APIGroup: k8s.example.com, Kind: StorageBucket, Name: static-assets
Rules:
  Host        Path  Backends
  ----        ----  --------
  *
              /icons   APIGroup: k8s.example.com, Kind: StorageBucket, Name: icon-assets
Annotations:  &lt;none&gt;
Events:       &lt;none&gt;
```
 --&gt;
&lt;h3 id=&#34;resource-backend&#34;&gt;资源(Resource) 后端&lt;/h3&gt;
&lt;p&gt;一个 &lt;code&gt;Resource&lt;/code&gt; 后端是一个与 Ingress 对象在同一个命名空间的另一个 k8s 资源的引用。
&lt;code&gt;Resource&lt;/code&gt; 与 Service 是互斥的，如果同时配置了两者，则不会通过验证。 &lt;code&gt;Resource&lt;/code&gt; 的一个常见
应用场景是进入一个存放静态资源的对象存储后端。&lt;/p&gt;


 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingingress-resource-backendyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/ingress-resource-backend.yaml&#34; download=&#34;service/networking/ingress-resource-backend.yaml&#34;&gt;
                    &lt;code&gt;service/networking/ingress-resource-backend.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingingress-resource-backendyaml&#39;)&#34; title=&#34;Copy service/networking/ingress-resource-backend.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;networking.k8s.io/v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Ingress&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;ingress-resource-backend&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;defaultBackend&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;resource&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;apiGroup&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;k8s.example.com&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;StorageBucket&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;static-assets&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;rules&lt;/span&gt;:
    - &lt;span style=&#34;color:#f92672&#34;&gt;http&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;paths&lt;/span&gt;:
          - &lt;span style=&#34;color:#f92672&#34;&gt;path&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;/icons&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;pathType&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;ImplementationSpecific&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;backend&lt;/span&gt;:
              &lt;span style=&#34;color:#f92672&#34;&gt;resource&lt;/span&gt;:
                &lt;span style=&#34;color:#f92672&#34;&gt;apiGroup&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;k8s.example.com&lt;/span&gt;
                &lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;StorageBucket&lt;/span&gt;
                &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;icon-assets&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;在创建以上定义的 Ingress 后，可以通过以下命令查看:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl describe ingress ingress-resource-backend
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Name:             ingress-resource-backend
Namespace:        default
Address:
Default backend:  APIGroup: k8s.example.com, Kind: StorageBucket, Name: static-assets
Rules:
  Host        Path  Backends
  ----        ----  --------
  *
              /icons   APIGroup: k8s.example.com, Kind: StorageBucket, Name: icon-assets
Annotations:  &amp;lt;none&amp;gt;
Events:       &amp;lt;none&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;!--
### Path types

Each path in an Ingress is required to have a corresponding path type. Paths
that do not include an explicit `pathType` will fail validation. There are three
supported path types:

* `ImplementationSpecific`: With this path type, matching is up to the
  IngressClass. Implementations can treat this as a separate `pathType` or treat
  it identically to `Prefix` or `Exact` path types.

* `Exact`: Matches the URL path exactly and with case sensitivity.

* `Prefix`: Matches based on a URL path prefix split by `/`. Matching is case
  sensitive and done on a path element by element basis. A path element refers
  to the list of labels in the path split by the `/` separator. A request is a
  match for path _p_ if every _p_ is an element-wise prefix of _p_ of the
  request path.

  &lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; If the last element of the path is a substring of the last
element in request path, it is not a match (for example: &lt;code&gt;/foo/bar&lt;/code&gt;
matches&lt;code&gt;/foo/bar/baz&lt;/code&gt;, but does not match &lt;code&gt;/foo/barbaz&lt;/code&gt;).&lt;/div&gt;
&lt;/blockquote&gt;

 --&gt;
&lt;h3 id=&#34;路径path类型&#34;&gt;路径(Path)类型&lt;/h3&gt;
&lt;p&gt;Ingress 中的每一个路径都需要有一个相应的路径类型。 没有显示设置 &lt;code&gt;pathType&lt;/code&gt; 是没办法通过验证的。
有以下三种支持的路径类型:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;ImplementationSpecific&lt;/code&gt;: 这个路径类型的匹配是由 IngressClass 决定。 具体实现可以将其认为是
独立的 &lt;code&gt;pathType&lt;/code&gt; 或认为是 &lt;code&gt;Prefix&lt;/code&gt; 或 &lt;code&gt;Exact&lt;/code&gt; 路径类型。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Exact&lt;/code&gt;:  完全匹配路径，区分大小写。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Prefix&lt;/code&gt;: 基于由 &lt;code&gt;/&lt;/code&gt; 分割的 URL 路径前缀匹配。匹配区分大小写，并且逐个元素匹配。
一个元素就是通过 &lt;code&gt;/&lt;/code&gt; 分割后列表中的每一个元素。 一个请求与路径 &lt;em&gt;p&lt;/em&gt; 相匹配则请求中的元素可以
依次匹配完路径 &lt;em&gt;p&lt;/em&gt; 的每一个元素。
&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; 如果路径的最后一个元素是请求路径的最后一个元素的子串，则不能匹配(例如：&lt;code&gt;/foo/bar&lt;/code&gt; 可以匹配
请求路径 &lt;code&gt;/foo/bar/baz&lt;/code&gt;，但是不能匹配请求路径 &lt;code&gt;/foo/barbaz&lt;/code&gt; )。&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/p&gt;
&lt;!--
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;examples&#34;&gt;Examples&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Kind&lt;/th&gt;
&lt;th&gt;Path(s)&lt;/th&gt;
&lt;th&gt;Request path(s)&lt;/th&gt;
&lt;th&gt;Matches?&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Prefix&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;(all paths)&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Exact&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/foo&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/foo&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Exact&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/foo&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/bar&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Exact&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/foo&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/foo/&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Exact&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/foo/&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/foo&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Prefix&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/foo&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/foo&lt;/code&gt;, &lt;code&gt;/foo/&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Prefix&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/foo/&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/foo&lt;/code&gt;, &lt;code&gt;/foo/&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Prefix&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/aaa/bb&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/aaa/bbb&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Prefix&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/aaa/bbb&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/aaa/bbb&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Prefix&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/aaa/bbb/&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/aaa/bbb&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Yes, ignores trailing slash&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Prefix&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/aaa/bbb&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/aaa/bbb/&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Yes,  matches trailing slash&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Prefix&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/aaa/bbb&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/aaa/bbb/ccc&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Yes, matches subpath&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Prefix&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/aaa/bbb&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/aaa/bbbxyz&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;No, does not match string prefix&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Prefix&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/&lt;/code&gt;, &lt;code&gt;/aaa&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/aaa/ccc&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Yes, matches &lt;code&gt;/aaa&lt;/code&gt; prefix&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Prefix&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/&lt;/code&gt;, &lt;code&gt;/aaa&lt;/code&gt;, &lt;code&gt;/aaa/bbb&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/aaa/bbb&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Yes, matches &lt;code&gt;/aaa/bbb&lt;/code&gt; prefix&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Prefix&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/&lt;/code&gt;, &lt;code&gt;/aaa&lt;/code&gt;, &lt;code&gt;/aaa/bbb&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/ccc&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Yes, matches &lt;code&gt;/&lt;/code&gt; prefix&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Prefix&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/aaa&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/ccc&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;No, uses default backend&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Mixed&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/foo&lt;/code&gt; (Prefix), &lt;code&gt;/foo&lt;/code&gt; (Exact)&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/foo&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Yes, prefers Exact&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&amp;ndash;&amp;gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;示例&#34;&gt;示例&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;路径&lt;/th&gt;
&lt;th&gt;请求路径&lt;/th&gt;
&lt;th&gt;匹配结果&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Prefix&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;(all paths)&lt;/td&gt;
&lt;td&gt;匹配&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Exact&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/foo&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/foo&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;匹配&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Exact&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/foo&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/bar&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;不匹配&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Exact&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/foo&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/foo/&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;不匹配&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Exact&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/foo/&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/foo&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;不匹配&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Prefix&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/foo&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/foo&lt;/code&gt;, &lt;code&gt;/foo/&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;匹配&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Prefix&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/foo/&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/foo&lt;/code&gt;, &lt;code&gt;/foo/&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;匹配&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Prefix&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/aaa/bb&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/aaa/bbb&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;不匹配&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Prefix&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/aaa/bbb&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/aaa/bbb&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;匹配&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Prefix&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/aaa/bbb/&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/aaa/bbb&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;匹配, 忽略尾部的斜线&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Prefix&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/aaa/bbb&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/aaa/bbb/&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;匹配, 匹配尾部的斜线&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Prefix&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/aaa/bbb&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/aaa/bbb/ccc&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;匹配, 匹配前缀&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Prefix&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/aaa/bbb&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/aaa/bbbxyz&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;不匹配, 不是匹配字符串前缀&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Prefix&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/&lt;/code&gt;, &lt;code&gt;/aaa&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/aaa/ccc&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;匹配, 匹配 &lt;code&gt;/aaa&lt;/code&gt; 前缀&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Prefix&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/&lt;/code&gt;, &lt;code&gt;/aaa&lt;/code&gt;, &lt;code&gt;/aaa/bbb&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/aaa/bbb&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;匹配, 匹配 &lt;code&gt;/aaa/bbb&lt;/code&gt; 前缀&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Prefix&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/&lt;/code&gt;, &lt;code&gt;/aaa&lt;/code&gt;, &lt;code&gt;/aaa/bbb&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/ccc&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;匹配, 匹配 &lt;code&gt;/&lt;/code&gt; 前缀&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Prefix&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/aaa&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/ccc&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;不匹配, 使用默认后端&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Mixed&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/foo&lt;/code&gt; (Prefix), &lt;code&gt;/foo&lt;/code&gt; (Exact)&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/foo&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;匹配, 优先完全匹配&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;!--
#### Multiple matches
In some cases, multiple paths within an Ingress will match a request. In those
cases precedence will be given first to the longest matching path. If two paths
are still equally matched, precedence will be given to paths with an exact path
type over prefix path type.
 --&gt;
&lt;h4 id=&#34;多匹配&#34;&gt;多匹配&lt;/h4&gt;
&lt;p&gt;在某些情况下，一个 Ingress 中的多个路径都能与请求路径相匹配。在这种情况下优先级最高的是最长匹配
路径。 如果还有两个路径匹配长度匹配相同，则完全匹配优先级高于前端匹配。&lt;/p&gt;
&lt;!--
## Hostname wildcards
Hosts can be precise matches (for example “`foo.bar.com`”) or a wildcard (for
example “`*.foo.com`”). Precise matches require that the HTTP `host` header
matches the `host` field. Wildcard matches require the HTTP `host` header is
equal to the suffix of the wildcard rule.

| Host        | Host header       | Match?                                            |
| ----------- |-------------------| --------------------------------------------------|
| `*.foo.com` | `bar.foo.com`     | Matches based on shared suffix                    |
| `*.foo.com` | `baz.bar.foo.com` | No match, wildcard only covers a single DNS label |
| `*.foo.com` | `foo.com`         | No match, wildcard only covers a single DNS label |



 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingingress-wildcard-hostyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/ingress-wildcard-host.yaml&#34; download=&#34;service/networking/ingress-wildcard-host.yaml&#34;&gt;
                    &lt;code&gt;service/networking/ingress-wildcard-host.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingingress-wildcard-hostyaml&#39;)&#34; title=&#34;Copy service/networking/ingress-wildcard-host.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;networking.k8s.io/v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Ingress&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;ingress-wildcard-host&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;rules&lt;/span&gt;:
  - &lt;span style=&#34;color:#f92672&#34;&gt;host&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;foo.bar.com&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;http&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;paths&lt;/span&gt;:
      - &lt;span style=&#34;color:#f92672&#34;&gt;pathType&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Prefix&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;path&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/bar&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;backend&lt;/span&gt;:
          &lt;span style=&#34;color:#f92672&#34;&gt;service&lt;/span&gt;:
            &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;service1&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;:
              &lt;span style=&#34;color:#f92672&#34;&gt;number&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
  - &lt;span style=&#34;color:#f92672&#34;&gt;host&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;*.foo.com&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;http&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;paths&lt;/span&gt;:
      - &lt;span style=&#34;color:#f92672&#34;&gt;pathType&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Prefix&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;path&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/foo&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;backend&lt;/span&gt;:
          &lt;span style=&#34;color:#f92672&#34;&gt;service&lt;/span&gt;:
            &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;service2&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;:
              &lt;span style=&#34;color:#f92672&#34;&gt;number&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;


 --&gt;
&lt;h2 id=&#34;主机名通配符&#34;&gt;主机名通配符&lt;/h2&gt;
&lt;p&gt;主机名可以是精确匹配(例如 &lt;code&gt;foo.bar.com&lt;/code&gt;)，也可以有通配符(例如 &lt;code&gt;*.foo.com&lt;/code&gt;)。
精确匹配必须要 HTTP 请求头中的 &lt;code&gt;host&lt;/code&gt; 与规则的 &lt;code&gt;host&lt;/code&gt; 字段完全匹配。
通配符则要 HTTP 请求头中的 &lt;code&gt;host&lt;/code&gt; 与通配符规则的后缀相同。&lt;/p&gt;
&lt;p&gt;例如:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;规则&lt;/th&gt;
&lt;th&gt;请求头&lt;code&gt;host&lt;/code&gt;&lt;/th&gt;
&lt;th&gt;匹配结果&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;*.foo.com&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;bar.foo.com&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;匹配，因为后缀相同&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;*.foo.com&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;baz.bar.foo.com&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;不匹配, 通配符只能包含一级子域名&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;*.foo.com&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;foo.com&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;不匹配, 通配符只能包含一级子域名&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingingress-wildcard-hostyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/ingress-wildcard-host.yaml&#34; download=&#34;service/networking/ingress-wildcard-host.yaml&#34;&gt;
                    &lt;code&gt;service/networking/ingress-wildcard-host.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingingress-wildcard-hostyaml&#39;)&#34; title=&#34;Copy service/networking/ingress-wildcard-host.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;networking.k8s.io/v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Ingress&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;ingress-wildcard-host&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;rules&lt;/span&gt;:
  - &lt;span style=&#34;color:#f92672&#34;&gt;host&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;foo.bar.com&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;http&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;paths&lt;/span&gt;:
      - &lt;span style=&#34;color:#f92672&#34;&gt;pathType&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Prefix&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;path&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/bar&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;backend&lt;/span&gt;:
          &lt;span style=&#34;color:#f92672&#34;&gt;service&lt;/span&gt;:
            &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;service1&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;:
              &lt;span style=&#34;color:#f92672&#34;&gt;number&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
  - &lt;span style=&#34;color:#f92672&#34;&gt;host&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;*.foo.com&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;http&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;paths&lt;/span&gt;:
      - &lt;span style=&#34;color:#f92672&#34;&gt;pathType&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Prefix&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;path&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/foo&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;backend&lt;/span&gt;:
          &lt;span style=&#34;color:#f92672&#34;&gt;service&lt;/span&gt;:
            &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;service2&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;:
              &lt;span style=&#34;color:#f92672&#34;&gt;number&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;


&lt;!--
## Ingress class

Ingresses can be implemented by different controllers, often with different
configuration. Each Ingress should specify a class, a reference to an
IngressClass resource that contains additional configuration including the name
of the controller that should implement the class.



 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingexternal-lbyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/external-lb.yaml&#34; download=&#34;service/networking/external-lb.yaml&#34;&gt;
                    &lt;code&gt;service/networking/external-lb.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingexternal-lbyaml&#39;)&#34; title=&#34;Copy service/networking/external-lb.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;networking.k8s.io/v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;IngressClass&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;external-lb&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;controller&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;example.com/ingress-controller&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;parameters&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;apiGroup&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;k8s.example.com&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;IngressParameters&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;external-lb&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;



IngressClass resources contain an optional parameters field. This can be used to
reference additional configuration for this class.
 --&gt;
&lt;h2 id=&#34;ingressclass&#34;&gt;IngressClass&lt;/h2&gt;
&lt;p&gt;Ingress 可以由不同的控制器实现，通常也会有不同的配置。 每个 Ingress 都需要指定一个类型，
它是一个 IngressClass 资源的引用， 其中包含如实现该类型的控制器的名称等额外配置。&lt;/p&gt;


 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingexternal-lbyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/external-lb.yaml&#34; download=&#34;service/networking/external-lb.yaml&#34;&gt;
                    &lt;code&gt;service/networking/external-lb.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingexternal-lbyaml&#39;)&#34; title=&#34;Copy service/networking/external-lb.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;networking.k8s.io/v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;IngressClass&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;external-lb&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;controller&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;example.com/ingress-controller&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;parameters&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;apiGroup&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;k8s.example.com&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;IngressParameters&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;external-lb&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;IngressClass 资源中包含一个可选参数字段。 可以用设置该类型额外配置的引用&lt;/p&gt;
&lt;!--

### Deprecated annotation

Before the IngressClass resource and `ingressClassName` field were added in
Kubernetes 1.18, Ingress classes were specified with a
`kubernetes.io/ingress.class` annotation on the Ingress. This annotation was
never formally defined, but was widely supported by Ingress controllers.

The newer `ingressClassName` field on Ingresses is a replacement for that
annotation, but is not a direct equivalent. While the annotation was generally
used to reference the name of the Ingress controller that should implement the
Ingress, the field is a reference to an IngressClass resource that contains
additional Ingress configuration, including the name of the Ingress controller.
 --&gt;
&lt;h3 id=&#34;废弃的注解&#34;&gt;废弃的注解&lt;/h3&gt;
&lt;p&gt;在 k8s 1.18 版本中添加 IngressClass 资源和 &lt;code&gt;ingressClassName&lt;/code&gt; 资源前，Ingress 的类型是
通过其上的 &lt;code&gt;kubernetes.io/ingress.class&lt;/code&gt; 注解指定的。 这个注解从来没有正式的定义过，但它
在 Ingress 控制器中被广泛支持。&lt;/p&gt;
&lt;p&gt;Ingress 中的新字段 &lt;code&gt;ingressClassName&lt;/code&gt; 就是对这个注解的替代，但它们也不是直接等价的。
其中注解通常是用来指定实现该 Ingress 的控制器的名称， 新字段则是指定一个 IngressClass 资源的引用。
这个 IngressClass 资源中包含一额外的 Ingress 配置参数和 Ingress 控制器的名称。&lt;/p&gt;
&lt;!--
### Default IngressClass {#default-ingress-class}

You can mark a particular IngressClass as default for your cluster. Setting the
`ingressclass.kubernetes.io/is-default-class` annotation to `true` on an
IngressClass resource will ensure that new Ingresses without an
`ingressClassName` field specified will be assigned this default IngressClass.

&lt;blockquote class=&#34;caution&#34;&gt;
  &lt;div&gt;&lt;strong&gt;注意：&lt;/strong&gt; If you have more than one IngressClass marked as the default for your cluster,
the admission controller prevents creating new Ingress objects that don&amp;rsquo;t have
an &lt;code&gt;ingressClassName&lt;/code&gt; specified. You can resolve this by ensuring that at most 1
IngressClass is marked as default in your cluster.&lt;/div&gt;
&lt;/blockquote&gt;

 --&gt;
&lt;h3 id=&#34;default-ingress-class&#34;&gt;默认 IngressClass&lt;/h3&gt;
&lt;p&gt;用户可以将某个 IngressClass 设置为集群的默认 IngressClass。
在 IngressClass 资源上设置 &lt;code&gt;ingressclass.kubernetes.io/is-default-class&lt;/code&gt; 注解值为 &lt;code&gt;true&lt;/code&gt;。
这样新创建 Ingress 如果没有设置 &lt;code&gt;ingressClassName&lt;/code&gt; 字段则会分配这个默认的 IngressClass。&lt;/p&gt;
&lt;blockquote class=&#34;caution&#34;&gt;
  &lt;div&gt;&lt;strong&gt;注意：&lt;/strong&gt; 如果集群中有不止一个 IngressClass 被标记为默认，准入控制器(admission controller) 就会禁止
创建没有设置 &lt;code&gt;ingressClassName&lt;/code&gt; 的 Ingress。 需要用户手动解决，确保集群中只有一个默认
IngressClass。&lt;/div&gt;
&lt;/blockquote&gt;

&lt;!--
## Types of Ingress

### Ingress backed by a single Service {#single-service-ingress}

There are existing Kubernetes concepts that allow you to expose a single Service
(see [alternatives](#alternatives)). You can also do this with an Ingress by specifying a
*default backend* with no rules.



 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingtest-ingressyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/test-ingress.yaml&#34; download=&#34;service/networking/test-ingress.yaml&#34;&gt;
                    &lt;code&gt;service/networking/test-ingress.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingtest-ingressyaml&#39;)&#34; title=&#34;Copy service/networking/test-ingress.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;networking.k8s.io/v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Ingress&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;test-ingress&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;defaultBackend&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;service&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;test&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;number&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;



If you create it using `kubectl apply -f` you should be able to view the state
of the Ingress you just added:

```bash
kubectl get ingress test-ingress
```

```
NAME           CLASS         HOSTS   ADDRESS         PORTS   AGE
test-ingress   external-lb   *       203.0.113.123   80      59s
```

Where `203.0.113.123` is the IP allocated by the Ingress controller to satisfy
this Ingress.

&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; Ingress controllers and load balancers may take a minute or two to allocate an IP address.
Until that time, you often see the address listed as &lt;code&gt;&amp;lt;pending&amp;gt;&lt;/code&gt;.&lt;/div&gt;
&lt;/blockquote&gt;

 --&gt;
&lt;h2 id=&#34;ingress-的类型&#34;&gt;Ingress 的类型&lt;/h2&gt;
&lt;h3 id=&#34;single-service-ingress&#34;&gt;后端只有一个 Service 的 Ingress &lt;/h3&gt;
&lt;p&gt;k8s 存在概念可以让用户暴露单个 Service (见 &lt;a href=&#34;#alternatives&#34;&gt;替代方案&lt;/a&gt;).
也可以通过一个指定 &lt;em&gt;默认后端&lt;/em&gt; 但没有配置规则的 Ingress 达到同样的效果。&lt;/p&gt;


 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingtest-ingressyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/test-ingress.yaml&#34; download=&#34;service/networking/test-ingress.yaml&#34;&gt;
                    &lt;code&gt;service/networking/test-ingress.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingtest-ingressyaml&#39;)&#34; title=&#34;Copy service/networking/test-ingress.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;networking.k8s.io/v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Ingress&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;test-ingress&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;defaultBackend&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;service&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;test&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;number&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;通过 &lt;code&gt;kubectl apply -f&lt;/code&gt; 创建 Ingress，并通过以下命令查看:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get ingress test-ingress
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;NAME           CLASS         HOSTS   ADDRESS         PORTS   AGE
test-ingress   external-lb   *       203.0.113.123   80      59s
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中 &lt;code&gt;203.0.113.123&lt;/code&gt; 是由 Ingress 控制器分配来满足这个 Ingress 的 IP 地址。&lt;/p&gt;
&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; Ingress 控制器和负载均衡器可能需要一两分钟为分配一个 IP 地址。在这之前，通常看到地址列的值为 &lt;code&gt;&amp;lt;pending&amp;gt;&lt;/code&gt;&lt;/div&gt;
&lt;/blockquote&gt;

&lt;!--
### Simple fanout

A fanout configuration routes traffic from a single IP address to more than one Service,
based on the HTTP URI being requested. An Ingress allows you to keep the number of load balancers
down to a minimum. For example, a setup like:

```
foo.bar.com -&gt; 178.91.123.132 -&gt; / foo    service1:4200
                                 / bar    service2:8080
```

would require an Ingress such as:



 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingsimple-fanout-exampleyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/simple-fanout-example.yaml&#34; download=&#34;service/networking/simple-fanout-example.yaml&#34;&gt;
                    &lt;code&gt;service/networking/simple-fanout-example.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingsimple-fanout-exampleyaml&#39;)&#34; title=&#34;Copy service/networking/simple-fanout-example.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;networking.k8s.io/v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Ingress&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;simple-fanout-example&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;rules&lt;/span&gt;:
  - &lt;span style=&#34;color:#f92672&#34;&gt;host&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;foo.bar.com&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;http&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;paths&lt;/span&gt;:
      - &lt;span style=&#34;color:#f92672&#34;&gt;path&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;/foo&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;pathType&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Prefix&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;backend&lt;/span&gt;:
          &lt;span style=&#34;color:#f92672&#34;&gt;service&lt;/span&gt;:
            &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;service1&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;:
              &lt;span style=&#34;color:#f92672&#34;&gt;number&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;4200&lt;/span&gt;
      - &lt;span style=&#34;color:#f92672&#34;&gt;path&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;/bar&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;pathType&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Prefix&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;backend&lt;/span&gt;:
          &lt;span style=&#34;color:#f92672&#34;&gt;service&lt;/span&gt;:
            &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;service2&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;:
              &lt;span style=&#34;color:#f92672&#34;&gt;number&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;8080&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;



When you create the Ingress with `kubectl apply -f`:

```shell
kubectl describe ingress simple-fanout-example
```

```
Name:             simple-fanout-example
Namespace:        default
Address:          178.91.123.132
Default backend:  default-http-backend:80 (10.8.2.3:8080)
Rules:
  Host         Path  Backends
  ----         ----  --------
  foo.bar.com
               /foo   service1:4200 (10.8.0.90:4200)
               /bar   service2:8080 (10.8.0.91:8080)
Events:
  Type     Reason  Age                From                     Message
  ----     ------  ----               ----                     -------
  Normal   ADD     22s                loadbalancer-controller  default/test
```

The Ingress controller provisions an implementation-specific load balancer
that satisfies the Ingress, as long as the Services (`service1`, `service2`) exist.
When it has done so, you can see the address of the load balancer at the
Address field.

&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; Depending on the &lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/docs/concepts/services-networking/ingress-controllers/&#34;&gt;Ingress controller&lt;/a&gt;
you are using, you may need to create a default-http-backend
&lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/docs/concepts/services-networking/service/&#34;&gt;Service&lt;/a&gt;.&lt;/div&gt;
&lt;/blockquote&gt;

 --&gt;
&lt;h3 id=&#34;简单分散fanout&#34;&gt;简单分散(fanout)&lt;/h3&gt;
&lt;p&gt;一个分散就是基于请求的 HTTP URI 配置路由流量从一单个 IP 地址到多个 Service。
一个 Ingress 可以使负载均衡器的数量减少到最低。 例如如下配置:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;foo.bar.com -&amp;gt; 178.91.123.132 -&amp;gt; / foo    service1:4200
                                 / bar    service2:8080
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;需要要一个如下 Ingress:&lt;/p&gt;


 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingsimple-fanout-exampleyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/simple-fanout-example.yaml&#34; download=&#34;service/networking/simple-fanout-example.yaml&#34;&gt;
                    &lt;code&gt;service/networking/simple-fanout-example.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingsimple-fanout-exampleyaml&#39;)&#34; title=&#34;Copy service/networking/simple-fanout-example.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;networking.k8s.io/v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Ingress&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;simple-fanout-example&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;rules&lt;/span&gt;:
  - &lt;span style=&#34;color:#f92672&#34;&gt;host&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;foo.bar.com&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;http&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;paths&lt;/span&gt;:
      - &lt;span style=&#34;color:#f92672&#34;&gt;path&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;/foo&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;pathType&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Prefix&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;backend&lt;/span&gt;:
          &lt;span style=&#34;color:#f92672&#34;&gt;service&lt;/span&gt;:
            &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;service1&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;:
              &lt;span style=&#34;color:#f92672&#34;&gt;number&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;4200&lt;/span&gt;
      - &lt;span style=&#34;color:#f92672&#34;&gt;path&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;/bar&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;pathType&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Prefix&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;backend&lt;/span&gt;:
          &lt;span style=&#34;color:#f92672&#34;&gt;service&lt;/span&gt;:
            &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;service2&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;:
              &lt;span style=&#34;color:#f92672&#34;&gt;number&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;8080&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;在使用 &lt;code&gt;kubectl apply -f&lt;/code&gt; 命令创建 Ingress 后，通过以下命令查看详情:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl describe ingress simple-fanout-example
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Name:             simple-fanout-example
Namespace:        default
Address:          178.91.123.132
Default backend:  default-http-backend:80 (10.8.2.3:8080)
Rules:
  Host         Path  Backends
  ----         ----  --------
  foo.bar.com
               /foo   service1:4200 (10.8.0.90:4200)
               /bar   service2:8080 (10.8.0.91:8080)
Events:
  Type     Reason  Age                From                     Message
  ----     ------  ----               ----                     -------
  Normal   ADD     22s                loadbalancer-controller  default/test
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Ingress 控制器会在目标 Service (&lt;code&gt;service1&lt;/code&gt;, &lt;code&gt;service2&lt;/code&gt;) 还存在时，
根据本身实现提供一个满足 Ingress 的负载均衡器直到。
当创建好后，可以在地址字段看到负载均衡器的地址。&lt;/p&gt;
&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; 基于使用的
&lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/docs/concepts/services-networking/ingress-controllers/&#34;&gt;Ingress 控制器&lt;/a&gt;
可能需要创建一个 default-http-backend
&lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/docs/concepts/services-networking/service/&#34;&gt;Service&lt;/a&gt;.&lt;/div&gt;
&lt;/blockquote&gt;

&lt;!--
### Name based virtual hosting

Name-based virtual hosts support routing HTTP traffic to multiple host names at the same IP address.

```none
foo.bar.com --|                 |-&gt; foo.bar.com service1:80
              | 178.91.123.132  |
bar.foo.com --|                 |-&gt; bar.foo.com service2:80
```

The following Ingress tells the backing load balancer to route requests based on
the [Host header](https://tools.ietf.org/html/rfc7230#section-5.4).



 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingname-virtual-host-ingressyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/name-virtual-host-ingress.yaml&#34; download=&#34;service/networking/name-virtual-host-ingress.yaml&#34;&gt;
                    &lt;code&gt;service/networking/name-virtual-host-ingress.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingname-virtual-host-ingressyaml&#39;)&#34; title=&#34;Copy service/networking/name-virtual-host-ingress.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;networking.k8s.io/v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Ingress&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;name-virtual-host-ingress&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;rules&lt;/span&gt;:
  - &lt;span style=&#34;color:#f92672&#34;&gt;host&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;foo.bar.com&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;http&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;paths&lt;/span&gt;:
      - &lt;span style=&#34;color:#f92672&#34;&gt;pathType&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Prefix&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;path&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;backend&lt;/span&gt;:
          &lt;span style=&#34;color:#f92672&#34;&gt;service&lt;/span&gt;:
            &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;service1&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;:
              &lt;span style=&#34;color:#f92672&#34;&gt;number&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
  - &lt;span style=&#34;color:#f92672&#34;&gt;host&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;bar.foo.com&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;http&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;paths&lt;/span&gt;:
      - &lt;span style=&#34;color:#f92672&#34;&gt;pathType&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Prefix&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;path&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;backend&lt;/span&gt;:
          &lt;span style=&#34;color:#f92672&#34;&gt;service&lt;/span&gt;:
            &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;service2&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;:
              &lt;span style=&#34;color:#f92672&#34;&gt;number&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;



If you create an Ingress resource without any hosts defined in the rules, then any
web traffic to the IP address of your Ingress controller can be matched without a name based
virtual host being required.

For example, the following Ingress routes traffic
requested for `first.bar.com` to `service1`, `second.foo.com` to `service2`, and any traffic
to the IP address without a hostname defined in request (that is, without a request header being
presented) to `service3`.



 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingname-virtual-host-ingress-no-third-hostyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/name-virtual-host-ingress-no-third-host.yaml&#34; download=&#34;service/networking/name-virtual-host-ingress-no-third-host.yaml&#34;&gt;
                    &lt;code&gt;service/networking/name-virtual-host-ingress-no-third-host.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingname-virtual-host-ingress-no-third-hostyaml&#39;)&#34; title=&#34;Copy service/networking/name-virtual-host-ingress-no-third-host.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;networking.k8s.io/v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Ingress&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;name-virtual-host-ingress-no-third-host&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;rules&lt;/span&gt;:
  - &lt;span style=&#34;color:#f92672&#34;&gt;host&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;first.bar.com&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;http&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;paths&lt;/span&gt;:
      - &lt;span style=&#34;color:#f92672&#34;&gt;pathType&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Prefix&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;path&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;backend&lt;/span&gt;:
          &lt;span style=&#34;color:#f92672&#34;&gt;service&lt;/span&gt;:
            &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;service1&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;:
              &lt;span style=&#34;color:#f92672&#34;&gt;number&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
  - &lt;span style=&#34;color:#f92672&#34;&gt;host&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;second.bar.com&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;http&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;paths&lt;/span&gt;:
      - &lt;span style=&#34;color:#f92672&#34;&gt;pathType&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Prefix&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;path&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;backend&lt;/span&gt;:
          &lt;span style=&#34;color:#f92672&#34;&gt;service&lt;/span&gt;:
            &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;service2&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;:
              &lt;span style=&#34;color:#f92672&#34;&gt;number&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
  - &lt;span style=&#34;color:#f92672&#34;&gt;http&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;paths&lt;/span&gt;:
      - &lt;span style=&#34;color:#f92672&#34;&gt;pathType&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Prefix&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;path&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;backend&lt;/span&gt;:
          &lt;span style=&#34;color:#f92672&#34;&gt;service&lt;/span&gt;:
            &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;service3&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;:
              &lt;span style=&#34;color:#f92672&#34;&gt;number&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;


 --&gt;
&lt;h3 id=&#34;基于名称的虚拟主机&#34;&gt;基于名称的虚拟主机&lt;/h3&gt;
&lt;p&gt;基于名称的虚拟主机支持在同一个IP上将 HTTP 流量路由到多个主机名上。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-none&#34; data-lang=&#34;none&#34;&gt;foo.bar.com --|                 |-&amp;gt; foo.bar.com service1:80
              | 178.91.123.132  |
bar.foo.com --|                 |-&amp;gt; bar.foo.com service2:80
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The following Ingress tells the backing load balancer to route requests based on
the &lt;a href=&#34;https://tools.ietf.org/html/rfc7230#section-5.4&#34;&gt;Host header&lt;/a&gt;.
以下 Ingress 告诉后端的负载均衡器基于
&lt;a href=&#34;https://tools.ietf.org/html/rfc7230#section-5.4&#34;&gt;Host 头字段&lt;/a&gt;
路由请求。&lt;/p&gt;


 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingname-virtual-host-ingressyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/name-virtual-host-ingress.yaml&#34; download=&#34;service/networking/name-virtual-host-ingress.yaml&#34;&gt;
                    &lt;code&gt;service/networking/name-virtual-host-ingress.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingname-virtual-host-ingressyaml&#39;)&#34; title=&#34;Copy service/networking/name-virtual-host-ingress.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;networking.k8s.io/v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Ingress&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;name-virtual-host-ingress&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;rules&lt;/span&gt;:
  - &lt;span style=&#34;color:#f92672&#34;&gt;host&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;foo.bar.com&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;http&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;paths&lt;/span&gt;:
      - &lt;span style=&#34;color:#f92672&#34;&gt;pathType&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Prefix&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;path&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;backend&lt;/span&gt;:
          &lt;span style=&#34;color:#f92672&#34;&gt;service&lt;/span&gt;:
            &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;service1&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;:
              &lt;span style=&#34;color:#f92672&#34;&gt;number&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
  - &lt;span style=&#34;color:#f92672&#34;&gt;host&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;bar.foo.com&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;http&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;paths&lt;/span&gt;:
      - &lt;span style=&#34;color:#f92672&#34;&gt;pathType&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Prefix&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;path&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;backend&lt;/span&gt;:
          &lt;span style=&#34;color:#f92672&#34;&gt;service&lt;/span&gt;:
            &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;service2&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;:
              &lt;span style=&#34;color:#f92672&#34;&gt;number&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;If you create an Ingress resource without any hosts defined in the rules, then any
web traffic to the IP address of your Ingress controller can be matched without a name based
virtual host being required.
如果创建的 Ingress 资源中没有定义任何主机规则，则所有到达这个 Ingress 控制 IP 的的 web 流量
则不需要基于名称的虚拟主机就能匹配。&lt;/p&gt;
&lt;p&gt;例如， 以下 Ingress 路由 &lt;code&gt;first.bar.com&lt;/code&gt; 的请求到 &lt;code&gt;service1&lt;/code&gt;，
&lt;code&gt;second.foo.com&lt;/code&gt; 的请求到 &lt;code&gt;service2&lt;/code&gt;，其它任意到达这个 IP 地址，但在请求中没有包含主机名
(也就是没的请求头(或请求头中没有 Host 字段))的请求到 &lt;code&gt;service3&lt;/code&gt;&lt;/p&gt;


 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingname-virtual-host-ingress-no-third-hostyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/name-virtual-host-ingress-no-third-host.yaml&#34; download=&#34;service/networking/name-virtual-host-ingress-no-third-host.yaml&#34;&gt;
                    &lt;code&gt;service/networking/name-virtual-host-ingress-no-third-host.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingname-virtual-host-ingress-no-third-hostyaml&#39;)&#34; title=&#34;Copy service/networking/name-virtual-host-ingress-no-third-host.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;networking.k8s.io/v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Ingress&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;name-virtual-host-ingress-no-third-host&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;rules&lt;/span&gt;:
  - &lt;span style=&#34;color:#f92672&#34;&gt;host&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;first.bar.com&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;http&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;paths&lt;/span&gt;:
      - &lt;span style=&#34;color:#f92672&#34;&gt;pathType&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Prefix&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;path&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;backend&lt;/span&gt;:
          &lt;span style=&#34;color:#f92672&#34;&gt;service&lt;/span&gt;:
            &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;service1&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;:
              &lt;span style=&#34;color:#f92672&#34;&gt;number&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
  - &lt;span style=&#34;color:#f92672&#34;&gt;host&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;second.bar.com&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;http&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;paths&lt;/span&gt;:
      - &lt;span style=&#34;color:#f92672&#34;&gt;pathType&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Prefix&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;path&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;backend&lt;/span&gt;:
          &lt;span style=&#34;color:#f92672&#34;&gt;service&lt;/span&gt;:
            &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;service2&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;:
              &lt;span style=&#34;color:#f92672&#34;&gt;number&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
  - &lt;span style=&#34;color:#f92672&#34;&gt;http&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;paths&lt;/span&gt;:
      - &lt;span style=&#34;color:#f92672&#34;&gt;pathType&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Prefix&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;path&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;backend&lt;/span&gt;:
          &lt;span style=&#34;color:#f92672&#34;&gt;service&lt;/span&gt;:
            &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;service3&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;:
              &lt;span style=&#34;color:#f92672&#34;&gt;number&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;


&lt;!--
### TLS

You can secure an Ingress by specifying a &lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/docs/concepts/configuration/secret/&#39; target=&#39;_blank&#39;&gt;Secret&lt;span class=&#39;tooltip-text&#39;&gt;存放如密码, OAuth, ssh 密钥等敏感信息&lt;/span&gt;
&lt;/a&gt;
that contains a TLS private key and certificate. The Ingress resource only
supports a single TLS port, 443, and assumes TLS termination at the ingress point
(traffic to the Service and its Pods is in plaintext).
If the TLS configuration section in an Ingress specifies different hosts, they are
multiplexed on the same port according to the hostname specified through the
SNI TLS extension (provided the Ingress controller supports SNI). The TLS secret
must contain keys named `tls.crt` and `tls.key` that contain the certificate
and private key to use for TLS. For example:

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: testsecret-tls
  namespace: default
data:
  tls.crt: base64 encoded cert
  tls.key: base64 encoded key
type: kubernetes.io/tls
```

Referencing this secret in an Ingress tells the Ingress controller to
secure the channel from the client to the load balancer using TLS. You need to make
sure the TLS secret you created came from a certificate that contains a Common
Name (CN), also known as a Fully Qualified Domain Name (FQDN) for `sslexample.foo.com`.



 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingtls-example-ingressyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/tls-example-ingress.yaml&#34; download=&#34;service/networking/tls-example-ingress.yaml&#34;&gt;
                    &lt;code&gt;service/networking/tls-example-ingress.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingtls-example-ingressyaml&#39;)&#34; title=&#34;Copy service/networking/tls-example-ingress.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;networking.k8s.io/v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Ingress&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;tls-example-ingress&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;tls&lt;/span&gt;:
  - &lt;span style=&#34;color:#f92672&#34;&gt;hosts&lt;/span&gt;:
      - &lt;span style=&#34;color:#ae81ff&#34;&gt;https-example.foo.com&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;secretName&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;testsecret-tls&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;rules&lt;/span&gt;:
  - &lt;span style=&#34;color:#f92672&#34;&gt;host&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;https-example.foo.com&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;http&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;paths&lt;/span&gt;:
      - &lt;span style=&#34;color:#f92672&#34;&gt;path&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;/&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;pathType&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Prefix&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;backend&lt;/span&gt;:
          &lt;span style=&#34;color:#f92672&#34;&gt;service&lt;/span&gt;:
            &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;service1&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;:
              &lt;span style=&#34;color:#f92672&#34;&gt;number&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;



&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; There is a gap between TLS features supported by various Ingress
controllers. Please refer to documentation on
&lt;a href=&#34;https://kubernetes.github.io/ingress-nginx/user-guide/tls/&#34;&gt;nginx&lt;/a&gt;,
&lt;a href=&#34;https://git.k8s.io/ingress-gce/README.md#frontend-https&#34;&gt;GCE&lt;/a&gt;, or any other
platform specific Ingress controller to understand how TLS works in your environment.&lt;/div&gt;
&lt;/blockquote&gt;

 --&gt;
&lt;h3 id=&#34;tls&#34;&gt;TLS&lt;/h3&gt;
&lt;p&gt;用户可以能过一个包含 TLS 私钥和证书的 &lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/docs/concepts/configuration/secret/&#39; target=&#39;_blank&#39;&gt;Secret&lt;span class=&#39;tooltip-text&#39;&gt;存放如密码, OAuth, ssh 密钥等敏感信息&lt;/span&gt;
&lt;/a&gt; 为 Ingress
添加安全层。 Ingress 只支持一个 TLS 端口，&lt;code&gt;443&lt;/code&gt;， 并且假定 TLS 在 Ingress 终结(也就是
到达 Service 及其 Pod 的流量是明文的)。
如果 Ingress TLS 配置区中包含了多个主机名，那么它们根据 SNI TLS 扩展(需要 Ingress 控制器
支持 SNI)中指定的主机名来区分请求。 TLS &lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/docs/concepts/configuration/secret/&#39; target=&#39;_blank&#39;&gt;Secret&lt;span class=&#39;tooltip-text&#39;&gt;存放如密码, OAuth, ssh 密钥等敏感信息&lt;/span&gt;
&lt;/a&gt;
中必须要包含名叫 &lt;code&gt;tls.crt&lt;/code&gt; 和 &lt;code&gt;tls.key&lt;/code&gt; 的键，其它分别存放 TLS 的证书和私钥。 例如:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Secret&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;testsecret-tls&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;namespace&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;default&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;data&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;tls.crt&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;base64 encoded cert&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;tls.key&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;base64 encoded key&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;type&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;kubernetes.io/tls&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在一个 Ingress 中引用该 &lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/docs/concepts/configuration/secret/&#39; target=&#39;_blank&#39;&gt;Secret&lt;span class=&#39;tooltip-text&#39;&gt;存放如密码, OAuth, ssh 密钥等敏感信息&lt;/span&gt;
&lt;/a&gt; 保证客户端到负载均衡器之间的
连接是使用 TLS。必须要保证创建 TLS Secret 的证书中包含公用名(CN), 也就是 &lt;code&gt;sslexample.foo.com&lt;/code&gt;
的全限定名(FQDN).&lt;/p&gt;


 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingtls-example-ingressyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/tls-example-ingress.yaml&#34; download=&#34;service/networking/tls-example-ingress.yaml&#34;&gt;
                    &lt;code&gt;service/networking/tls-example-ingress.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingtls-example-ingressyaml&#39;)&#34; title=&#34;Copy service/networking/tls-example-ingress.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;networking.k8s.io/v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Ingress&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;tls-example-ingress&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;tls&lt;/span&gt;:
  - &lt;span style=&#34;color:#f92672&#34;&gt;hosts&lt;/span&gt;:
      - &lt;span style=&#34;color:#ae81ff&#34;&gt;https-example.foo.com&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;secretName&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;testsecret-tls&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;rules&lt;/span&gt;:
  - &lt;span style=&#34;color:#f92672&#34;&gt;host&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;https-example.foo.com&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;http&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;paths&lt;/span&gt;:
      - &lt;span style=&#34;color:#f92672&#34;&gt;path&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;/&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;pathType&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Prefix&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;backend&lt;/span&gt;:
          &lt;span style=&#34;color:#f92672&#34;&gt;service&lt;/span&gt;:
            &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;service1&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;:
              &lt;span style=&#34;color:#f92672&#34;&gt;number&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;


&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; 不同的 Ingress 控制器对 TLS 特性的支持有较大差异。 请查阅
&lt;a href=&#34;https://kubernetes.github.io/ingress-nginx/user-guide/tls/&#34;&gt;nginx&lt;/a&gt;,
&lt;a href=&#34;https://git.k8s.io/ingress-gce/README.md#frontend-https&#34;&gt;GCE&lt;/a&gt;,
或其它平台相应的 Ingress 控制的说明文档，以理解在你的环境中 TLS 是怎么工作的。&lt;/div&gt;
&lt;/blockquote&gt;

&lt;!--
### Load balancing {#load-balancing}

An Ingress controller is bootstrapped with some load balancing policy settings
that it applies to all Ingress, such as the load balancing algorithm, backend
weight scheme, and others. More advanced load balancing concepts
(e.g. persistent sessions, dynamic weights) are not yet exposed through the
Ingress. You can instead get these features through the load balancer used for
a Service.

It&#39;s also worth noting that even though health checks are not exposed directly
through the Ingress, there exist parallel concepts in Kubernetes such as
[readiness probes](/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/)
that allow you to achieve the same end result. Please review the controller
specific documentation to see how they handle health checks (for example:
[nginx](https://git.k8s.io/ingress-nginx/README.md), or
[GCE](https://git.k8s.io/ingress-gce/README.md#health-checks)).
 --&gt;
&lt;h3 id=&#34;load-balancing&#34;&gt;负载均衡&lt;/h3&gt;
&lt;p&gt;Ingress 控制器天生带有一些会应用到所有 Ingress 负载均衡策略设置，如 负载均衡算法，后端权重，等。
更高级的负载均衡概念(如，持久会化，动态权重)目前还没能过 Ingress 实现。 要实现这些特性可以通过
Service 使用的负载均衡器。&lt;/p&gt;
&lt;p&gt;还有值得注意的是健康检查不是直接通过 Ingress 暴露的。 k8s 中存在如
&lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/&#34;&gt;存活探针&lt;/a&gt;
的平行概念，允许用户达成同样的结果。 请查阅控制的说明文档，看看是怎么处理健康检查的(例如
&lt;a href=&#34;https://git.k8s.io/ingress-nginx/README.md&#34;&gt;nginx&lt;/a&gt;, or
&lt;a href=&#34;https://git.k8s.io/ingress-gce/README.md#health-checks&#34;&gt;GCE&lt;/a&gt;).
)&lt;/p&gt;
&lt;!--
## Updating an Ingress

To update an existing Ingress to add a new Host, you can update it by editing the resource:

```shell
kubectl describe ingress test
```

```
Name:             test
Namespace:        default
Address:          178.91.123.132
Default backend:  default-http-backend:80 (10.8.2.3:8080)
Rules:
  Host         Path  Backends
  ----         ----  --------
  foo.bar.com
               /foo   service1:80 (10.8.0.90:80)
Annotations:
  nginx.ingress.kubernetes.io/rewrite-target:  /
Events:
  Type     Reason  Age                From                     Message
  ----     ------  ----               ----                     -------
  Normal   ADD     35s                loadbalancer-controller  default/test
```

```shell
kubectl edit ingress test
```

This pops up an editor with the existing configuration in YAML format.
Modify it to include the new Host:

```yaml
spec:
  rules:
  - host: foo.bar.com
    http:
      paths:
      - backend:
          service:
            name: service1
            port:
              number: 80
        path: /foo
        pathType: Prefix
  - host: bar.baz.com
    http:
      paths:
      - backend:
          service:
            name: service2
            port:
              number: 80
        path: /foo
        pathType: Prefix
..
```

After you save your changes, kubectl updates the resource in the API server, which tells the
Ingress controller to reconfigure the load balancer.

Verify this:

```shell
kubectl describe ingress test
```

```
Name:             test
Namespace:        default
Address:          178.91.123.132
Default backend:  default-http-backend:80 (10.8.2.3:8080)
Rules:
  Host         Path  Backends
  ----         ----  --------
  foo.bar.com
               /foo   service1:80 (10.8.0.90:80)
  bar.baz.com
               /foo   service2:80 (10.8.0.91:80)
Annotations:
  nginx.ingress.kubernetes.io/rewrite-target:  /
Events:
  Type     Reason  Age                From                     Message
  ----     ------  ----               ----                     -------
  Normal   ADD     45s                loadbalancer-controller  default/test
```

You can achieve the same outcome by invoking `kubectl replace -f` on a modified Ingress YAML file.
 --&gt;
&lt;h2 id=&#34;更新-ingress&#34;&gt;更新 Ingress&lt;/h2&gt;
&lt;p&gt;要在已经存在的 Ingress 中添加一个新的主机规则，可以通过编辑 Ingress 资源实现:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl describe ingress test
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Name:             test
Namespace:        default
Address:          178.91.123.132
Default backend:  default-http-backend:80 (10.8.2.3:8080)
Rules:
  Host         Path  Backends
  ----         ----  --------
  foo.bar.com
               /foo   service1:80 (10.8.0.90:80)
Annotations:
  nginx.ingress.kubernetes.io/rewrite-target:  /
Events:
  Type     Reason  Age                From                     Message
  ----     ------  ----               ----                     -------
  Normal   ADD     35s                loadbalancer-controller  default/test
&lt;/code&gt;&lt;/pre&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl edit ingress test
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这条命令会用文本编辑器打开已经存在的 Ingress  YAML 格式的配置文件，在其中添加新的主机规则配置:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;rules&lt;/span&gt;:
  - &lt;span style=&#34;color:#f92672&#34;&gt;host&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;foo.bar.com&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;http&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;paths&lt;/span&gt;:
      - &lt;span style=&#34;color:#f92672&#34;&gt;backend&lt;/span&gt;:
          &lt;span style=&#34;color:#f92672&#34;&gt;service&lt;/span&gt;:
            &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;service1&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;:
              &lt;span style=&#34;color:#f92672&#34;&gt;number&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;path&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;/foo&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;pathType&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Prefix&lt;/span&gt;
  - &lt;span style=&#34;color:#f92672&#34;&gt;host&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;bar.baz.com&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;http&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;paths&lt;/span&gt;:
      - &lt;span style=&#34;color:#f92672&#34;&gt;backend&lt;/span&gt;:
          &lt;span style=&#34;color:#f92672&#34;&gt;service&lt;/span&gt;:
            &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;service2&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;:
              &lt;span style=&#34;color:#f92672&#34;&gt;number&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;path&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;/foo&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;pathType&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Prefix&lt;/span&gt;
&lt;span style=&#34;color:#ae81ff&#34;&gt;..&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在保存修改后， kubectl 就会在 API-server 中更新该资源，这会使得 Ingress 控制器重新配置
负载均衡器&lt;/p&gt;
&lt;p&gt;通过以下命令验证:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl describe ingress test
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Name:             test
Namespace:        default
Address:          178.91.123.132
Default backend:  default-http-backend:80 (10.8.2.3:8080)
Rules:
  Host         Path  Backends
  ----         ----  --------
  foo.bar.com
               /foo   service1:80 (10.8.0.90:80)
  bar.baz.com
               /foo   service2:80 (10.8.0.91:80)
Annotations:
  nginx.ingress.kubernetes.io/rewrite-target:  /
Events:
  Type     Reason  Age                From                     Message
  ----     ------  ----               ----                     -------
  Normal   ADD     45s                loadbalancer-controller  default/test
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;也可以通过在外部修改 Ingress YAML 配置后，使用 &lt;code&gt;kubectl replace -f&lt;/code&gt; 命令可以达成相同的效果。&lt;/p&gt;
&lt;!--
## Failing across availability zones

Techniques for spreading traffic across failure domains differ between cloud providers.
Please check the documentation of the relevant [Ingress controller](/docs/concepts/services-networking/ingress-controllers) for details.
 --&gt;
&lt;h2 id=&#34;跨可用区失效&#34;&gt;跨可用区失效&lt;/h2&gt;
&lt;p&gt;在故障域之间传播流量的方法在各家云提供商上的方式都不一样。
请查看 &lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/docs/concepts/services-networking/ingress-controllers&#34;&gt;Ingress 控制器&lt;/a&gt;文档了解详细信息&lt;/p&gt;
&lt;!--
## Alternatives

You can expose a Service in multiple ways that don&#39;t directly involve the Ingress resource:

* Use [Service.Type=LoadBalancer](/docs/concepts/services-networking/service/#loadbalancer)
* Use [Service.Type=NodePort](/docs/concepts/services-networking/service/#nodeport)
 --&gt;
&lt;h2 id=&#34;alternatives&#34;&gt;替代方案&lt;/h2&gt;
&lt;p&gt;在不直接使用 Ingress 的情况下还有几种暴露 Service 的方法:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用 &lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/docs/concepts/services-networking/service/#loadbalancer&#34;&gt;Service.Type=LoadBalancer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;使用 &lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/docs/concepts/services-networking/service/#nodeport&#34;&gt;Service.Type=NodePort&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;相关资料&#34;&gt;相关资料&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;查阅 &lt;a href=&#34;https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.19/#ingress-v1beta1-networking-k8s-io&#34;&gt;Ingress API&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;概念 &lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/docs/concepts/services-networking/ingress-controllers/&#34;&gt;Ingress 控制器&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;实践 &lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/tasks/access-application-cluster/ingress-minikube/&#34;&gt;使用 NGINX 控制器在 Minikube 上设置 Ingress&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Ingress 控制器</title>
      <link>https://lostsquirrel.github.io/k8sDocs/docs/concepts/services-networking/ingress-controllers/</link>
      <pubDate>Wed, 23 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://lostsquirrel.github.io/k8sDocs/docs/concepts/services-networking/ingress-controllers/</guid>
      <description>
        
        
        &lt;!--
---
title: Ingress Controllers
reviewers:
content_type: concept
weight: 40
--- --&gt;
&lt;!-- overview --&gt;
&lt;!--
In order for the Ingress resource to work, the cluster must have an ingress controller running.

Unlike other types of controllers which run as part of the `kube-controller-manager` binary, Ingress controllers
are not started automatically with a cluster. Use this page to choose the ingress controller implementation
that best fits your cluster.

Kubernetes as a project currently supports and maintains [GCE](https://git.k8s.io/ingress-gce/README.md) and
  [nginx](https://git.k8s.io/ingress-nginx/README.md) controllers.
 --&gt;
&lt;p&gt;要使一个 Ingress 工作的前提是集群中必须要有一个 Ingress 控制器在运行。&lt;/p&gt;
&lt;p&gt;与其它类型的控制器作为 &lt;code&gt;kube-controller-manager&lt;/code&gt; 的一部分运行不同， Ingress 不会自动在集群中
运行。 使用本文选择最适合你的集群的 Ingress 控制器实现。&lt;/p&gt;
&lt;p&gt;k8s 项目目前支持和维护
&lt;a href=&#34;https://git.k8s.io/ingress-gce/README.md&#34;&gt;GCE&lt;/a&gt;
和
&lt;a href=&#34;https://git.k8s.io/ingress-nginx/README.md&#34;&gt;nginx&lt;/a&gt;
控制器&lt;/p&gt;
&lt;!-- body --&gt;
&lt;!--
## Additional controllers

* [AKS Application Gateway Ingress Controller](https://github.com/Azure/application-gateway-kubernetes-ingress) is an ingress controller that enables ingress to [AKS clusters](https://docs.microsoft.com/azure/aks/kubernetes-walkthrough-portal) using the [Azure Application Gateway](https://docs.microsoft.com/azure/application-gateway/overview).
* [Ambassador](https://www.getambassador.io/) API Gateway is an [Envoy](https://www.envoyproxy.io) based ingress
  controller with [community](https://www.getambassador.io/docs) or
  [commercial](https://www.getambassador.io/pro/) support from [Datawire](https://www.datawire.io/).
* [AppsCode Inc.](https://appscode.com) offers support and maintenance for the most widely used [HAProxy](https://www.haproxy.org/) based ingress controller [Voyager](https://appscode.com/products/voyager).
* [AWS ALB Ingress Controller](https://github.com/kubernetes-sigs/aws-alb-ingress-controller) enables ingress using the [AWS Application Load Balancer](https://aws.amazon.com/elasticloadbalancing/).
* [Contour](https://projectcontour.io/) is an [Envoy](https://www.envoyproxy.io/) based ingress controller
  provided and supported by VMware.
* Citrix provides an [Ingress Controller](https://github.com/citrix/citrix-k8s-ingress-controller) for its hardware (MPX), virtualized (VPX) and [free containerized (CPX) ADC](https://www.citrix.com/products/citrix-adc/cpx-express.html) for [baremetal](https://github.com/citrix/citrix-k8s-ingress-controller/tree/master/deployment/baremetal) and [cloud](https://github.com/citrix/citrix-k8s-ingress-controller/tree/master/deployment) deployments.
* F5 Networks provides [support and maintenance](https://support.f5.com/csp/article/K86859508)
  for the [F5 BIG-IP Container Ingress Services for Kubernetes](https://clouddocs.f5.com/containers/latest/userguide/kubernetes/).
* [Gloo](https://gloo.solo.io) is an open-source ingress controller based on [Envoy](https://www.envoyproxy.io) which offers API Gateway functionality with enterprise support from [solo.io](https://www.solo.io).  
* [HAProxy Ingress](https://haproxy-ingress.github.io) is a highly customizable community-driven ingress controller for HAProxy.
* [HAProxy Technologies](https://www.haproxy.com/) offers support and maintenance for the [HAProxy Ingress Controller for Kubernetes](https://github.com/haproxytech/kubernetes-ingress). See the [official documentation](https://www.haproxy.com/documentation/hapee/1-9r1/traffic-management/kubernetes-ingress-controller/).
* [Istio](https://istio.io/) based ingress controller
  [Control Ingress Traffic](https://istio.io/docs/tasks/traffic-management/ingress/).
* [Kong](https://konghq.com/) offers [community](https://discuss.konghq.com/c/kubernetes) or
  [commercial](https://konghq.com/kong-enterprise/) support and maintenance for the
  [Kong Ingress Controller for Kubernetes](https://github.com/Kong/kubernetes-ingress-controller).
* [NGINX, Inc.](https://www.nginx.com/) offers support and maintenance for the
  [NGINX Ingress Controller for Kubernetes](https://www.nginx.com/products/nginx/kubernetes-ingress-controller).
* [Skipper](https://opensource.zalando.com/skipper/kubernetes/ingress-controller/) HTTP router and reverse proxy for service composition, including use cases like Kubernetes Ingress, designed as a library to build your custom proxy
* [Traefik](https://github.com/containous/traefik) is a fully featured ingress controller
  ([Let&#39;s Encrypt](https://letsencrypt.org), secrets, http2, websocket), and it also comes with commercial
  support by [Containous](https://containo.us/services).
 --&gt;
&lt;h2 id=&#34;其它的控制器&#34;&gt;其它的控制器&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/Azure/application-gateway-kubernetes-ingress&#34;&gt;AKS Application Gateway Ingress Controller&lt;/a&gt;
是使用
&lt;a href=&#34;https://docs.microsoft.com/azure/application-gateway/overview&#34;&gt;Azure Application Gateway&lt;/a&gt;
为
&lt;a href=&#34;https://docs.microsoft.com/azure/aks/kubernetes-walkthrough-portal&#34;&gt;AKS 集群&lt;/a&gt;
提供入口的 Ingress 控制器&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.getambassador.io/&#34;&gt;Ambassador&lt;/a&gt; API 网关
是一个基于
&lt;a href=&#34;https://www.envoyproxy.io&#34;&gt;Envoy&lt;/a&gt;
的 Ingress 控制器
有 &lt;a href=&#34;https://www.getambassador.io/docs&#34;&gt;社区&lt;/a&gt; 支持和
来自
&lt;a href=&#34;https://www.datawire.io/&#34;&gt;Datawire&lt;/a&gt;
的
&lt;a href=&#34;https://www.getambassador.io/pro/&#34;&gt;商业&lt;/a&gt; 支持&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://appscode.com&#34;&gt;AppsCode Inc.&lt;/a&gt; 提供了最广泛使用的基于
&lt;a href=&#34;https://www.haproxy.org/&#34;&gt;HAProxy&lt;/a&gt;
的 Ingress 控制器
&lt;a href=&#34;https://appscode.com/products/voyager&#34;&gt;Voyager&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubernetes-sigs/aws-alb-ingress-controller&#34;&gt;AWS ALB Ingress Controller&lt;/a&gt;
使用
&lt;a href=&#34;https://aws.amazon.com/elasticloadbalancing/&#34;&gt;AWS Application Load Balancer&lt;/a&gt;
实现 Ingress&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://projectcontour.io/&#34;&gt;Contour&lt;/a&gt;
由 VMware 提供和支持的基于 &lt;a href=&#34;https://www.envoyproxy.io/&#34;&gt;Envoy&lt;/a&gt; 的 Ingress 控制器&lt;/li&gt;
&lt;li&gt;Citrix 为它的
&lt;a href=&#34;https://github.com/citrix/citrix-k8s-ingress-controller/tree/master/deployment/baremetal&#34;&gt;baremetal&lt;/a&gt;
和
&lt;a href=&#34;https://github.com/citrix/citrix-k8s-ingress-controller/tree/master/deployment&#34;&gt;cloud&lt;/a&gt;
上部署的硬件(MPX),虚拟化(VPX)和
&lt;a href=&#34;https://www.citrix.com/products/citrix-adc/cpx-express.html&#34;&gt;free containerized (CPX) ADC&lt;/a&gt;
提供的 &lt;a href=&#34;https://github.com/citrix/citrix-k8s-ingress-controller&#34;&gt;Ingress 控制器&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;F5 Networks&lt;/code&gt; 为
&lt;a href=&#34;https://clouddocs.f5.com/containers/latest/userguide/kubernetes/&#34;&gt;F5 BIG-IP Container Ingress Services for Kubernetes&lt;/a&gt;
提供 &lt;a href=&#34;https://support.f5.com/csp/article/K86859508&#34;&gt;支持和维护&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gloo.solo.io&#34;&gt;Gloo&lt;/a&gt; 是基于
&lt;a href=&#34;https://www.envoyproxy.io&#34;&gt;Envoy&lt;/a&gt; 的开源 Ingress 控制器
提供了来自 &lt;a href=&#34;https://www.solo.io&#34;&gt;solo.io&lt;/a&gt; 企业支持的 API 网络功能&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://haproxy-ingress.github.io&#34;&gt;HAProxy Ingress&lt;/a&gt; 用于 HAProxy 调度可定制的社区驱动的 Ingress 控制器&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.haproxy.com/&#34;&gt;HAProxy Technologies&lt;/a&gt; 为
&lt;a href=&#34;https://github.com/haproxytech/kubernetes-ingress&#34;&gt;HAProxy Ingress Controller for Kubernetes&lt;/a&gt;
提供支持和维护。 详见
&lt;a href=&#34;https://www.haproxy.com/documentation/hapee/1-9r1/traffic-management/kubernetes-ingress-controller/&#34;&gt;官方文档&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;基于 &lt;a href=&#34;https://istio.io/&#34;&gt;Istio&lt;/a&gt; 的
&lt;a href=&#34;https://istio.io/docs/tasks/traffic-management/ingress/&#34;&gt;Control Ingress Traffic&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://konghq.com/&#34;&gt;Kong&lt;/a&gt; 为
&lt;a href=&#34;https://github.com/Kong/kubernetes-ingress-controller&#34;&gt;Kong Ingress Controller for Kubernetes&lt;/a&gt;
提供
&lt;a href=&#34;https://discuss.konghq.com/c/kubernetes&#34;&gt;社区&lt;/a&gt;
或
&lt;a href=&#34;https://konghq.com/kong-enterprise/&#34;&gt;商业&lt;/a&gt;的
支持和维护
&lt;a href=&#34;https://www.nginx.com/products/nginx/kubernetes-ingress-controller&#34;&gt;NGINX Ingress Controller for Kubernetes&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.nginx.com/&#34;&gt;NGINX, Inc.&lt;/a&gt; 为
&lt;a href=&#34;https://www.nginx.com/products/nginx/kubernetes-ingress-controller&#34;&gt;NGINX Ingress Controller for Kubernetes&lt;/a&gt;
提供支持和维护&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://opensource.zalando.com/skipper/kubernetes/ingress-controller/&#34;&gt;Skipper&lt;/a&gt;
为 Service 提供 HTTP 路由 和反向代理。还包含了类似 k8s Ingress 的使用场景，
设计上可以作为自定义代理的库&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/containous/traefik&#34;&gt;Traefik&lt;/a&gt; 是个功能齐全的 Ingress 控制器
(&lt;a href=&#34;https://letsencrypt.org&#34;&gt;Let&amp;rsquo;s Encrypt&lt;/a&gt;, secrets, http2, websocket)
还有来自 &lt;a href=&#34;https://containo.us/services&#34;&gt;Containous&lt;/a&gt; 的商业支持&lt;/li&gt;
&lt;/ul&gt;
&lt;!--
## Using multiple Ingress controllers

You may deploy [any number of ingress controllers](https://git.k8s.io/ingress-nginx/docs/user-guide/multiple-ingress.md#multiple-ingress-controllers)
within a cluster. When you create an ingress, you should annotate each ingress with the appropriate
[`ingress.class`](https://git.k8s.io/ingress-gce/docs/faq/README.md#how-do-i-run-multiple-ingress-controllers-in-the-same-cluster)
to indicate which ingress controller should be used if more than one exists within your cluster.

If you do not define a class, your cloud provider may use a default ingress controller.

Ideally, all ingress controllers should fulfill this specification, but the various ingress
controllers operate slightly differently.

&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; Make sure you review your ingress controller&amp;rsquo;s documentation to understand the caveats of choosing it.&lt;/div&gt;
&lt;/blockquote&gt;

 --&gt;
&lt;h2 id=&#34;using-multiple-ingress-controllers&#34;&gt;Using multiple Ingress controllers&lt;/h2&gt;
&lt;p&gt;用户可以在集群中部署
&lt;a href=&#34;https://git.k8s.io/ingress-nginx/docs/user-guide/multiple-ingress.md#multiple-ingress-controllers&#34;&gt;任意数量的 Ingress 控制器&lt;/a&gt;
如果集群中有多个 Ingress 控制器，在创建 Ingress 时需要为每个 Ingress 标注恰当的
&lt;a href=&#34;https://git.k8s.io/ingress-gce/docs/faq/README.md#how-do-i-run-multiple-ingress-controllers-in-the-same-cluster&#34;&gt;&lt;code&gt;ingress.class&lt;/code&gt;&lt;/a&gt;
来指示使用哪个 Ingress 控制器。&lt;/p&gt;
&lt;p&gt;如果在 Ingress 中没有定义控制器类型，云提供商可能使用一个默认的 Ingress 控制器。&lt;/p&gt;
&lt;p&gt;理想情况下，所有的 Ingress 控制器都应当满足这个规范，但是很多 Ingress 控制器动作方式都有点不同。&lt;/p&gt;
&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; 一定要仔细阅读你选择的 Ingress 控制器的文档，确保理解了相关注意事项。&lt;/div&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;相关资料&#34;&gt;相关资料&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;概念 &lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/docs/concepts/services-networking/ingress/&#34;&gt;Ingress&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;实践 &lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/tasks/access-application-cluster/ingress-minikube&#34;&gt;使用 NGINX 控制器在 Minikube 上设置 Ingress&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: 网络策略</title>
      <link>https://lostsquirrel.github.io/k8sDocs/docs/concepts/services-networking/network-policies/</link>
      <pubDate>Wed, 23 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://lostsquirrel.github.io/k8sDocs/docs/concepts/services-networking/network-policies/</guid>
      <description>
        
        
        &lt;!--
---
reviewers:
- thockin
- caseydavenport
- danwinship
title: Network Policies
content_type: concept
weight: 50
---
 --&gt;
&lt;!-- overview --&gt;
&lt;!--
If you want to control traffic flow at the IP address or port level (OSI layer 3 or 4), then you might consider using Kubernetes NetworkPolicies for particular applications in your cluster.  NetworkPolicies are an application-centric construct which allow you to specify how a &lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/concepts/workloads/pods/&#39; target=&#39;_blank&#39;&gt;pod&lt;span class=&#39;tooltip-text&#39;&gt;Pod 表示集群中运行的一组容器的集合&lt;/span&gt;
&lt;/a&gt; is allowed to communicate with various network &#34;entities&#34; (we use the word &#34;entity&#34; here to avoid overloading the more common terms such as &#34;endpoints&#34; and &#34;services&#34;, which have specific Kubernetes connotations) over the network.

The entities that a Pod can communicate with are identified through a combination of the following 3 identifiers:

1. Other pods that are allowed (exception: a pod cannot block access to itself)
2. Namespaces that are allowed
3. IP blocks (exception: traffic to and from the node where a Pod is running is always allowed, regardless of the IP address of the Pod or the node)

When defining a pod- or namespace- based NetworkPolicy, you use a &lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/concepts/overview/working-with-objects/labels/&#39; target=&#39;_blank&#39;&gt;selector&lt;span class=&#39;tooltip-text&#39;&gt;允许用户基于标签过滤资源列表&lt;/span&gt;
&lt;/a&gt; to specify what traffic is allowed to and from the Pod(s) that match the selector.

Meanwhile, when IP based NetworkPolicies are created, we define policies based on IP blocks (CIDR ranges).
 --&gt;
&lt;p&gt;如果想要在 IP 地址或端口层(OSI 3 或 4 层)控制网络流量，可以考虑对集群中的特定应用使用 k8s 网络策略。
网络策略是一个应用为中心的构造，它允许用户指定怎么控制一个 &lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/concepts/workloads/pods/&#39; target=&#39;_blank&#39;&gt;pod&lt;span class=&#39;tooltip-text&#39;&gt;Pod 表示集群中运行的一组容器的集合&lt;/span&gt;
&lt;/a&gt; 以允许它与其它多种网络实体(这里使用 实体(entity)避免与 &amp;ldquo;Endpoint&amp;rdquo; &amp;ldquo;Service&amp;rdquo;
这此在 k8s 中有明确含义的词混淆)通信。&lt;/p&gt;
&lt;p&gt;Pod 可以与之通信的实体可以由以下三个标识组合来识别:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;其它被允许的 Pod (例外: Pod 不可以禁止与它本身通信)&lt;/li&gt;
&lt;li&gt;被允许的命名空间&lt;/li&gt;
&lt;li&gt;IP 段(例外: Pod 所在的节点进出流量都是允许的，Pod 和 节点的 IP 如果在禁用段则会被忽略)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在定义一个基于 Pod 或 命名空间的网络策略时，可以使用&lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/concepts/overview/working-with-objects/labels/&#39; target=&#39;_blank&#39;&gt;选择器&lt;span class=&#39;tooltip-text&#39;&gt;允许用户基于标签过滤资源列表&lt;/span&gt;
&lt;/a&gt;
来指定只与选择器相匹配的 Pod 在允许与之进行流量往来。&lt;/p&gt;
&lt;p&gt;同时，当创建基于 IP 的网络策略时，定义的策略基于 IP 段(CIDR 范围)。&lt;/p&gt;
&lt;!-- body --&gt;
&lt;!--
## Prerequisites

Network policies are implemented by the [network plugin](/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/). To use network policies, you must be using a networking solution which supports NetworkPolicy. Creating a NetworkPolicy resource without a controller that implements it will have no effect.
--&gt;
&lt;h2 id=&#34;前置条件&#34;&gt;前置条件&lt;/h2&gt;
&lt;p&gt;网络策略是由
&lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/&#34;&gt;网络插件&lt;/a&gt;
实现的。 要使用网络策略，就必要使用一个支持网络策略的网络解决方案。 创建一个没有实现的控制器的
&lt;code&gt;NetworkPolicy&lt;/code&gt; 资源是没有效果的&lt;/p&gt;
&lt;!--
## Isolated and Non-isolated Pods

By default, pods are non-isolated; they accept traffic from any source.

Pods become isolated by having a NetworkPolicy that selects them. Once there is any NetworkPolicy in a namespace selecting a particular pod, that pod will reject any connections that are not allowed by any NetworkPolicy. (Other pods in the namespace that are not selected by any NetworkPolicy will continue to accept all traffic.)

Network policies do not conflict; they are additive. If any policy or policies select a pod, the pod is restricted to what is allowed by the union of those policies&#39; ingress/egress rules. Thus, order of evaluation does not affect the policy result.
 --&gt;
&lt;h2 id=&#34;隔离和非隔离的-pod&#34;&gt;隔离和非隔离的 Pod&lt;/h2&gt;
&lt;p&gt;默认情况下，所有的 Pod 都是非隔离的; 它们可以接收来自任意源的流量。&lt;/p&gt;
&lt;p&gt;当 Pod 被一个 NetworkPolicy 选中时就会变成隔离的。 当在一个命名空间中有任意 NetworkPolicy
选中了某个 Pod， 这个 Pod 就会拒绝那些不被这些 NetworkPolicy 允许的连接就会被拒绝。(同一个
命名空间中其它没有被任何 NetworkPolicy 选择的 Pod 依然继续接收所有流量。)&lt;/p&gt;
&lt;p&gt;网络策略不会冲突； 它们可叠加。 如果任意策略选中了一个 Pod， 该 Pod 就会被限制在这些策略的
&lt;code&gt;ingress/egress&lt;/code&gt; 规则交集允许的范围。 因此，执行的顺序并不会影响策略的结果。&lt;/p&gt;
&lt;!--
## The NetworkPolicy resource {#networkpolicy-resource}

See the [NetworkPolicy](/docs/reference/generated/kubernetes-api/v1.19/#networkpolicy-v1-networking-k8s-io) reference for a full definition of the resource.

An example NetworkPolicy might look like this:

```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: test-network-policy
  namespace: default
spec:
  podSelector:
    matchLabels:
      role: db
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - ipBlock:
        cidr: 172.17.0.0/16
        except:
        - 172.17.1.0/24
    - namespaceSelector:
        matchLabels:
          project: myproject
    - podSelector:
        matchLabels:
          role: frontend
    ports:
    - protocol: TCP
      port: 6379
  egress:
  - to:
    - ipBlock:
        cidr: 10.0.0.0/24
    ports:
    - protocol: TCP
      port: 5978
```

&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; POSTing this to the API server for your cluster will have no effect unless your chosen networking solution supports network policy.&lt;/div&gt;
&lt;/blockquote&gt;


__Mandatory Fields__: As with all other Kubernetes config, a NetworkPolicy
needs `apiVersion`, `kind`, and `metadata` fields.  For general information
about working with config files, see
[Configure Containers Using a ConfigMap](/docs/tasks/configure-pod-container/configure-pod-configmap/),
and [Object Management](/docs/concepts/overview/working-with-objects/object-management).

__spec__: NetworkPolicy [spec](https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api-conventions.md#spec-and-status) has all the information needed to define a particular network policy in the given namespace.

__podSelector__: Each NetworkPolicy includes a `podSelector` which selects the grouping of pods to which the policy applies. The example policy selects pods with the label &#34;role=db&#34;. An empty `podSelector` selects all pods in the namespace.

__policyTypes__: Each NetworkPolicy includes a `policyTypes` list which may include either `Ingress`, `Egress`, or both. The `policyTypes` field indicates whether or not the given policy applies to ingress traffic to selected pod, egress traffic from selected pods, or both. If no `policyTypes` are specified on a NetworkPolicy then by default `Ingress` will always be set and `Egress` will be set if the NetworkPolicy has any egress rules.

__ingress__: Each NetworkPolicy may include a list of allowed `ingress` rules.  Each rule allows traffic which matches both the `from` and `ports` sections. The example policy contains a single rule, which matches traffic on a single port, from one of three sources, the first specified via an `ipBlock`, the second via a `namespaceSelector` and the third via a `podSelector`.

__egress__: Each NetworkPolicy may include a list of allowed `egress` rules.  Each rule allows traffic which matches both the `to` and `ports` sections. The example policy contains a single rule, which matches traffic on a single port to any destination in `10.0.0.0/24`.

So, the example NetworkPolicy:

1. isolates &#34;role=db&#34; pods in the &#34;default&#34; namespace for both ingress and egress traffic (if they weren&#39;t already isolated)
2. (Ingress rules) allows connections to all pods in the &#34;default&#34; namespace with the label &#34;role=db&#34; on TCP port 6379 from:

   * any pod in the &#34;default&#34; namespace with the label &#34;role=frontend&#34;
   * any pod in a namespace with the label &#34;project=myproject&#34;
   * IP addresses in the ranges 172.17.0.0–172.17.0.255 and 172.17.2.0–172.17.255.255 (ie, all of 172.17.0.0/16 except 172.17.1.0/24)
3. (Egress rules) allows connections from any pod in the &#34;default&#34; namespace with the label &#34;role=db&#34; to CIDR 10.0.0.0/24 on TCP port 5978

See the [Declare Network Policy](/docs/tasks/administer-cluster/declare-network-policy/) walkthrough for further examples.
--&gt;
&lt;h2 id=&#34;networkpolicy-resource&#34;&gt;网络策略资源&lt;/h2&gt;
&lt;p&gt;可以在 &lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/docs/reference/generated/kubernetes-api/v1.19/#networkpolicy-v1-networking-k8s-io&#34;&gt;NetworkPolicy&lt;/a&gt; 查阅详细定义文档.&lt;/p&gt;
&lt;p&gt;一个 NetworkPolicy 示例可能长成这个样子:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;networking.k8s.io/v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;NetworkPolicy&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;test-network-policy&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;namespace&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;default&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;podSelector&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;matchLabels&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;role&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;db&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;policyTypes&lt;/span&gt;:
  - &lt;span style=&#34;color:#ae81ff&#34;&gt;Ingress&lt;/span&gt;
  - &lt;span style=&#34;color:#ae81ff&#34;&gt;Egress&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;ingress&lt;/span&gt;:
  - &lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt;:
    - &lt;span style=&#34;color:#f92672&#34;&gt;ipBlock&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;cidr&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;172.17.0.0&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;/16&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;except&lt;/span&gt;:
        - &lt;span style=&#34;color:#ae81ff&#34;&gt;172.17.1.0&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;/24&lt;/span&gt;
    - &lt;span style=&#34;color:#f92672&#34;&gt;namespaceSelector&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;matchLabels&lt;/span&gt;:
          &lt;span style=&#34;color:#f92672&#34;&gt;project&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;myproject&lt;/span&gt;
    - &lt;span style=&#34;color:#f92672&#34;&gt;podSelector&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;matchLabels&lt;/span&gt;:
          &lt;span style=&#34;color:#f92672&#34;&gt;role&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;frontend&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;ports&lt;/span&gt;:
    - &lt;span style=&#34;color:#f92672&#34;&gt;protocol&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;TCP&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;6379&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;egress&lt;/span&gt;:
  - &lt;span style=&#34;color:#f92672&#34;&gt;to&lt;/span&gt;:
    - &lt;span style=&#34;color:#f92672&#34;&gt;ipBlock&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;cidr&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;10.0.0.0&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;/24&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;ports&lt;/span&gt;:
    - &lt;span style=&#34;color:#f92672&#34;&gt;protocol&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;TCP&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;5978&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; 如果集群的网络解决方案(网络插件)不支持网络策略，POST 这个配置到集群 api-server 将是没有效果的
也就是说要使用网络策略，就必须要安装支持网络策略的网络插件。&lt;/div&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;必要字段&lt;/strong&gt;: 与其它所有的 k8s 配置一样， NetworkPolicy 必须有 &lt;code&gt;apiVersion&lt;/code&gt;, &lt;code&gt;kind&lt;/code&gt;, &lt;code&gt;metadata&lt;/code&gt;
字段。 配置文件常用信息请见
&lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/tasks/configure-pod-container/configure-pod-configmap/&#34;&gt;使用 ConfigMap 配置容器&lt;/a&gt;,
和 &lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/docs/concepts/overview/working-with-objects/object-management&#34;&gt;对象管理&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;spec&lt;/strong&gt;: NetworkPolicy &lt;a href=&#34;https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api-conventions.md#spec-and-status&#34;&gt;spec&lt;/a&gt; 包含了在指定命名空间创建特定网络策略的所有信息&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;podSelector&lt;/strong&gt;: 每个 NetworkPolicy 都包含了一个 &lt;code&gt;podSelector&lt;/code&gt; 字段，用户选择应用该策略的 Pod 组。
上面例子中的策略选择包含 &amp;ldquo;&lt;code&gt;role=db&lt;/code&gt;&amp;rdquo; 标签的 Pod。 如果 &lt;code&gt;podSelector&lt;/code&gt; 是空则选择该命名空间中所有的 Pod。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;policyTypes&lt;/strong&gt;: 每个 NetworkPolicy 包含一个 &lt;code&gt;policyTypes&lt;/code&gt; 字段，该字段值为一个列表，
这个列表的值可以是 &lt;code&gt;Ingress&lt;/code&gt;, &lt;code&gt;Egress&lt;/code&gt; 中的任意一个或同时包含两个。 该字段值是否包含
&lt;code&gt;Ingress&lt;/code&gt; 表示是否将该策略执行到输入流量到达选定的 Pod；
&lt;code&gt;Egress&lt;/code&gt; 表示是否将该策略执行到选择 Pod 输出的流量。
如果没有指定 &lt;code&gt;policyTypes&lt;/code&gt; 字段，则默认情况下 &lt;code&gt;Ingress&lt;/code&gt; 问题要设置，而 &lt;code&gt;Egress&lt;/code&gt; 则只在
NetworkPolicy 中包含 &lt;code&gt;egress&lt;/code&gt; 规则是才设置。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ingress&lt;/strong&gt;: 每个 NetworkPolicy 可能包含一个被允许的 &lt;code&gt;ingress&lt;/code&gt; 规则列表。
每个规则所允许的流量会同时匹配 &lt;code&gt;from&lt;/code&gt; 和 &lt;code&gt;ports&lt;/code&gt; 两个部分。上面例子中的策略就包含一个规则
这个规则匹配来自一个端口加上三个源(第一个是通过 &lt;code&gt;ipBlock&lt;/code&gt;指定一个 IP 段； 第三个是通过
&lt;code&gt;namespaceSelector&lt;/code&gt;；第三个是通过 &lt;code&gt;podSelector&lt;/code&gt;)中的一个的组合的流量&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;egress&lt;/strong&gt;: 每个 NetworkPolicy 可能包含一个被允许的 &lt;code&gt;egress&lt;/code&gt; 规则列表。 每个规则允许的流量
由 &lt;code&gt;to&lt;/code&gt; 和 &lt;code&gt;ports&lt;/code&gt; 组合匹配。 上面的例子中的策略包含一个规则，这个规则匹配一个端口加上
&lt;code&gt;10.0.0.0/24&lt;/code&gt; 中的任意一个目标的组合的流量。&lt;/p&gt;
&lt;p&gt;因此，上面例子中 NetworkPolicy 如下:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;在默认(default)命名空间中隔离 &amp;ldquo;role=db&amp;rdquo; 所选择 Pod 的 &lt;code&gt;ingress&lt;/code&gt; 和 &lt;code&gt;egress&lt;/code&gt; 流量(如果它们还没有被隔离)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;(Ingress 规则)允许以下范围的所有连接到默认(default)命名空间中包含 &amp;ldquo;role=db&amp;rdquo; 标签的 Pod 的 TCP 端口 6379:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;默认(default)命名空间中包含 &amp;ldquo;role=frontend&amp;rdquo; 标签的任意 Pod&lt;/li&gt;
&lt;li&gt;所在命名空间包含 &amp;ldquo;project=myproject&amp;rdquo; 标签的任意 Pod&lt;/li&gt;
&lt;li&gt;&lt;code&gt;172.17.0.0–172.17.0.255&lt;/code&gt; 和 &lt;code&gt;172.17.2.0–172.17.255.255&lt;/code&gt; IP 段中的地址(
&lt;code&gt;172.17.0.0/16&lt;/code&gt; 中除了 &lt;code&gt;172.17.1.0/24&lt;/code&gt; 之外的地址
)&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;(Egress 规则) 允许 默认(default)命名空间中包含 &amp;ldquo;role=db&amp;rdquo; 的任意 Pod 到
CIDR 10.0.0.0/24 TCP 端口 5978 的所有连接&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;更多示例见 &lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/tasks/administer-cluster/declare-network-policy/&#34;&gt;声明网络策略&lt;/a&gt;&lt;/p&gt;
&lt;!--
## Behavior of `to` and `from` selectors

There are four kinds of selectors that can be specified in an `ingress` `from` section or `egress` `to` section:

__podSelector__: This selects particular Pods in the same namespace as the NetworkPolicy which should be allowed as ingress sources or egress destinations.

__namespaceSelector__: This selects particular namespaces for which all Pods should be allowed as ingress sources or egress destinations.

__namespaceSelector__ *and* __podSelector__: A single `to`/`from` entry that specifies both `namespaceSelector` and `podSelector` selects particular Pods within particular namespaces. Be careful to use correct YAML syntax; this policy:

```yaml
  ...
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          user: alice
      podSelector:
        matchLabels:
          role: client
  ...
```

contains a single `from` element allowing connections from Pods with the label `role=client` in namespaces with the label `user=alice`. But *this* policy:

```yaml
  ...
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          user: alice
    - podSelector:
        matchLabels:
          role: client
  ...
```

contains two elements in the `from` array, and allows connections from Pods in the local Namespace with the label `role=client`, *or* from any Pod in any namespace with the label `user=alice`.

When in doubt, use `kubectl describe` to see how Kubernetes has interpreted the policy.

__ipBlock__: This selects particular IP CIDR ranges to allow as ingress sources or egress destinations. These should be cluster-external IPs, since Pod IPs are ephemeral and unpredictable.

Cluster ingress and egress mechanisms often require rewriting the source or destination IP
of packets. In cases where this happens, it is not defined whether this happens before or
after NetworkPolicy processing, and the behavior may be different for different
combinations of network plugin, cloud provider, `Service` implementation, etc.

In the case of ingress, this means that in some cases you may be able to filter incoming
packets based on the actual original source IP, while in other cases, the &#34;source IP&#34; that
the NetworkPolicy acts on may be the IP of a `LoadBalancer` or of the Pod&#39;s node, etc.

For egress, this means that connections from pods to `Service` IPs that get rewritten to
cluster-external IPs may or may not be subject to `ipBlock`-based policies.
 --&gt;
&lt;h2 id=&#34;to-和-from-选择器的行为方式&#34;&gt;&lt;code&gt;to&lt;/code&gt; 和 &lt;code&gt;from&lt;/code&gt; 选择器的行为方式&lt;/h2&gt;
&lt;p&gt;在 &lt;code&gt;ingress&lt;/code&gt; 的 &lt;code&gt;from&lt;/code&gt; 区 或 &lt;code&gt;egress&lt;/code&gt; 的 &lt;code&gt;to&lt;/code&gt; 区可以指定以下四种选择器：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;podSelector&lt;/strong&gt;:  选择与 NetworkPolicy 在同一个命名空间的指定 Pod 允许为 &lt;code&gt;ingress&lt;/code&gt; 的源() 或 &lt;code&gt;egress&lt;/code&gt; 的目的
&lt;strong&gt;namespaceSelector&lt;/strong&gt;: 选择指定名称空间，其中所有的 Pod 允许为 &lt;code&gt;ingress&lt;/code&gt; 的源或 &lt;code&gt;egress&lt;/code&gt; 的目的
&lt;strong&gt;namespaceSelector&lt;/strong&gt; &lt;em&gt;加&lt;/em&gt; &lt;strong&gt;podSelector&lt;/strong&gt;: 单个 &lt;code&gt;to&lt;/code&gt;/&lt;code&gt;from&lt;/code&gt; 条目可以同时指定 &lt;code&gt;namespaceSelector&lt;/code&gt; 和 &lt;code&gt;podSelector&lt;/code&gt;
来选择指定命名空间的指定 Pod。 需要注意正确地使用 YAML 语法。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;...&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;ingress&lt;/span&gt;:
  - &lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt;:
    - &lt;span style=&#34;color:#f92672&#34;&gt;namespaceSelector&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;matchLabels&lt;/span&gt;:
          &lt;span style=&#34;color:#f92672&#34;&gt;user&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;alice&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;podSelector&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;matchLabels&lt;/span&gt;:
          &lt;span style=&#34;color:#f92672&#34;&gt;role&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;client&lt;/span&gt;
  &lt;span style=&#34;color:#ae81ff&#34;&gt;...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;上面的这个策略包含一个 &lt;code&gt;from&lt;/code&gt; 元素，它允许连接的 Pod 在包含 &lt;code&gt;user=alice&lt;/code&gt; 标签的命名空间中
并且要包含 &lt;code&gt;role=client&lt;/code&gt; 标签。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;...&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;ingress&lt;/span&gt;:
  - &lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt;:
    - &lt;span style=&#34;color:#f92672&#34;&gt;namespaceSelector&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;matchLabels&lt;/span&gt;:
          &lt;span style=&#34;color:#f92672&#34;&gt;user&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;alice&lt;/span&gt;
    - &lt;span style=&#34;color:#f92672&#34;&gt;podSelector&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;matchLabels&lt;/span&gt;:
          &lt;span style=&#34;color:#f92672&#34;&gt;role&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;client&lt;/span&gt;
  &lt;span style=&#34;color:#ae81ff&#34;&gt;...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这个策略包含两上 &lt;code&gt;from&lt;/code&gt; 元素的数据， 它允许连接的 Pod 有: 同命名空间中有 &lt;code&gt;role=client&lt;/code&gt; 标签的 Pod
&lt;em&gt;或&lt;/em&gt; 任意命名空间中包含 &lt;code&gt;user=alice&lt;/code&gt; 标签的任意 Pod&lt;/p&gt;
&lt;p&gt;当搞不清楚的时候，就使用 &lt;code&gt;kubectl describe&lt;/code&gt; 来看 k8s 是怎么来解释这个策略的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ipBlock&lt;/strong&gt;: 指定 IP CIDR 范围允许为 &lt;code&gt;ingress&lt;/code&gt; 的源或 &lt;code&gt;egress&lt;/code&gt; 的目的。这个 IP 范围
应该是集群外部 IP， 因为 Pod 的 IP 是临时的并且是不可预测的。&lt;/p&gt;
&lt;p&gt;集群的 &lt;code&gt;ingress&lt;/code&gt; 和 &lt;code&gt;egress&lt;/code&gt; 经常需要重写包的源或目的 IP。 如果发生了这种情况， 它发生在
NetworkPolicy 之前还是之后不不确定的，由网络插件，云提供商，&lt;code&gt;Service&lt;/code&gt; 实现的不同而有不同的行为方式&lt;/p&gt;
&lt;p&gt;对于 &lt;code&gt;ingress&lt;/code&gt;, 就意味着在某些情况下可能可以通过实际的原始源 IP 地址来过滤包，在另一情况下,
NetworkPolicy 处理的的 &amp;ldquo;源 IP&amp;rdquo; 可能是 &lt;code&gt;LoadBalancer&lt;/code&gt; 的 IP 或 Pod 所在节点的 IP 等。&lt;/p&gt;
&lt;p&gt;对于 &lt;code&gt;egress&lt;/code&gt;， 这就意味着 Pod 连接的目标 &lt;code&gt;Service&lt;/code&gt; IP 在重写到集群外部IP 就可能受 &lt;code&gt;ipBlock&lt;/code&gt;
策略控制，也可能不受控制。&lt;/p&gt;
&lt;!--
## Default policies

By default, if no policies exist in a namespace, then all ingress and egress traffic is allowed to and from pods in that namespace. The following examples let you change the default behavior
in that namespace.
 --&gt;
&lt;h2 id=&#34;默认策略&#34;&gt;默认策略&lt;/h2&gt;
&lt;p&gt;默认情况下，如果一个命名空间中没有策略存在，那这个命名空间中的 Pod 所有的 &lt;code&gt;ingress&lt;/code&gt; 和 &lt;code&gt;egress&lt;/code&gt;
流量都是允许的。 下面的例子让用户可以修改那个命名空间中的默认行为。&lt;/p&gt;
&lt;!--
### Default deny all ingress traffic

You can create a &#34;default&#34; isolation policy for a namespace by creating a NetworkPolicy that selects all pods but does not allow any ingress traffic to those pods.



 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingnetwork-policy-default-deny-ingressyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/network-policy-default-deny-ingress.yaml&#34; download=&#34;service/networking/network-policy-default-deny-ingress.yaml&#34;&gt;
                    &lt;code&gt;service/networking/network-policy-default-deny-ingress.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingnetwork-policy-default-deny-ingressyaml&#39;)&#34; title=&#34;Copy service/networking/network-policy-default-deny-ingress.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;---
&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;networking.k8s.io/v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;NetworkPolicy&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;default-deny-ingress&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;podSelector&lt;/span&gt;: {}
  &lt;span style=&#34;color:#f92672&#34;&gt;policyTypes&lt;/span&gt;:
  - &lt;span style=&#34;color:#ae81ff&#34;&gt;Ingress&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;



This ensures that even pods that aren&#39;t selected by any other NetworkPolicy will still be isolated. This policy does not change the default egress isolation behavior.
 --&gt;
&lt;h3 id=&#34;默认拒绝所有-ingress-流量&#34;&gt;默认拒绝所有 &lt;code&gt;ingress&lt;/code&gt; 流量&lt;/h3&gt;
&lt;p&gt;可以能过创建一个 NetworkPolicy 为命名空间创建一个&amp;quot;默认&amp;quot;的隔离策略。这个 NetworkPolicy
会选择所有的 Pod 并且不允许任何 &lt;code&gt;ingress&lt;/code&gt; 流量到这些 Pod。&lt;/p&gt;


 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingnetwork-policy-default-deny-ingressyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/network-policy-default-deny-ingress.yaml&#34; download=&#34;service/networking/network-policy-default-deny-ingress.yaml&#34;&gt;
                    &lt;code&gt;service/networking/network-policy-default-deny-ingress.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingnetwork-policy-default-deny-ingressyaml&#39;)&#34; title=&#34;Copy service/networking/network-policy-default-deny-ingress.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;---
&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;networking.k8s.io/v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;NetworkPolicy&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;default-deny-ingress&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;podSelector&lt;/span&gt;: {}
  &lt;span style=&#34;color:#f92672&#34;&gt;policyTypes&lt;/span&gt;:
  - &lt;span style=&#34;color:#ae81ff&#34;&gt;Ingress&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;这样可以保证即便有些 Pod 没有被其它任意 NetworkPolicy 选择还是会被隔离。
这个策略不会影响默认的 &lt;code&gt;egress&lt;/code&gt; 隔离行为。&lt;/p&gt;
&lt;!--
### Default allow all ingress traffic

If you want to allow all traffic to all pods in a namespace (even if policies are added that cause some pods to be treated as &#34;isolated&#34;), you can create a policy that explicitly allows all traffic in that namespace.



 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingnetwork-policy-allow-all-ingressyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/network-policy-allow-all-ingress.yaml&#34; download=&#34;service/networking/network-policy-allow-all-ingress.yaml&#34;&gt;
                    &lt;code&gt;service/networking/network-policy-allow-all-ingress.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingnetwork-policy-allow-all-ingressyaml&#39;)&#34; title=&#34;Copy service/networking/network-policy-allow-all-ingress.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;---
&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;networking.k8s.io/v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;NetworkPolicy&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;allow-all-ingress&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;podSelector&lt;/span&gt;: {}
  &lt;span style=&#34;color:#f92672&#34;&gt;ingress&lt;/span&gt;:
  - {}
  &lt;span style=&#34;color:#f92672&#34;&gt;policyTypes&lt;/span&gt;:
  - &lt;span style=&#34;color:#ae81ff&#34;&gt;Ingress&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;


 --&gt;
&lt;h3 id=&#34;默认允许所有-ingress-流量&#34;&gt;默认允许所有 &lt;code&gt;ingress&lt;/code&gt; 流量&lt;/h3&gt;
&lt;p&gt;如果想要在一个命名空间中允许到达所有 Pod 的所有流量(即便已经添加了一些策略导致有些 Pod 被认为是隔离的)
可以通过创建一个策略显式地允许这个命名空间中的所有离题。&lt;/p&gt;


 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingnetwork-policy-allow-all-ingressyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/network-policy-allow-all-ingress.yaml&#34; download=&#34;service/networking/network-policy-allow-all-ingress.yaml&#34;&gt;
                    &lt;code&gt;service/networking/network-policy-allow-all-ingress.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingnetwork-policy-allow-all-ingressyaml&#39;)&#34; title=&#34;Copy service/networking/network-policy-allow-all-ingress.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;---
&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;networking.k8s.io/v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;NetworkPolicy&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;allow-all-ingress&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;podSelector&lt;/span&gt;: {}
  &lt;span style=&#34;color:#f92672&#34;&gt;ingress&lt;/span&gt;:
  - {}
  &lt;span style=&#34;color:#f92672&#34;&gt;policyTypes&lt;/span&gt;:
  - &lt;span style=&#34;color:#ae81ff&#34;&gt;Ingress&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;


&lt;!--
### Default deny all egress traffic

You can create a &#34;default&#34; egress isolation policy for a namespace by creating a NetworkPolicy that selects all pods but does not allow any egress traffic from those pods.



 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingnetwork-policy-default-deny-egressyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/network-policy-default-deny-egress.yaml&#34; download=&#34;service/networking/network-policy-default-deny-egress.yaml&#34;&gt;
                    &lt;code&gt;service/networking/network-policy-default-deny-egress.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingnetwork-policy-default-deny-egressyaml&#39;)&#34; title=&#34;Copy service/networking/network-policy-default-deny-egress.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;---
&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;networking.k8s.io/v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;NetworkPolicy&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;default-deny-egress&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;podSelector&lt;/span&gt;: {}
  &lt;span style=&#34;color:#f92672&#34;&gt;policyTypes&lt;/span&gt;:
  - &lt;span style=&#34;color:#ae81ff&#34;&gt;Egress&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;



This ensures that even pods that aren&#39;t selected by any other NetworkPolicy will not be allowed egress traffic. This policy does not
change the default ingress isolation behavior.
 --&gt;
&lt;h3 id=&#34;默认拒绝所有-egress-流量&#34;&gt;默认拒绝所有 &lt;code&gt;egress&lt;/code&gt; 流量&lt;/h3&gt;
&lt;p&gt;可以通过创建一个选择所有 Pod 并不接受任何来自这些 Pod 的 egress 流量的 NetworkPolicy 来作为
这个命名空间的默认 &lt;code&gt;egress&lt;/code&gt; 隔离策略。&lt;/p&gt;


 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingnetwork-policy-default-deny-egressyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/network-policy-default-deny-egress.yaml&#34; download=&#34;service/networking/network-policy-default-deny-egress.yaml&#34;&gt;
                    &lt;code&gt;service/networking/network-policy-default-deny-egress.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingnetwork-policy-default-deny-egressyaml&#39;)&#34; title=&#34;Copy service/networking/network-policy-default-deny-egress.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;---
&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;networking.k8s.io/v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;NetworkPolicy&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;default-deny-egress&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;podSelector&lt;/span&gt;: {}
  &lt;span style=&#34;color:#f92672&#34;&gt;policyTypes&lt;/span&gt;:
  - &lt;span style=&#34;color:#ae81ff&#34;&gt;Egress&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;这样可以保证即便有 Pod 没有被其它任意 NetworkPolicy 选中，也不会被允许其 egress 流量。
这个策略不影响默认 &lt;code&gt;ingress&lt;/code&gt; 隔离行为。&lt;/p&gt;
&lt;!--
### Default allow all egress traffic

If you want to allow all traffic from all pods in a namespace (even if policies are added that cause some pods to be treated as &#34;isolated&#34;), you can create a policy that explicitly allows all egress traffic in that namespace.



 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingnetwork-policy-allow-all-egressyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/network-policy-allow-all-egress.yaml&#34; download=&#34;service/networking/network-policy-allow-all-egress.yaml&#34;&gt;
                    &lt;code&gt;service/networking/network-policy-allow-all-egress.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingnetwork-policy-allow-all-egressyaml&#39;)&#34; title=&#34;Copy service/networking/network-policy-allow-all-egress.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;---
&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;networking.k8s.io/v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;NetworkPolicy&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;allow-all-egress&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;podSelector&lt;/span&gt;: {}
  &lt;span style=&#34;color:#f92672&#34;&gt;egress&lt;/span&gt;:
  - {}
  &lt;span style=&#34;color:#f92672&#34;&gt;policyTypes&lt;/span&gt;:
  - &lt;span style=&#34;color:#ae81ff&#34;&gt;Egress&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;


 --&gt;
&lt;h3 id=&#34;默认允许所有-egress-流量&#34;&gt;默认允许所有 &lt;code&gt;egress&lt;/code&gt; 流量&lt;/h3&gt;
&lt;p&gt;如果想要允许一个命名空间中来自所有 Pod 的所有流量(即便已经添加了一些策略导致有些 Pod 被认为是隔离的)，
也可以通过创建一个策略显式地允许这个命名空间中所有的 &lt;code&gt;egress&lt;/code&gt; 流量。&lt;/p&gt;


 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingnetwork-policy-allow-all-egressyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/network-policy-allow-all-egress.yaml&#34; download=&#34;service/networking/network-policy-allow-all-egress.yaml&#34;&gt;
                    &lt;code&gt;service/networking/network-policy-allow-all-egress.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingnetwork-policy-allow-all-egressyaml&#39;)&#34; title=&#34;Copy service/networking/network-policy-allow-all-egress.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;---
&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;networking.k8s.io/v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;NetworkPolicy&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;allow-all-egress&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;podSelector&lt;/span&gt;: {}
  &lt;span style=&#34;color:#f92672&#34;&gt;egress&lt;/span&gt;:
  - {}
  &lt;span style=&#34;color:#f92672&#34;&gt;policyTypes&lt;/span&gt;:
  - &lt;span style=&#34;color:#ae81ff&#34;&gt;Egress&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;


&lt;!--
### Default deny all ingress and all egress traffic

You can create a &#34;default&#34; policy for a namespace which prevents all ingress AND egress traffic by creating the following NetworkPolicy in that namespace.



 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingnetwork-policy-default-deny-allyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/network-policy-default-deny-all.yaml&#34; download=&#34;service/networking/network-policy-default-deny-all.yaml&#34;&gt;
                    &lt;code&gt;service/networking/network-policy-default-deny-all.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingnetwork-policy-default-deny-allyaml&#39;)&#34; title=&#34;Copy service/networking/network-policy-default-deny-all.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;---
&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;networking.k8s.io/v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;NetworkPolicy&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;default-deny-all&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;podSelector&lt;/span&gt;: {}
  &lt;span style=&#34;color:#f92672&#34;&gt;policyTypes&lt;/span&gt;:
  - &lt;span style=&#34;color:#ae81ff&#34;&gt;Ingress&lt;/span&gt;
  - &lt;span style=&#34;color:#ae81ff&#34;&gt;Egress&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;



This ensures that even pods that aren&#39;t selected by any other NetworkPolicy will not be allowed ingress or egress traffic.
 --&gt;
&lt;h3 id=&#34;拒绝所有-ingress-和所有-egress-流量&#34;&gt;拒绝所有 &lt;code&gt;ingress&lt;/code&gt; 和所有 &lt;code&gt;egress&lt;/code&gt; 流量&lt;/h3&gt;
&lt;p&gt;You can create a &amp;ldquo;default&amp;rdquo; policy for a namespace which prevents all ingress AND egress traffic by creating the following NetworkPolicy in that namespace.
可以在一个命名空间中创建一个如下默认的 NetworkPolicy，同时禁止所有的 &lt;code&gt;ingress&lt;/code&gt; 和 &lt;code&gt;egress&lt;/code&gt; 流量。&lt;/p&gt;


 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingnetwork-policy-default-deny-allyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/network-policy-default-deny-all.yaml&#34; download=&#34;service/networking/network-policy-default-deny-all.yaml&#34;&gt;
                    &lt;code&gt;service/networking/network-policy-default-deny-all.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingnetwork-policy-default-deny-allyaml&#39;)&#34; title=&#34;Copy service/networking/network-policy-default-deny-all.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;---
&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;networking.k8s.io/v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;NetworkPolicy&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;default-deny-all&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;podSelector&lt;/span&gt;: {}
  &lt;span style=&#34;color:#f92672&#34;&gt;policyTypes&lt;/span&gt;:
  - &lt;span style=&#34;color:#ae81ff&#34;&gt;Ingress&lt;/span&gt;
  - &lt;span style=&#34;color:#ae81ff&#34;&gt;Egress&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;这样确保即便有 Pod 没有被其它任意 NetworkPolicy 选中，也不会被允许其 &lt;code&gt;ingress&lt;/code&gt; 或 &lt;code&gt;egress&lt;/code&gt; 流量&lt;/p&gt;
&lt;!--
## SCTP support






&lt;div style=&#34;margin-top: 10px; margin-bottom: 10px;&#34;&gt;
&lt;b&gt;功能特性状态:&lt;/b&gt; &lt;code&gt;Kubernetes v1.19 [beta]&lt;/code&gt;
&lt;/div&gt;



As a beta feature, this is enabled by default. To disable SCTP at a cluster level, you (or your cluster administrator) will need to disable the `SCTPSupport` [feature gate](/docs/reference/command-line-tools-reference/feature-gates/) for the API server with `--feature-gates=SCTPSupport=false,…`.
When the feature gate is enabled, you can set the `protocol` field of a NetworkPolicy to `SCTP`.

&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; You must be using a &lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/#cni&#39; target=&#39;_blank&#39;&gt;CNI&lt;span class=&#39;tooltip-text&#39;&gt;Container network interface (CNI) plugins are a type of Network plugin that adheres to the appc/CNI specification.&lt;/span&gt;
&lt;/a&gt; plugin that supports SCTP protocol NetworkPolicies.&lt;/div&gt;
&lt;/blockquote&gt;

 --&gt;
&lt;h2 id=&#34;sctp-支持&#34;&gt;SCTP 支持&lt;/h2&gt;





&lt;div style=&#34;margin-top: 10px; margin-bottom: 10px;&#34;&gt;
&lt;b&gt;功能特性状态:&lt;/b&gt; &lt;code&gt;Kubernetes v1.19 [beta]&lt;/code&gt;
&lt;/div&gt;


&lt;p&gt;作为一个 &lt;code&gt;beta&lt;/code&gt; 版本的特性，默认是开启的。要在集群级别禁用 SCTP， 需要在 api-server 使用
&lt;code&gt;--feature-gates=SCTPSupport=false,…&lt;/code&gt; 禁用
&lt;code&gt;SCTPSupport&lt;/code&gt; &lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/reference/command-line-tools-reference/feature-gates/&#34;&gt;功能特性阀&lt;/a&gt;
当这个特性被启用时，可能在 NetworkPolicy 的 &lt;code&gt;protocol&lt;/code&gt; 字段使用 &lt;code&gt;SCTP&lt;/code&gt; 协议。
&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; 必须要使用一个支持 NetworkPolicy SCTP 协议的 &lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/#cni&#39; target=&#39;_blank&#39;&gt;CNI&lt;span class=&#39;tooltip-text&#39;&gt;Container network interface (CNI) plugins are a type of Network plugin that adheres to the appc/CNI specification.&lt;/span&gt;
&lt;/a&gt; 插件&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/p&gt;
&lt;!--
# What you CAN&#39;T do with network policy&#39;s (at least, not yet)

As of Kubernetes 1.20, the following functionality does not exist in the NetworkPolicy API, but you might be able to implement workarounds using Operating System components (such as SELinux, OpenVSwitch, IPTables, and so on) or Layer 7 technologies (Ingress controllers, Service Mesh implementations) or admission controllers.  In case you are new to network security in Kubernetes, its worth noting that the following User Stories cannot (yet) be implemented using the NetworkPolicy API.  Some (but not all) of these user stories are actively being discussed for future releases of the NetworkPolicy API.

- Forcing internal cluster traffic to go through a common gateway (this might be best served with a service mesh or other proxy).
- Anything TLS related (use a service mesh or ingress controller for this).
- Node specific policies (you can use CIDR notation for these, but you cannot target nodes by their Kubernetes identities specifically).
- Targeting of namespaces or services by name (you can, however, target pods or namespaces by their&lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/concepts/overview/working-with-objects/labels&#39; target=&#39;_blank&#39;&gt;labels&lt;span class=&#39;tooltip-text&#39;&gt;在对象上标上对用户有意义和有关联的属性&lt;/span&gt;
&lt;/a&gt;, which is often a viable workaround).
- Creation or management of &#34;Policy requests&#34; that are fulfilled by a third party.
- Default policies which are applied to all namespaces or pods (there are some third party Kubernetes distributions and projects which can do this).
- Advanced policy querying and reachability tooling.
- The ability to target ranges of Ports in a single policy declaration.
- The ability to log network security events (for example connections that are blocked or accepted).
- The ability to explicitly deny policies (currently the model for NetworkPolicies are deny by default, with only the ability to add allow rules).
- The ability to prevent loopback or incoming host traffic (Pods cannot currently block localhost access, nor do they have the ability to block access from their resident node).
 --&gt;
&lt;h2 id=&#34;不能通过网络策略做到的情况-至少目前还不能&#34;&gt;不能通过网络策略做到的情况 (至少目前还不能)&lt;/h2&gt;
&lt;p&gt;到 k8s v1.20 为止，以下功能在 NetworkPolicy API 中是不存在的， 但可能可能通过操作系统组件
(如 SELinux， OpenVSwitch， IPTables 等) 或者通过 7 层技术(Ingress 控制器，&lt;code&gt;Service Mesh&lt;/code&gt; 实现)
或者 准入控制器(admission controller) 来曲线救国。 假如用户对 k8s 网络安全了解比较少，
需要注意下面的用户故事(User Stories)(还)不能通过使用 NetworkPolicy API 实现。
有些(但不是所有)正在被讨论加入到未来版本中的 NetworkPolicy API 中。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;强制集群内流量通过一个通用网关(这个最好使用服务网格或其它代理来提供)&lt;/li&gt;
&lt;li&gt;所有与 TLS 相关的事(使用服务网格或 Ingress 控制器来实现)&lt;/li&gt;
&lt;li&gt;节点特有的策略(可以使用 CIDR 标注，但是不能能过 k8s 标识来特指一些节点)(说的啥？)&lt;/li&gt;
&lt;li&gt;通过名称将命名空间或 Service 作为目标(通常的做法是通过 Pod 或命名空间的
&lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/concepts/overview/working-with-objects/labels&#39; target=&#39;_blank&#39;&gt;标签&lt;span class=&#39;tooltip-text&#39;&gt;在对象上标上对用户有意义和有关联的属性&lt;/span&gt;
&lt;/a&gt;来筛选目标)&lt;/li&gt;
&lt;li&gt;通过第三方达成对&amp;quot;Policy requests&amp;quot;的创建的或管理&lt;/li&gt;
&lt;li&gt;应用到所有命名空间或 Pod 的默认策略(有些第三方 k8s 发行版本和项目提供该功能)&lt;/li&gt;
&lt;li&gt;高级策略查询和可到达性检查工具&lt;/li&gt;
&lt;li&gt;在一个策略定义中设置端口范围的能力&lt;/li&gt;
&lt;li&gt;输出网络安全事件的能力(如，连接是被禁止或接受)&lt;/li&gt;
&lt;li&gt;声明显示拒绝的策略的能力(目前的网络策略模型默认为拒绝，只能提供添加允许规则的能力)&lt;/li&gt;
&lt;li&gt;能够阻止回环网络或进入主机流量(目前 Pod 不能禁用通过 localhost 的访问，也不能禁止所在主机的访问)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;相关资料&#34;&gt;相关资料&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;实践 &lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/docs/tasks/administer-cluster/declare-network-policy/&#34;&gt;声明网络策略&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;参阅 &lt;a href=&#34;https://github.com/ahmetb/kubernetes-network-policy-recipes&#34;&gt;recipes&lt;/a&gt;
启用网络策略的常见场景&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: 通过 HostAliases 向 Pod 的 /etc/hosts 文件中添加条目</title>
      <link>https://lostsquirrel.github.io/k8sDocs/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/</link>
      <pubDate>Fri, 09 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://lostsquirrel.github.io/k8sDocs/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/</guid>
      <description>
        
        
        &lt;!--
---
reviewers:
- rickypai
- thockin
title: Adding entries to Pod /etc/hosts with HostAliases
content_type: concept
weight: 60
min-kubernetes-server-version: 1.7
--- --&gt;
&lt;!-- overview --&gt;
&lt;!--
Adding entries to a Pod&#39;s `/etc/hosts` file provides Pod-level override of hostname resolution when DNS and other options are not applicable. You can add these custom entries with the HostAliases field in PodSpec.

Modification not using HostAliases is not suggested because the file is managed by the kubelet and can be overwritten on during Pod creation/restart.
--&gt;
&lt;p&gt;在 DNS 和其它方式都不可用时，想要向通过向 Pod 的 &lt;code&gt;/etc/hosts&lt;/code&gt; 文件添加条目的方式来重写 Pod
级别的域名解析，可能通过 &lt;code&gt;PodSpec&lt;/code&gt; 的 &lt;code&gt;HostAliases&lt;/code&gt; 字段向该 Pod 的 &lt;code&gt;/etc/hosts&lt;/code&gt; 添加自定义条目。&lt;/p&gt;
&lt;p&gt;不建议直接修改文件而不使用 &lt;code&gt;HostAliases&lt;/code&gt;， 因为这个文件是受 kubelet 管理并且在 Pod 的重新创建
或重启(能重启？)时会重写该文件，也就是直接修改文件在重建后会丢失。&lt;/p&gt;
&lt;!-- body --&gt;
&lt;!--
## Default hosts file content

Start an Nginx Pod which is assigned a Pod IP:

```shell
kubectl run nginx --image nginx
```

```
pod/nginx created
```

Examine a Pod IP:

```shell
kubectl get pods --output=wide
```

```
NAME     READY     STATUS    RESTARTS   AGE    IP           NODE
nginx    1/1       Running   0          13s    10.200.0.4   worker0
```

The hosts file content would look like this:

```shell
kubectl exec nginx -- cat /etc/hosts
```

```
# Kubernetes-managed hosts file.
127.0.0.1	localhost
::1	localhost ip6-localhost ip6-loopback
fe00::0	ip6-localnet
fe00::0	ip6-mcastprefix
fe00::1	ip6-allnodes
fe00::2	ip6-allrouters
10.200.0.4	nginx
```

By default, the `hosts` file only includes IPv4 and IPv6 boilerplates like
`localhost` and its own hostname.
 --&gt;
&lt;h2 id=&#34;hosts-默认的内容&#34;&gt;hosts 默认的内容&lt;/h2&gt;
&lt;p&gt;启动一个 Nginx 的 Pod，它会被分配一个 Pod IP:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl run nginx --image nginx
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;pod/nginx created
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;检查 Pod IP:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl get pods --output&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;wide
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;NAME     READY     STATUS    RESTARTS   AGE    IP           NODE
nginx    1/1       Running   0          13s    10.200.0.4   worker0
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;通过以下命令查看 hosts 文件内容&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl exec nginx -- cat /etc/hosts
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;输出结果类似如下:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Kubernetes-managed hosts file.
127.0.0.1	localhost
::1	localhost ip6-localhost ip6-loopback
fe00::0	ip6-localnet
fe00::0	ip6-mcastprefix
fe00::1	ip6-allnodes
fe00::2	ip6-allrouters
10.200.0.4	nginx
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;默认情况下， &lt;code&gt;hosts&lt;/code&gt; 文件只会包含 IPv4/IPv6 如 &lt;code&gt;localhost&lt;/code&gt; 这样的模板条目和主机名条目&lt;/p&gt;
&lt;!--
## Adding additional entries with hostAliases

In addition to the default boilerplate, you can add additional entries to the
`hosts` file.
For example: to resolve `foo.local`, `bar.local` to `127.0.0.1` and `foo.remote`,
`bar.remote` to `10.1.2.3`, you can configure HostAliases for a Pod under
`.spec.hostAliases`:



 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkinghostaliases-podyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/hostaliases-pod.yaml&#34; download=&#34;service/networking/hostaliases-pod.yaml&#34;&gt;
                    &lt;code&gt;service/networking/hostaliases-pod.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkinghostaliases-podyaml&#39;)&#34; title=&#34;Copy service/networking/hostaliases-pod.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Pod&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;hostaliases-pod&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;restartPolicy&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Never&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;hostAliases&lt;/span&gt;:
  - &lt;span style=&#34;color:#f92672&#34;&gt;ip&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;127.0.0.1&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;hostnames&lt;/span&gt;:
    - &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;foo.local&amp;#34;&lt;/span&gt;
    - &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;bar.local&amp;#34;&lt;/span&gt;
  - &lt;span style=&#34;color:#f92672&#34;&gt;ip&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;10.1.2.3&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;hostnames&lt;/span&gt;:
    - &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;foo.remote&amp;#34;&lt;/span&gt;
    - &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;bar.remote&amp;#34;&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;containers&lt;/span&gt;:
  - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;cat-hosts&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;image&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;busybox&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;command&lt;/span&gt;:
    - &lt;span style=&#34;color:#ae81ff&#34;&gt;cat&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;args&lt;/span&gt;:
    - &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/etc/hosts&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;



You can start a Pod with that configuration by running:

```shell
kubectl apply -f https://k8s.io/examples/service/networking/hostaliases-pod.yaml
```

```
pod/hostaliases-pod created
```

Examine a Pod&#39;s details to see its IPv4 address and its status:

```shell
kubectl get pod --output=wide
```

```
NAME                           READY     STATUS      RESTARTS   AGE       IP              NODE
hostaliases-pod                0/1       Completed   0          6s        10.200.0.5      worker0
```

The `hosts` file content looks like this:

```shell
kubectl logs hostaliases-pod
```

```
# Kubernetes-managed hosts file.
127.0.0.1	localhost
::1	localhost ip6-localhost ip6-loopback
fe00::0	ip6-localnet
fe00::0	ip6-mcastprefix
fe00::1	ip6-allnodes
fe00::2	ip6-allrouters
10.200.0.5	hostaliases-pod

# Entries added by HostAliases.
127.0.0.1	foo.local	bar.local
10.1.2.3	foo.remote	bar.remote
```

with the additional entries specified at the bottom. --&gt;
&lt;h2 id=&#34;通过-hostaliases-添加额外的条目&#34;&gt;通过 hostAliases 添加额外的条目&lt;/h2&gt;
&lt;p&gt;除了模板条目，可以手动向 &lt;code&gt;hosts&lt;/code&gt; 文件添加条目
例如下面的示例中通过 Pod 的 &lt;code&gt;.spec.hostAliases&lt;/code&gt; 字段实现配置：
将 &lt;code&gt;foo.local&lt;/code&gt;, &lt;code&gt;bar.local&lt;/code&gt; 解析到 &lt;code&gt;127.0.0.1&lt;/code&gt;，
将 &lt;code&gt;foo.remote&lt;/code&gt;, &lt;code&gt;bar.remote&lt;/code&gt; 解析到 &lt;code&gt;10.1.2.3&lt;/code&gt;&lt;/p&gt;


 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkinghostaliases-podyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/hostaliases-pod.yaml&#34; download=&#34;service/networking/hostaliases-pod.yaml&#34;&gt;
                    &lt;code&gt;service/networking/hostaliases-pod.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkinghostaliases-podyaml&#39;)&#34; title=&#34;Copy service/networking/hostaliases-pod.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Pod&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;hostaliases-pod&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;restartPolicy&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Never&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;hostAliases&lt;/span&gt;:
  - &lt;span style=&#34;color:#f92672&#34;&gt;ip&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;127.0.0.1&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;hostnames&lt;/span&gt;:
    - &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;foo.local&amp;#34;&lt;/span&gt;
    - &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;bar.local&amp;#34;&lt;/span&gt;
  - &lt;span style=&#34;color:#f92672&#34;&gt;ip&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;10.1.2.3&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;hostnames&lt;/span&gt;:
    - &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;foo.remote&amp;#34;&lt;/span&gt;
    - &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;bar.remote&amp;#34;&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;containers&lt;/span&gt;:
  - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;cat-hosts&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;image&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;busybox&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;command&lt;/span&gt;:
    - &lt;span style=&#34;color:#ae81ff&#34;&gt;cat&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;args&lt;/span&gt;:
    - &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/etc/hosts&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;用户可以通过以下命令，使用该配置启动一个 Pod:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl apply -f https://k8s.io/examples/service/networking/hostaliases-pod.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;pod/hostaliases-pod created
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;通过以下命令查看 Pod 的信息，查看其 IPv4 地址及其状态:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl get pod --output&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;wide
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;NAME                           READY     STATUS      RESTARTS   AGE       IP              NODE
hostaliases-pod                0/1       Completed   0          6s        10.200.0.5      worker0
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;通过以下命令查看 &lt;code&gt;hosts&lt;/code&gt; 文件的内存:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl logs hostaliases-pod
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;输出结果类似:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Kubernetes-managed hosts file.
127.0.0.1	localhost
::1	localhost ip6-localhost ip6-loopback
fe00::0	ip6-localnet
fe00::0	ip6-mcastprefix
fe00::1	ip6-allnodes
fe00::2	ip6-allrouters
10.200.0.5	hostaliases-pod

# Entries added by HostAliases.
127.0.0.1	foo.local	bar.local
10.1.2.3	foo.remote	bar.remote
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;额外添加的条目的文件的底部。&lt;/p&gt;
&lt;!--
## Why does the kubelet manage the hosts file? {#why-does-kubelet-manage-the-hosts-file}

The kubelet [manages](https://github.com/kubernetes/kubernetes/issues/14633) the
`hosts` file for each container of the Pod to prevent Docker from
[modifying](https://github.com/moby/moby/issues/17190) the file after the
containers have already been started.

&lt;blockquote class=&#34;caution&#34;&gt;
  &lt;div&gt;&lt;strong&gt;注意：&lt;/strong&gt; &lt;p&gt;Avoid making manual changes to the hosts file inside a container.&lt;/p&gt;
&lt;p&gt;If you make manual changes to the hosts file,
those changes are lost when the container exits.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;

 --&gt;
&lt;h2 id=&#34;why-does-kubelet-manage-the-hosts-file&#34;&gt;为啥要 kubelet 管理 hosts 文件?&lt;/h2&gt;
&lt;p&gt;使用 kubelet &lt;a href=&#34;https://github.com/kubernetes/kubernetes/issues/14633&#34;&gt;管理&lt;/a&gt; the
Pod 中每个容器的 &lt;code&gt;hosts&lt;/code&gt; 文件，是防止 Docker 在容器启动后再
&lt;a href=&#34;https://github.com/moby/moby/issues/17190&#34;&gt;修改&lt;/a&gt; 该文件。&lt;/p&gt;
&lt;blockquote class=&#34;caution&#34;&gt;
  &lt;div&gt;&lt;strong&gt;注意：&lt;/strong&gt; &lt;p&gt;避免手动修改容器中的 &lt;code&gt;hosts&lt;/code&gt; 文件&lt;/p&gt;
&lt;p&gt;如果手动修改了 &lt;code&gt;hosts&lt;/code&gt; 文件， 这些改动会在容器退出时丢失。&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;


      </description>
    </item>
    
    <item>
      <title>Docs: IPv4/IPv6 双栈</title>
      <link>https://lostsquirrel.github.io/k8sDocs/docs/concepts/services-networking/dual-stack/</link>
      <pubDate>Fri, 09 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://lostsquirrel.github.io/k8sDocs/docs/concepts/services-networking/dual-stack/</guid>
      <description>
        
        
        &lt;!--
---
reviewers:
- lachie83
- khenidak
- aramase
title: IPv4/IPv6 dual-stack
feature:
  title: IPv4/IPv6 dual-stack
  description: &gt;
    Allocation of IPv4 and IPv6 addresses to Pods and Services

content_type: concept
weight: 70
---
--&gt;
&lt;!-- overview --&gt;
&lt;!--





&lt;div style=&#34;margin-top: 10px; margin-bottom: 10px;&#34;&gt;
&lt;b&gt;功能特性状态:&lt;/b&gt; &lt;code&gt;Kubernetes v1.16 [alpha]&lt;/code&gt;
&lt;/div&gt;



 IPv4/IPv6 dual-stack enables the allocation of both IPv4 and IPv6 addresses to &lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/concepts/workloads/pods/&#39; target=&#39;_blank&#39;&gt;Pods&lt;span class=&#39;tooltip-text&#39;&gt;Pod 表示集群中运行的一组容器的集合&lt;/span&gt;
&lt;/a&gt; and &lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/concepts/services-networking/service/&#39; target=&#39;_blank&#39;&gt;Services&lt;span class=&#39;tooltip-text&#39;&gt;以网络服务的方式让一个由一组 Pod 构成的应用可以对外提供服务的一种方式&lt;/span&gt;
&lt;/a&gt;.

If you enable IPv4/IPv6 dual-stack networking for your Kubernetes cluster, the cluster will support the simultaneous assignment of both IPv4 and IPv6 addresses.
 --&gt;





&lt;div style=&#34;margin-top: 10px; margin-bottom: 10px;&#34;&gt;
&lt;b&gt;功能特性状态:&lt;/b&gt; &lt;code&gt;Kubernetes v1.16 [alpha]&lt;/code&gt;
&lt;/div&gt;


&lt;p&gt;IPv4/IPv6 双栈让 &lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/concepts/workloads/pods/&#39; target=&#39;_blank&#39;&gt;Pod&lt;span class=&#39;tooltip-text&#39;&gt;Pod 表示集群中运行的一组容器的集合&lt;/span&gt;
&lt;/a&gt; 和
&lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/concepts/services-networking/service/&#39; target=&#39;_blank&#39;&gt;Service&lt;span class=&#39;tooltip-text&#39;&gt;以网络服务的方式让一个由一组 Pod 构成的应用可以对外提供服务的一种方式&lt;/span&gt;
&lt;/a&gt; 能够同时分配到 IPv4 和 IPv6 地址。&lt;/p&gt;
&lt;p&gt;如果在 k8s 集群中启用了 IPv4/IPv6 双栈网络，则集群支持同时分配 IPv4 和 IPv6 地址。&lt;/p&gt;
&lt;!-- body --&gt;
&lt;!--
## Supported Features

Enabling IPv4/IPv6 dual-stack on your Kubernetes cluster provides the following features:

   * Dual-stack Pod networking (a single IPv4 and IPv6 address assignment per Pod)
   * IPv4 and IPv6 enabled Services (each Service must be for a single address family)
   * Pod off-cluster egress routing (eg. the Internet) via both IPv4 and IPv6 interfaces
 --&gt;
&lt;h2 id=&#34;支持的特性&#34;&gt;支持的特性&lt;/h2&gt;
&lt;p&gt;在集群中开启 IPv4/IPv6 双栈可以提供以下特性:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Pod 双栈网络(每个 Pod 分配一个 IPv4 和 IPv6 地址)&lt;/li&gt;
&lt;li&gt;Service 启用 IPv4 和 IPv6 (每个 Service 只能是 IPv4 或 IPv6)&lt;/li&gt;
&lt;li&gt;Pod 的出站路由(如，到互联网)会同时通过 IPv4 和 IPv6 接口&lt;/li&gt;
&lt;/ul&gt;
&lt;!--
## Prerequisites

The following prerequisites are needed in order to utilize IPv4/IPv6 dual-stack Kubernetes clusters:

   * Kubernetes 1.16 or later
   * Provider support for dual-stack networking (Cloud provider or otherwise must be able to provide Kubernetes nodes with routable IPv4/IPv6 network interfaces)
   * A network plugin that supports dual-stack (such as Kubenet or Calico)
 --&gt;
&lt;h2 id=&#34;前置条件&#34;&gt;前置条件&lt;/h2&gt;
&lt;p&gt;为集群启用 IPv4/IPv6 双栈需要做以下准备:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;k8s &lt;code&gt;v1.16+&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;提供商支持双栈网络(云提供商或其它的提供者必须要为 k8s 节点提供IPv4/IPv6网络接口)&lt;/li&gt;
&lt;li&gt;一个支持双栈的网络插件(如 Kubenet 或 Calico)&lt;/li&gt;
&lt;/ul&gt;
&lt;!--
## Enable IPv4/IPv6 dual-stack

To enable IPv4/IPv6 dual-stack, enable the `IPv6DualStack` [feature gate](/docs/reference/command-line-tools-reference/feature-gates/) for the relevant components of your cluster, and set dual-stack cluster network assignments:

   * kube-apiserver:
      * `--feature-gates=&#34;IPv6DualStack=true&#34;`
      * `--service-cluster-ip-range=&lt;IPv4 CIDR&gt;,&lt;IPv6 CIDR&gt;`
   * kube-controller-manager:
      * `--feature-gates=&#34;IPv6DualStack=true&#34;`
      * `--cluster-cidr=&lt;IPv4 CIDR&gt;,&lt;IPv6 CIDR&gt;`
      * `--service-cluster-ip-range=&lt;IPv4 CIDR&gt;,&lt;IPv6 CIDR&gt;`
      * `--node-cidr-mask-size-ipv4|--node-cidr-mask-size-ipv6` defaults to /24 for IPv4 and /64 for IPv6
   * kubelet:
      * `--feature-gates=&#34;IPv6DualStack=true&#34;`
   * kube-proxy:
      * `--cluster-cidr=&lt;IPv4 CIDR&gt;,&lt;IPv6 CIDR&gt;`
      * `--feature-gates=&#34;IPv6DualStack=true&#34;`

&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; &lt;p&gt;An example of an IPv4 CIDR: &lt;code&gt;10.244.0.0/16&lt;/code&gt; (though you would supply your own address range)&lt;/p&gt;
&lt;p&gt;An example of an IPv6 CIDR: &lt;code&gt;fdXY:IJKL:MNOP:15::/64&lt;/code&gt; (this shows the format but is not a valid address - see &lt;a href=&#34;https://tools.ietf.org/html/rfc4193&#34;&gt;RFC 4193&lt;/a&gt;)&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;

 --&gt;
&lt;h2 id=&#34;启用-ipv4ipv6-双栈&#34;&gt;启用 IPv4/IPv6 双栈&lt;/h2&gt;
&lt;p&gt;要启用 IPv4/IPv6 双栈, 需要打开集群中的对应组件 &lt;code&gt;IPv6DualStack&lt;/code&gt; &lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/docs/reference/command-line-tools-reference/feature-gates/&#34;&gt;功能阀&lt;/a&gt;
并设置集群双栈网络分配:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;kube-apiserver:
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--feature-gates=&amp;quot;IPv6DualStack=true&amp;quot;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--service-cluster-ip-range=&amp;lt;IPv4 CIDR&amp;gt;,&amp;lt;IPv6 CIDR&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;kube-controller-manager:
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--feature-gates=&amp;quot;IPv6DualStack=true&amp;quot;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--cluster-cidr=&amp;lt;IPv4 CIDR&amp;gt;,&amp;lt;IPv6 CIDR&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--service-cluster-ip-range=&amp;lt;IPv4 CIDR&amp;gt;,&amp;lt;IPv6 CIDR&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--node-cidr-mask-size-ipv4|--node-cidr-mask-size-ipv6&lt;/code&gt; IPv4 默认为 /24；IPv6 默认为 /64&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;kubelet:
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--feature-gates=&amp;quot;IPv6DualStack=true&amp;quot;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;kube-proxy:
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--cluster-cidr=&amp;lt;IPv4 CIDR&amp;gt;,&amp;lt;IPv6 CIDR&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--feature-gates=&amp;quot;IPv6DualStack=true&amp;quot;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; &lt;p&gt;一个 IPv4 CIDR 示例: &lt;code&gt;10.244.0.0/16&lt;/code&gt; (应该根据需要设置IP范围)&lt;/p&gt;
&lt;p&gt;一个 IPv6 CIDR 示例: &lt;code&gt;fdXY:IJKL:MNOP:15::/64&lt;/code&gt; (这里只显示格式，但不是一个有效的值 - 具体见 &lt;a href=&#34;https://tools.ietf.org/html/rfc4193&#34;&gt;RFC 4193&lt;/a&gt;)&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;

&lt;!--
## Services

If your cluster has IPv4/IPv6 dual-stack networking enabled, you can create &lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/concepts/services-networking/service/&#39; target=&#39;_blank&#39;&gt;Services&lt;span class=&#39;tooltip-text&#39;&gt;以网络服务的方式让一个由一组 Pod 构成的应用可以对外提供服务的一种方式&lt;/span&gt;
&lt;/a&gt; with either an IPv4 or an IPv6 address. You can choose the address family for the Service&#39;s cluster IP by setting a field, `.spec.ipFamily`, on that Service.
You can only set this field when creating a new Service. Setting the `.spec.ipFamily` field is optional and should only be used if you plan to enable IPv4 and IPv6 &lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/concepts/services-networking/service/&#39; target=&#39;_blank&#39;&gt;Services&lt;span class=&#39;tooltip-text&#39;&gt;以网络服务的方式让一个由一组 Pod 构成的应用可以对外提供服务的一种方式&lt;/span&gt;
&lt;/a&gt; and &lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/concepts/services-networking/ingress/&#39; target=&#39;_blank&#39;&gt;Ingresses&lt;span class=&#39;tooltip-text&#39;&gt;一个用于管理外部访问集群内 Service 的 API 对象，通常是 HTTP。&lt;/span&gt;
&lt;/a&gt; on your cluster. The configuration of this field not a requirement for [egress](#egress-traffic) traffic.

&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; The default address family for your cluster is the address family of the first service cluster IP range configured via the &lt;code&gt;--service-cluster-ip-range&lt;/code&gt; flag to the kube-controller-manager.&lt;/div&gt;
&lt;/blockquote&gt;


You can set `.spec.ipFamily` to either:

   * `IPv4`: The API server will assign an IP from a `service-cluster-ip-range` that is `ipv4`
   * `IPv6`: The API server will assign an IP from a `service-cluster-ip-range` that is `ipv6`

The following Service specification does not include the `ipFamily` field. Kubernetes will assign an IP address (also known as a &#34;cluster IP&#34;) from the first configured `service-cluster-ip-range` to this Service.



 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingdual-stack-default-svcyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/dual-stack-default-svc.yaml&#34; download=&#34;service/networking/dual-stack-default-svc.yaml&#34;&gt;
                    &lt;code&gt;service/networking/dual-stack-default-svc.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingdual-stack-default-svcyaml&#39;)&#34; title=&#34;Copy service/networking/dual-stack-default-svc.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Service&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-service&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;selector&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;app&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;MyApp&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;ports&lt;/span&gt;:
    - &lt;span style=&#34;color:#f92672&#34;&gt;protocol&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;TCP&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;targetPort&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;9376&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;



The following Service specification includes the `ipFamily` field. Kubernetes will assign an IPv6 address (also known as a &#34;cluster IP&#34;) from the configured `service-cluster-ip-range` to this Service.



 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingdual-stack-ipv6-svcyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/dual-stack-ipv6-svc.yaml&#34; download=&#34;service/networking/dual-stack-ipv6-svc.yaml&#34;&gt;
                    &lt;code&gt;service/networking/dual-stack-ipv6-svc.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingdual-stack-ipv6-svcyaml&#39;)&#34; title=&#34;Copy service/networking/dual-stack-ipv6-svc.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Service&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-service&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;ipFamily&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;IPv6&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;selector&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;app&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;MyApp&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;ports&lt;/span&gt;:
    - &lt;span style=&#34;color:#f92672&#34;&gt;protocol&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;TCP&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;targetPort&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;9376&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;



For comparison, the following Service specification will be assigned an IPv4 address (also known as a &#34;cluster IP&#34;) from the configured `service-cluster-ip-range` to this Service.



 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingdual-stack-ipv4-svcyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/dual-stack-ipv4-svc.yaml&#34; download=&#34;service/networking/dual-stack-ipv4-svc.yaml&#34;&gt;
                    &lt;code&gt;service/networking/dual-stack-ipv4-svc.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingdual-stack-ipv4-svcyaml&#39;)&#34; title=&#34;Copy service/networking/dual-stack-ipv4-svc.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Service&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-service&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;ipFamily&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;IPv4&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;selector&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;app&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;MyApp&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;ports&lt;/span&gt;:
    - &lt;span style=&#34;color:#f92672&#34;&gt;protocol&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;TCP&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;targetPort&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;9376&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;


 --&gt;
&lt;h2 id=&#34;service&#34;&gt;Service&lt;/h2&gt;
&lt;p&gt;如果集群启用的了 IPv4/IPv6 双栈网络，就可以创建一个带 IPv4 或 IPv6 地址的 &lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/concepts/services-networking/service/&#39; target=&#39;_blank&#39;&gt;Service&lt;span class=&#39;tooltip-text&#39;&gt;以网络服务的方式让一个由一组 Pod 构成的应用可以对外提供服务的一种方式&lt;/span&gt;
&lt;/a&gt;。
可以通过 Service 的 &lt;code&gt;.spec.ipFamily&lt;/code&gt; 来设置该 Service 是使用 IPv4 还是 IPv6 地址。
只有在创建一个新的 Service 才可以设置该字段。 &lt;code&gt;.spec.ipFamily&lt;/code&gt; 是一个可选字段，只有在需要
在 &lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/concepts/services-networking/service/&#39; target=&#39;_blank&#39;&gt;Service&lt;span class=&#39;tooltip-text&#39;&gt;以网络服务的方式让一个由一组 Pod 构成的应用可以对外提供服务的一种方式&lt;/span&gt;
&lt;/a&gt; 和 &lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/k8sDocs/concepts/services-networking/ingress/&#39; target=&#39;_blank&#39;&gt;Ingress&lt;span class=&#39;tooltip-text&#39;&gt;一个用于管理外部访问集群内 Service 的 API 对象，通常是 HTTP。&lt;/span&gt;
&lt;/a&gt;
上启用 IPv4 和 IPv6 时才需要配置该字段。 (这里还有一句不太明白在说啥)&lt;/p&gt;
&lt;blockquote class=&#34;note&#34;&gt;
  &lt;div&gt;&lt;strong&gt;说明：&lt;/strong&gt; 集群默认使用的 IP 族是 kube-controller-manager 上设置 &lt;code&gt;--service-cluster-ip-range&lt;/code&gt;的
值中，前面那一个 CIDR 对应的 IP 族。&lt;/div&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code&gt;.spec.ipFamily&lt;/code&gt; 字段的值可以是:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;IPv4&lt;/code&gt;: API server 会从 &lt;code&gt;service-cluster-ip-range&lt;/code&gt; 中分配一个 &lt;code&gt;ipv4&lt;/code&gt; 地址&lt;/li&gt;
&lt;li&gt;&lt;code&gt;IPv6&lt;/code&gt;: API server 会从 &lt;code&gt;service-cluster-ip-range&lt;/code&gt; 中分配一个 &lt;code&gt;ipv6&lt;/code&gt; 地址&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下面的这个 Service 配置文件中没有包含 &lt;code&gt;ipFamily&lt;/code&gt; 字段。 k8s 会为它分配一个 IP 地址
(也就是集群IP)，这个地址是 &lt;code&gt;service-cluster-ip-range&lt;/code&gt; 配置值中第一个个值所定义的 IP 范围内的一个 IP 地址&lt;/p&gt;


 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingdual-stack-default-svcyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/dual-stack-default-svc.yaml&#34; download=&#34;service/networking/dual-stack-default-svc.yaml&#34;&gt;
                    &lt;code&gt;service/networking/dual-stack-default-svc.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingdual-stack-default-svcyaml&#39;)&#34; title=&#34;Copy service/networking/dual-stack-default-svc.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Service&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-service&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;selector&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;app&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;MyApp&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;ports&lt;/span&gt;:
    - &lt;span style=&#34;color:#f92672&#34;&gt;protocol&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;TCP&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;targetPort&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;9376&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;下面的这个 Service 配置文件中包含 &lt;code&gt;ipFamily&lt;/code&gt; 字段。 k8s 会为它分配一个 IPv6 地址(也是集群IP)
这个地址在 &lt;code&gt;service-cluster-ip-range&lt;/code&gt; 配置的范围内&lt;/p&gt;


 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingdual-stack-ipv6-svcyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/dual-stack-ipv6-svc.yaml&#34; download=&#34;service/networking/dual-stack-ipv6-svc.yaml&#34;&gt;
                    &lt;code&gt;service/networking/dual-stack-ipv6-svc.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingdual-stack-ipv6-svcyaml&#39;)&#34; title=&#34;Copy service/networking/dual-stack-ipv6-svc.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Service&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-service&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;ipFamily&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;IPv6&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;selector&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;app&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;MyApp&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;ports&lt;/span&gt;:
    - &lt;span style=&#34;color:#f92672&#34;&gt;protocol&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;TCP&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;targetPort&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;9376&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;


&lt;p&gt;为了对应，下面的这个 Service 的配置会被分配一个 IPv4 地址(作为集群IP)，这个地址在 &lt;code&gt;service-cluster-ip-range&lt;/code&gt; 配置的范围内&lt;/p&gt;


 













&lt;table class=&#34;includecode&#34; id=&#34;servicenetworkingdual-stack-ipv4-svcyaml&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;
                &lt;a href=&#34;https://%25!s%28%3cnil%3e%29/master/content/zh/examples/service/networking/dual-stack-ipv4-svc.yaml&#34; download=&#34;service/networking/dual-stack-ipv4-svc.yaml&#34;&gt;
                    &lt;code&gt;service/networking/dual-stack-ipv4-svc.yaml&lt;/code&gt;
                &lt;/a&gt;
                &lt;img src=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/images/copycode.svg&#34; style=&#34;max-height:24px; cursor: pointer&#34; onclick=&#34;copyCode(&#39;servicenetworkingdual-stack-ipv4-svcyaml&#39;)&#34; title=&#34;Copy service/networking/dual-stack-ipv4-svc.yaml to clipboard&#34;&gt;
            &lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Service&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my-service&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;ipFamily&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;IPv4&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;selector&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;app&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;MyApp&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;ports&lt;/span&gt;:
    - &lt;span style=&#34;color:#f92672&#34;&gt;protocol&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;TCP&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;targetPort&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;9376&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;


&lt;!--
### Type LoadBalancer

On cloud providers which support IPv6 enabled external load balancers, setting the `type` field to `LoadBalancer` in additional to setting `ipFamily` field to `IPv6` provisions a cloud load balancer for your Service.
 --&gt;
&lt;h3 id=&#34;type-loadbalancer&#34;&gt;Type LoadBalancer&lt;/h3&gt;
&lt;p&gt;在支持 IPv6 的云提供商上启用外部负载均衡器时，在 Service 上设置 &lt;code&gt;type&lt;/code&gt; 字段值为 &lt;code&gt;LoadBalancer&lt;/code&gt; 时，同
时还需要设置 &lt;code&gt;ipFamily&lt;/code&gt; 字段的值为 &lt;code&gt;IPv6&lt;/code&gt;。&lt;/p&gt;
&lt;!--
## Egress Traffic

The use of publicly routable and non-publicly routable IPv6 address blocks is acceptable provided the underlying &lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/#cni&#39; target=&#39;_blank&#39;&gt;CNI&lt;span class=&#39;tooltip-text&#39;&gt;Container network interface (CNI) plugins are a type of Network plugin that adheres to the appc/CNI specification.&lt;/span&gt;
&lt;/a&gt; provider is able to implement the transport. If you have a Pod that uses non-publicly routable IPv6 and want that Pod to reach off-cluster destinations (eg. the public Internet), you must set up IP masquerading for the egress traffic and any replies. The [ip-masq-agent](https://github.com/kubernetes-incubator/ip-masq-agent) is dual-stack aware, so you can use ip-masq-agent for IP masquerading on dual-stack clusters.
 --&gt;
&lt;h2 id=&#34;egress-traffic&#34;&gt;Egress Traffic&lt;/h2&gt;
&lt;p&gt;底层实现的 &lt;a class=&#39;glossary-tooltip&#39; href=&#39;https://lostsquirrel.github.io/k8sDocs/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/#cni&#39; target=&#39;_blank&#39;&gt;CNI&lt;span class=&#39;tooltip-text&#39;&gt;Container network interface (CNI) plugins are a type of Network plugin that adheres to the appc/CNI specification.&lt;/span&gt;
&lt;/a&gt; 提供者可以提供对
公网可路由和公网不可路由的 IPv6 地址段。如果 Pod 使用的是公网不可路由的 IPv6 地址，但要求
这个 Pod 可以访问集群外的目标(如，互联网)， 需要为外出流量及其应答做 IP 地址转换。
&lt;a href=&#34;https://github.com/kubernetes-incubator/ip-masq-agent&#34;&gt;ip-masq-agent&lt;/a&gt; 支持双栈，
所以可以使用它在双栈集群中做地址转换。&lt;/p&gt;
&lt;!--
## Known Issues

   * Kubenet forces IPv4,IPv6 positional reporting of IPs (--cluster-cidr)
 --&gt;
&lt;h2 id=&#34;已知问题&#34;&gt;已知问题&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Kubenet forces IPv4,IPv6 positional reporting of IPs (&amp;ndash;cluster-cidr)&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;kubenet 强制 IPv4,IPv6 位置汇报  (&amp;ndash;cluster-cidr)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;相关资料&#34;&gt;相关资料&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;实践 &lt;a href=&#34;https://lostsquirrel.github.io/k8sDocs/k8sDocs/tasks/network/validate-dual-stack&#34;&gt;验证 IPv4/IPv6 双栈网络&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
  </channel>
</rss>
